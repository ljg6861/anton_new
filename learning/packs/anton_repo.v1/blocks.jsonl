{"id": "b0000001", "domain": "anton_repo", "section_path": ["metrics.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, logger: Any):\n        self.logger = logger\n        self.start_time = time.monotonic()\n        self.end_time = None\n        self.step_latencies = {}\n        self.step_token_counts = {}\n        self.resource_snapshots = {}\n        self.agent_step_count = 0\n        self.task_completed = False\n        self.task_completion_reason = \"Unknown\"\n\n    ", "source": {"file": "metrics.py", "section": "metrics.py:def __init__(self, logger: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000002", "domain": "anton_repo", "section_path": ["metrics.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def get_resource_usage(self) -> dict:\n        \"\"\"Captures a snapshot of current CPU, RAM, and GPU VRAM usage.\"\"\"\n        global NVML_INITIALIZED\n        usage = {\n            \"cpu_percent\": psutil.cpu_percent(),\n            \"ram_percent\": psutil.virtual_memory().percent,\n            \"gpu_percent\": None,\n            \"vram_percent\": None\n        }\n        if NVML_INITIALIZED:\n            try:\n                handle = nvmlDeviceGetHandleByIndex(0)\n                gpu_util = nvmlDeviceGetUtilizationRates(handle)\n                mem_info = nvmlDeviceGetMemoryInfo(handle)\n                usage[\"gpu_percent\"] = gpu_util.gpu\n                usage[\"vram_percent\"] = (mem_info.used / mem_info.total) * 100\n            except NVMLError as e:\n                self.logger.warning(f\"Could not get GPU stats: {e}\")\n        return usage\n\n    ", "source": {"file": "metrics.py", "section": "metrics.py:def get_resource_usage(self)"}, "tags": ["anton_repo"]}
{"id": "b0000003", "domain": "anton_repo", "section_path": ["metrics.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def log_final_metrics(self):\n        \"\"\"Calculates and logs all final metrics at the end of the request.\"\"\"\n        self.end_time = time.monotonic()\n        end_to_end_latency = self.end_time - self.start_time\n        total_tokens_generated = sum(self.step_token_counts.values())\n\n        # --- FORMAT AND LOG METRICS ---\n        self.logger.info(\"--- AGENT EXECUTION METRICS ---\")\n\n        # Latency Metrics\n        self.logger.info(f\"[Latency] End-to-End: {end_to_end_latency:.2f} seconds\")\n        for step, latency in self.step_latencies.items():\n            self.logger.info(f\"[Latency] Step '{step}': {latency:.2f} seconds\")\n\n        # Throughput Metrics\n        self.logger.info(f\"[Throughput] Total Tokens Generated: {total_tokens_generated}\")\n        for step, latency in self.step_latencies.items():\n            tokens = self.step_token_counts.get(step, 0)\n            if latency > 0 and tokens > 0:\n                throughput = tokens / latency\n                self.logger.info(f\"[Throughput] Step '{step}': {throughput:.2f} tokens/sec\")\n\n        # Resource Usage Metrics\n        for step, usage in self.resource_snapshots.items():\n            self.logger.info(\n                f\"[Resource Usage] After Step '{step}': \"\n                f\"CPU: {usage['cpu_percent']:.1f}%, RAM: {usage['ram_percent']:.1f}%, \"\n                f\"GPU: {usage.get('gpu_percent', 'N/A')}%, VRAM: {usage.get('vram_percent', 'N/A'):.1f}%\"\n            )\n\n        # Agent & Task Metrics\n        self.logger.info(f\"[Agent] Step Count: {self.agent_step_count}\")\n        self.logger.info(f\"[Task] Completion Status: {'Success' if self.task_completed else 'Failure'}\")\n        self.logger.info(f\"[Task] Completion Reason: {self.task_completion_reason}\")\n        self.logger.info(\"---------------------------------\")\n\n\n", "source": {"file": "metrics.py", "section": "metrics.py:def log_final_metrics(self)"}, "tags": ["anton_repo"]}
{"id": "b0000004", "domain": "anton_repo", "section_path": ["metrics.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def initialize_nvml(logger: Any):\n    \"\"\"Initializes the NVML library for GPU monitoring.\"\"\"\n    global NVML_INITIALIZED\n    if not NVML_INITIALIZED:\n        try:\n            nvmlInit()\n            NVML_INITIALIZED = True\n            logger.info(\"NVML Initialized for GPU monitoring.\")\n        except NVMLError as e:\n            logger.warning(f\"Could not initialize NVML for GPU monitoring. GPU stats will not be available. Error: {e}\")", "source": {"file": "metrics.py", "section": "metrics.py:def initialize_nvml(logger: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000005", "domain": "anton_repo", "section_path": ["metrics.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "import time\n\nimport psutil\nfrom typing import Any\n# --- METRICS: Import NVML for GPU stats ---\ntry:\n    from pynvml import *\n\n    NVML_INITIALIZED = False\nexcept ImportError:\n    NVML_INITIALIZED = False\n# --- END METRICS ---\nfrom vllm.third_party.pynvml import nvmlDeviceGetHandleByIndex, nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo, \\\n    NVMLError, nvmlInit\n\n# --- METRICS: Helper class and functions ---\nclass MetricsTracker:\n    \"\"\"A simple class to hold all performance metrics for a single request.\"\"\"\n\n    ", "source": {"file": "metrics.py", "section": "metrics.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000006", "domain": "anton_repo", "section_path": ["prompts.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "# /multi_agent_project/prompts.py\nPARSABLE_STRING = '</think>'\n\nPLANNER_PROMPT = \"\"\"You are a master planner. Your job is to break down a complex user request into a series of logical steps.\nThe user's overall goal is: \"{original_prompt}\"\n\nThe system includes multiple specialized agents with the ability to use the following tools:\n{tools}\n\nAs the planner, you do **not** execute tasks or use tools yourself. Your role is to decide the *next best step* for another expert agent to perform using the available tools.\n\nHere is the history of our conversation:\n{chat_history}\n\nHere is a summary of the work done so far for the current request:\n{completed_steps_summary}\n\nBased on the conversation history and the work done, determine the *single next logical step* to move closer to the user's goal.\nThe step should be a clear, actionable instruction for another expert to execute. IT SHOULD NOT CONTAIN ANY EXTRA VERBIAGE, ONLY OUTPUT THE NEXT IMMEDIATE ACTION\nIf you believe the goal has been fully achieved based on the work done, respond with the single word \"DONE\".\nOtherwise, describe the next step.\n\"\"\"\n\nVERIFIER_PROMPT = \"\"\"\nAs a quality assurance AI, your role is to verify if an assistant's answer fully meets the user's original request.\n\n== USER'S GOAL ==\n{original_prompt}\n\n== ASSISTANT'S ANSWER ==\n{generated_answer}\n\n== INSTRUCTIONS ==\nCarefully compare the \"ASSISTANT'S ANSWER\" against the \"USER'S GOAL\".\nDoes the answer directly and completely address the user's goal?\n\nRespond with a JSON object with two keys: \"is_sufficient\" (boolean) and \"critique\" (string).\n- \"is_sufficient\": true if the answer is complete and accurate, false otherwise.\n- \"critique\": A brief, constructive reason for your decision. If insufficient, explain what is missing.\n\nYour JSON response:\n\"\"\"\n\nANTON_PROMPT = \"\"\"\nYou are Anton, a helpful AI assistant.\nYour goal is to provide a clear, accurate, and helpful response to the user's request.\nUse the background information and conversation history to inform your answer.\n\nBackground Information:\n{background_info}\n\nUser Request:\n{input}\n\nAnswer:\n\"\"\"\n\n\nEXECUTOR_PROMPT = \"\"\"\nYou are a top-tier software engineer and system architect. Your purpose is to execute tasks using the tools at your disposal to achieve the user's goal.\n\nThe user's overall goal is: \"{original_prompt}\"\nThe context from work done in previous steps is:\n{context}\n\nYour current task is: \"{task_to_execute}\"\n\nYou will respond using the ReAct framework. You MUST follow one of the two formats below for your response.\n\n***\n\n**OPTION 1: Use a tool to continue working on the task.**\n\nThis is for when you need to take another step to get closer to the solution. Your response MUST be in this exact format:\n\nThought: <brief reasoning for choosing the tool and planning the next step>\nAction: <one tool name from the tools list>\nAction Input:\n<blank line>\n{{\"arg1\": \"value1\", \"arg2\": \"value2\"}}\n\n-----------------------------------------------\n\n\n**OPTION 2: Provide the final answer to the user.**\n\nUse this option ONLY when the task is fully complete and you have a final result for the user. YOU CAN ABSOLUTELY NOT DO THIS IN THE SAME STEP AS OPTION 1! Your response MUST be in this exact format:\n\nThought: The reasoning that the task is complete and I am ready to provide the final answer.\nFinal Answer: The final, complete answer or result for the user.\n\n***\n\n### CRITICAL RULES TO FOLLOW:\n1.  You MUST choose either OPTION 1 or OPTION 2 in every response. You can NEVER output both an `Action` and a `Final Answer` in the same response.\n2.  The `Action Input` MUST be a single, valid JSON object.\n3.  Only call one tool (`Action`) at a time.\n\nAvailable Tools:\n{tools}\n\nTool Names: {tool_names}\n\nREMEMBER TO NOT HAVE BOTH A THOUGHT AND A FINAL ANSWER IN THE SAME RESPONSE!! NO MATTER WHAT, STICK TO ONLY OPTION 1 OR OPTION 2!!!\n\nBegin!\n\nAgent Scratchpad:\n{agent_scratchpad}\n\"\"\"\n\n\n\nSUMMARIZER_PROMPT = \"\"\"You are a helpful summarizer. Your job is to synthesize a series of steps and results into a final, clean answer for the user.\nThe user's original request was: \"{original_prompt}\"\n\nHere is a summary of the plan and the results of each step:\n{full_context}\n\nPlease provide a comprehensive, final answer to the user based on this information. Format the answer clearly and concisely.\n\"\"\"\n\nORCHESTRATOR_PROMPT = \"\"\"\nBased on the original user request and the work done so far, has the user's goal been fully achieved? If not, did the agent underperform? \n\nOriginal Request:\n{original_prompt}\n\nWork Completed (Plan & Result):\n{completed_steps_summary}\n\nRespond with only the word \"YES\" if the goal is fully achieved, \"ERROR\" if the agent failed to complete the task or completed the task inefficiently, otherwise respond with \"NO\".\n\"\"\"\n\nCODE_REVIEWER = \"\"\"\nYou are currently helping a user at the moment, however you seem to be having a bit of trouble. \n\nReview your own source code to identify weaknesses, inefficiencies, or architectural issues. Focus on areas where your logic, maintainability, performance, or modularity could be improved.\n\nOnce weak points are identified, propose specific code changes to address them. Justify each change clearly.\n\nThen, implement the changes using a standard Git workflow:\n\nCreate a new branch based on the current main state.\n\nApply the changes with descriptive commits.\n\nOpen a pull request summarizing what was changed and why.\n\nYour task is complete when the pull request has been created and contains all proposed improvements. Be honest, objective, and proactive—treat this as a critical code review of your own intelligence.\n\nHere is the conversation history\n---------------------------\n\"\"\"\n\n\nCODE_REVIEWER_PROMPT = \"\"\"\nYou are an expert AI software engineer and a master of prompt engineering. Your task is to act as a meticulous code reviewer for an AI multi-agent project. You will analyze the provided source code and identify weaknesses, bugs, and areas for improvement.\n\nYour primary goal is to enhance the project's robustness, efficiency, and performance. Pay close attention to the following areas:\n\n1.  **Prompt Engineering:**\n    * **Clarity & Specificity:** Are the prompts clear, specific, and unambiguous? Do they effectively guide the LLM to the desired output?\n    * **Role-Playing:** Is the role assigned to the LLM well-defined and consistent?\n    * **Context:** Is all necessary context provided? Is there any extraneous information that could be confusing?\n    * **Structure:** Could the prompt be structured better (e.g., using headings, lists, or examples) to improve performance?\n\n2.  **Agent Logic & Control Flow:**\n    * **Error Handling:** Does the code gracefully handle potential errors or unexpected LLM outputs?\n    * **Edge Cases:** Are there any unhandled edge cases in the agent's logic?\n    * **Efficiency:** Can the logic be simplified or made more efficient?\n\n3.  **Overall Code Quality:**\n    * **Readability:** Is the code clean, well-commented, and easy to understand?\n    * **Best Practices:** Does the code adhere to common Python and AI engineering best practices?\n\n**Review the following file:**\n- **File Path:** `{file_path}`\n- **Chat History (for context):**\n{chat_history}\n\n**Source Code:**\n```python\n{source_code}\n```\n\n**Instructions:**\nAfter your review, provide your feedback as a JSON object. The object should contain a single key, \"suggestions\", which is a list of suggestion objects.\n\n- If you find no issues, return an empty list: `{\"suggestions\": []}`.\n- For each issue you identify, create a suggestion object with the following keys:\n  - `line_start`: The starting line number of the code to be changed.\n  - `line_end`: The ending line number of the code to be changed.\n  - `original_code`: The exact block of original code that needs improvement.\n  - `suggested_code`: The new code you propose to replace the original block.\n  - `reasoning`: A clear and concise explanation of why the change is necessary and what weakness it addresses.\n\nYour response MUST be only the JSON object and nothing else.\n\"\"\"", "source": {"file": "prompts.py", "section": "prompts.py:FULL"}, "tags": ["anton_repo"]}
{"id": "b0000007", "domain": "anton_repo", "section_path": ["app.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def on_chat_start():\n    \"\"\"Initializes the assistant and its memory when a new chat session starts.\"\"\"\n    cl.user_session.set(\"anton\", AntonClient())\n    cl.user_session.set(\"chat_history\", [])\n\n\n@cl.on_message\nasync ", "source": {"file": "app.py", "section": "app.py:def on_chat_start()"}, "tags": ["anton_repo"]}
{"id": "b0000008", "domain": "anton_repo", "section_path": ["app.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def on_message(message: cl.Message):\n    \"\"\"\n    Handles incoming messages, streams thoughts and the final response,\n    and learns from the exchange.\n    \"\"\"\n    anton: AntonClient = cl.user_session.get(\"anton\")\n    chat_history: List[Dict] = cl.user_session.get(\"chat_history\")\n\n    final_answer = \"\"\n    answer_msg = None  # create on first token so the Thinking step appears first\n    # Buffer to accumulate the content of a single thought.\n    thought_buffer = \"\"\n\n    # By creating the Step first, it will appear at the top.\n    async with cl.Step(name=\"Thinking\", parent_id=message.id) as step:\n        try:\n            async for chunk in anton.stream_response(\n                user_prompt=message.content, chat_history=chat_history\n            ):\n                # If the chunk is part of a thought, add it to the buffer.\n                if chunk[\"type\"] == \"thought\":\n                    thought_buffer += chunk[\"content\"]\n                # If a new chunk type arrives, the previous thought is complete.\n                # Flush the buffered thought before processing the new chunk.\n                else:\n                    if thought_buffer:\n                        await step.stream_token(f\"• {thought_buffer}\\n\")\n                        thought_buffer = \"\"  # Reset buffer for the next thought\n\n                    # Process the non-thought chunk.\n                    if chunk[\"type\"] == \"tool_result\":\n                        result_str = (\n                            f\"\\n*Tool Result:*\\n```json\\n{chunk['content']}\\n```\\n\"\n                        )\n                        await step.stream_token(result_str)\n\n                    elif chunk[\"type\"] == \"token\":\n                        token = html.unescape(chunk[\"content\"])  # keep markdown; html entities only\n                        if answer_msg is None:\n                            answer_msg = cl.Message(content=\"\", author=\"Anton\", parent_id=message.id)\n                            await answer_msg.send()\n                        await answer_msg.stream_token(token)\n                        final_answer += token\n            \n            # After the loop, flush any final thought that might be in the buffer.\n            if thought_buffer:\n                await step.stream_token(f\"• {thought_buffer}\\n\")\n\n        finally:\n            # Ensure the final message content is committed\n            if answer_msg:\n                await answer_msg.update()\n\n    # Update the session's chat history.\n    chat_history.append({\"role\": \"user\", \"content\": message.content})\n    chat_history.append({\"role\": \"assistant\", \"content\": final_answer})\n    cl.user_session.set(\"chat_history\", chat_history)", "source": {"file": "app.py", "section": "app.py:def on_message(message: cl.Message)"}, "tags": ["anton_repo"]}
{"id": "b0000009", "domain": "anton_repo", "section_path": ["app.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "import html\nfrom typing import List, Dict\n\nimport chainlit as cl\n\nfrom client.anton_client import AntonClient\n\n@cl.on_chat_start\nasync ", "source": {"file": "app.py", "section": "app.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000010", "domain": "anton_repo", "section_path": ["chainlit.toml"], "page": 1, "block_index": 1, "block_type": "code", "text": "[project]\nname = \"Anton\"\ndescription = \"Anton Assistant with ReAct and knowledge graph\"\n\n[UI]\n# Enable LaTeX/KaTeX rendering for $...$ and $$...$$ in Markdown outputs\n# Supported in recent Chainlit versions. If your version uses a different key, I can adjust.\nmarkdown = true\nlatex = true\n\n[features]\n# Keep streaming enabled\ncontinuous_streaming = true\n", "source": {"file": "chainlit.toml", "section": "chainlit.toml:1-14"}, "tags": ["anton_repo"]}
{"id": "b0000011", "domain": "anton_repo", "section_path": ["chainlit.md"], "page": 1, "block_index": 1, "block_type": "code", "text": "# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n\n## Welcome screen\n\nTo modify the welcome screen, edit the `chainlit.md` file at the root of your project. If you do not want a welcome screen, just leave this file empty.\n", "source": {"file": "chainlit.md", "section": "chainlit.md:1-15"}, "tags": ["anton_repo"]}
{"id": "b0000012", "domain": "anton_repo", "section_path": ["README.md"], "page": 1, "block_index": 1, "block_type": "code", "text": "# Anton - Intelligent Assistant\n\nAnton is an advanced AI assistant that leverages the ReAct (Reason-Act) pattern to provide accurate and helpful responses. Using a combination of code analysis, knowledge retrieval, and tool-based actions, Anton can assist with a wide range of technical and creative tasks.\n\n## Features\n- **ReAct Pattern**: Reason through problems before taking action\n- **Codebase Access**: Analyze and interact with source code using built-in tools\n- **File Operations**: Read, write, and manage files within the project\n- **Git Integration**: Commit, branch, and push changes via Git commands\n- **Knowledge Retrieval**: Access extensive knowledge base for quick answers\n\n## Usage\nSimply ask Anton a question or request a task. Anton will handle the reasoning and actions needed to fulfill your request.\n\n**Example:**\n```\nUser: Can you create a README file for me?\nAnton: (Reasons about needing to write a README.md, then uses write_file tool)\n```\n\n## Contributing\nContributions to Anton are welcome! Please open an issue or submit a pull request on GitHub.\n\n## License\nThis project is licensed under the MIT License.", "source": {"file": "README.md", "section": "README.md:1-25"}, "tags": ["anton_repo"]}
{"id": "b0000013", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def normalize_text(s: str) -> str:\n    s = unicodedata.normalize(\"NFC\", s)\n    s = SOFT_HYPHEN_RE.sub(\"\", s)\n    # fix hyphenation across line breaks (basic heuristic)\n    s = HARD_HYPHEN_BREAK_RE.sub(r\"\\1\\2\", s)\n    s = LINE_HYPHEN_END_RE.sub(r\"\\1\", s)\n    # collapse spaces\n    s = WHITESPACE_RE.sub(\" \", s)\n    # join harmless single newlines\n    s = JOIN_NL_RE.sub(\" \", s)\n    # collapse huge blank runs\n    s = MULTI_NL_RE.sub(\"\\n\\n\", s)\n    return s.strip()\n\n# ---------- Data structures ----------\n\n@dataclass\nclass SectionNode:\n    id: str\n    title: str\n    level: int\n    start_page: int\n    end_page: Optional[int] = None\n    index: int = 0\n    children: List[\"SectionNode\"] = field(default_factory=list)\n\n    ", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def normalize_text(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000014", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"id\": self.id,\n            \"title\": self.title,\n            \"level\": self.level,\n            \"start_page\": self.start_page,\n            \"end_page\": self.end_page,\n            \"index\": self.index,\n            \"children\": [c.to_dict() for c in self.children],\n        }\n\n@dataclass\nclass BlockRecord:\n    id: str\n    domain: str\n    section_path: List[str]\n    page: int\n    block_index: int\n    block_type: str  # \"paragraph\" | \"example\" | \"exercise\" | \"definition\" | \"theorem\" | \"remark\" | \"figure\" | \"unknown\"\n    text: str\n    source: Dict[str, Any]\n    tags: List[str] = field(default_factory=list)\n\n    ", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def to_dict(self)"}, "tags": ["anton_repo"]}
{"id": "b0000015", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def to_json(self) -> str:\n        return json.dumps(asdict(self), ensure_ascii=False)\n\n# ---------- Heuristics & helpers ----------\n\nHEADING_NUMBER_RE = re.compile(r\"^\\s*(?:Chapter\\s+\\d+|Appendix\\s+[A-Z]|[\\dIVX]+(?:\\.\\d+){0,3})\\b\", re.IGNORECASE)\nLABEL_CLASS_RE = [\n    (re.compile(r\"^\\s*Example\\b\", re.IGNORECASE), \"example\"),\n    (re.compile(r\"^\\s*Exercise\\b\", re.IGNORECASE), \"exercise\"),\n    (re.compile(r\"^\\s*Definition\\b\", re.IGNORECASE), \"definition\"),\n    (re.compile(r\"^\\s*Theorem\\b\", re.IGNORECASE), \"theorem\"),\n    (re.compile(r\"^\\s*Remark\\b\", re.IGNORECASE), \"remark\"),\n    (re.compile(r\"^\\s*Figure\\b\", re.IGNORECASE), \"figure\"),\n]\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def to_json(self)"}, "tags": ["anton_repo"]}
{"id": "b0000016", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def slugify(s: str) -> str:\n    s = unicodedata.normalize(\"NFKD\", s)\n    s = re.sub(r\"[^\\w\\s-]\", \"\", s).strip().lower()\n    s = re.sub(r\"[\\s_-]+\", \"-\", s)\n    return s[:64] or \"untitled\"\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def slugify(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000017", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def detect_headers_footers(doc: \"fitz.Document\", sample_pages: int = 30) -> Tuple[Dict[int, str], Dict[int, str]]:\n    \"\"\"\n    Identify repeated header/footer lines by sampling pages.\n    Returns maps: page_index -> header_text/footer_text to strip if present.\n    \"\"\"\n    total = len(doc)\n    idxs = list(range(0, min(sample_pages, total)))\n    top_counts: Dict[str, int] = {}\n    bot_counts: Dict[str, int] = {}\n\n    for i in idxs:\n        page = doc[i]\n        text_lines = page.get_text(\"text\").splitlines()\n        if not text_lines:\n            continue\n        # Take probable header/footer candidates (first and last non-blank lines)\n        header = next((l.strip() for l in text_lines[:5] if l.strip()), \"\")\n        footer = next((l.strip() for l in reversed(text_lines[-5:]) if l.strip()), \"\")\n        if header:\n            top_counts[header] = top_counts.get(header, 0) + 1\n        if footer:\n            bot_counts[footer] = bot_counts.get(footer, 0) + 1\n\n    # Consider lines that appear on >= 40% of sampled pages as header/footer\n    thresh = max(2, int(0.4 * len(idxs)))\n    headers = {k: k for k, c in top_counts.items() if c >= thresh}\n    footers = {k: k for k, c in bot_counts.items() if c >= thresh}\n    return headers, footers\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def detect_headers_footers(doc: \"fitz.Document\", sample_pages: int = 30)"}, "tags": ["anton_repo"]}
{"id": "b0000018", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def extract_toc_sections(doc: \"fitz.Document\") -> List[SectionNode]:\n    toc = doc.get_toc(simple=False) or doc.get_toc()\n    nodes: List[SectionNode] = []\n    stack: List[SectionNode] = []\n\n    if not toc:\n        return nodes\n\n    for idx, entry in enumerate(toc, start=1):\n        if isinstance(entry, dict):\n            level = entry.get(\"level\", 1)\n            title = entry.get(\"title\", \"\").strip() or f\"Section {idx}\"\n            page = max(1, entry.get(\"page\", 1))\n        else:\n            level, title, page = entry[0], entry[1].strip(), max(1, entry[2])\n\n        node = SectionNode(\n            id=f\"s{idx:04d}-{slugify(title)}\",\n            title=title,\n            level=level,\n            start_page=page,\n            index=idx,\n        )\n\n        # attach by level\n        while stack and stack[-1].level >= level:\n            stack.pop()\n        if stack:\n            stack[-1].children.append(node)\n        else:\n            nodes.append(node)\n        stack.append(node)\n\n    # fill end_page by next start\n    flat = flatten_sections(nodes)\n    for i, n in enumerate(flat):\n        n.end_page = (flat[i + 1].start_page - 1) if i + 1 < len(flat) else len(doc)\n    return nodes\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def extract_toc_sections(doc: \"fitz.Document\")"}, "tags": ["anton_repo"]}
{"id": "b0000019", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def flatten_sections(nodes: List[SectionNode]) -> List[SectionNode]:\n    out: List[SectionNode] = []\n    ", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def flatten_sections(nodes: List[SectionNode])"}, "tags": ["anton_repo"]}
{"id": "b0000020", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def _walk(n: SectionNode):\n        out.append(n)\n        for c in n.children:\n            _walk(c)\n    for n in nodes:\n        _walk(n)\n    return out\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def _walk(n: SectionNode)"}, "tags": ["anton_repo"]}
{"id": "b0000021", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def infer_sections_by_font(doc: \"fitz.Document\") -> List[SectionNode]:\n    \"\"\"\n    Fallback if no ToC: detect headings by large font spans and numbering patterns.\n    \"\"\"\n    candidates: List[Tuple[int, str, int, float]] = []  # (idx, title, page, size)\n    idx = 0\n    for pno in range(len(doc)):\n        page = doc[pno]\n        blocks = page.get_text(\"dict\")[\"blocks\"]\n        for b in blocks:\n            for l in b.get(\"lines\", []):\n                for s in l.get(\"spans\", []):\n                    text = s.get(\"text\", \"\").strip()\n                    if not text:\n                        continue\n                    size = float(s.get(\"size\", 0.0))\n                    if size >= 14.0 or HEADING_NUMBER_RE.search(text):\n                        # Keep short-ish heading candidates\n                        if len(text) <= 140:\n                            idx += 1\n                            candidates.append((idx, text, pno + 1, size))\n\n    # keep top-k percentile by size per page, dedupe near-duplicates\n    candidates.sort(key=lambda t: (t[2], -t[3]))  # by page, desc size\n    filtered: List[Tuple[int, str, int, float]] = []\n    seen_on_page: Dict[int, str] = {}\n    for i, text, page, size in candidates:\n        if page in seen_on_page:\n            # keep the largest one per page\n            continue\n        seen_on_page[page] = text\n        filtered.append((i, text, page, size))\n\n    nodes: List[SectionNode] = []\n    for i, text, page, size in filtered:\n        title = text\n        level = 1 if HEADING_NUMBER_RE.search(title) else 2\n        nodes.append(SectionNode(\n            id=f\"s{i:04d}-{slugify(title)}\",\n            title=title,\n            level=level,\n            start_page=page,\n            index=i,\n        ))\n\n    # sort by page then set end pages\n    nodes.sort(key=lambda n: (n.start_page, n.level))\n    flat = nodes\n    for i, n in enumerate(flat):\n        n.end_page = (flat[i + 1].start_page - 1) if i + 1 < len(flat) else len(doc)\n\n    # nest simple: level 1 are parents, others children\n    roots: List[SectionNode] = []\n    last_root: Optional[SectionNode] = None\n    for n in flat:\n        if n.level <= 1 or last_root is None:\n            roots.append(n)\n            last_root = n\n        else:\n            last_root.children.append(n)\n    return roots\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def infer_sections_by_font(doc: \"fitz.Document\")"}, "tags": ["anton_repo"]}
{"id": "b0000022", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def classify_block(text: str) -> str:\n    head = text.strip().splitlines()[0] if text.strip() else \"\"\n    for pattern, label in LABEL_CLASS_RE:\n        if pattern.search(head):\n            return label\n    return \"paragraph\"\n\n# ---------- Extraction ----------\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def classify_block(text: str)"}, "tags": ["anton_repo"]}
{"id": "b0000023", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def page_text_without_header_footer(page: \"fitz.Page\", headers: Dict[str, str], footers: Dict[str, str]) -> str:\n    raw = page.get_text(\"text\")\n    lines = [ln.rstrip() for ln in raw.splitlines()]\n\n    if lines:\n        # strip header if exact match (best-effort)\n        for h in headers:\n            if lines[0].strip() == h:\n                lines = lines[1:]\n                break\n    if lines:\n        for f in footers:\n            if lines[-1].strip() == f:\n                lines = lines[:-1]\n                break\n\n    return \"\\n\".join(lines)\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def page_text_without_header_footer(page: \"fitz.Page\", headers: Dict[str, str], footers: Dict[str, str])"}, "tags": ["anton_repo"]}
{"id": "b0000024", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def split_into_paragraphs(text: str) -> List[str]:\n    # paragraphs separated by blank line or large indentation reset\n    paras = re.split(r\"\\n\\s*\\n\", text.strip())\n    cleaned = []\n    for p in paras:\n        p = normalize_text(p)\n        if len(p) >= 30:  # ignore too-short fragments\n            cleaned.append(p)\n    return cleaned\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def split_into_paragraphs(text: str)"}, "tags": ["anton_repo"]}
{"id": "b0000025", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def build_section_path(section: SectionNode, roots: List[SectionNode]) -> List[str]:\n    # reconstruct path by walking down from roots\n    path = []\n    ", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def build_section_path(section: SectionNode, roots: List[SectionNode])"}, "tags": ["anton_repo"]}
{"id": "b0000026", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def _walk(current: SectionNode, target: SectionNode, trail: List[str]) -> Optional[List[str]]:\n        t = trail + [current.title]\n        if current is target:\n            return t\n        for c in current.children:\n            got = _walk(c, target, t)\n            if got:\n                return got\n        return None\n    for r in roots:\n        got = _walk(r, section, [])\n        if got:\n            path = got\n            break\n    return path or [section.title]\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def _walk(current: SectionNode, target: SectionNode, trail: List[str])"}, "tags": ["anton_repo"]}
{"id": "b0000027", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def emit_blocks(doc: \"fitz.Document\", roots: List[SectionNode], domain: str, out_jsonl: Path, src_file: str):\n    headers, footers = detect_headers_footers(doc)\n    block_id_counter = 0\n    with out_jsonl.open(\"w\", encoding=\"utf-8\") as fw:\n        flat = flatten_sections(roots)\n        for sec in flat:\n            sec_path = build_section_path(sec, roots)\n            start = max(1, sec.start_page)\n            end = min(len(doc), sec.end_page or len(doc))\n            for pno in range(start - 1, end):\n                page = doc[pno]\n                text = page_text_without_header_footer(page, headers, footers)\n                paras = split_into_paragraphs(text)\n                for idx, para in enumerate(paras, start=1):\n                    block_id_counter += 1\n                    btype = classify_block(para)\n                    rec = BlockRecord(\n                        id=f\"b{block_id_counter:07d}\",\n                        domain=domain,\n                        section_path=sec_path,\n                        page=pno + 1,\n                        block_index=idx,\n                        block_type=btype,\n                        text=para,\n                        source={\"file\": os.path.basename(src_file), \"page\": pno + 1, \"section_id\": sec.id},\n                        tags=[domain] if domain else [],\n                    )\n                    fw.write(rec.to_json() + \"\\n\")\n\n# ---------- Main ----------\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def emit_blocks(doc: \"fitz.Document\", roots: List[SectionNode], domain: str, out_jsonl: Path, src_file: str)"}, "tags": ["anton_repo"]}
{"id": "b0000028", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def main():\n    ap = argparse.ArgumentParser(description=\"Study Importer: PDF → outline.json + blocks.jsonl\")\n    ap.add_argument(\"pdf\", type=str, help=\"Path to PDF textbook\")\n    ap.add_argument(\"--outdir\", type=str, required=True, help=\"Output directory (e.g., packs/calc.v1)\")\n    ap.add_argument(\"--domain\", type=str, default=\"\", help=\"Domain tag (e.g., calculus, chess)\")\n    args = ap.parse_args()\n\n    outdir = Path(args.outdir)\n    outdir.mkdir(parents=True, exist_ok=True)\n\n    doc = fitz.open(args.pdf)\n\n    # 1) Sections: ToC if available, else heuristics\n    roots = extract_toc_sections(doc)\n    if not roots:\n        print(\"[info] No ToC found; inferring sections by font/numbering...\", file=sys.stderr)\n        roots = infer_sections_by_font(doc)\n\n    # 2) Persist outline\n    outline_path = outdir / \"outline.json\"\n    with outline_path.open(\"w\", encoding=\"utf-8\") as f:\n        json.dump([r.to_dict() for r in roots], f, ensure_ascii=False, indent=2)\n\n    # 3) Emit blocks\n    blocks_path = outdir / \"blocks.jsonl\"\n    emit_blocks(doc, roots, args.domain or \"\", blocks_path, args.pdf)\n\n    print(f\"[ok] Wrote {outline_path}\")\n    print(f\"[ok] Wrote {blocks_path}\")\n    print(\"[next] Feed blocks.jsonl to your concept extractor (Step 2).\")\n\nif __name__ == \"__main__\":\n    main()\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000029", "domain": "anton_repo", "section_path": ["learning/pdf_importer.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "# study_importer.py\n# Usage:\n#   pip install pymupdf==1.24.7\n#   python study_importer.py INPUT.pdf --outdir packs/calc.v1 --domain calculus\n#\n# Outputs:\n#   packs/calc.v1/outline.json\n#   packs/calc.v1/blocks.jsonl\n\nimport argparse\nimport json\nimport os\nimport re\nimport sys\nimport unicodedata\nfrom dataclasses import dataclass, asdict, field\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple, Dict, Any\n\ntry:\n    import fitz  # PyMuPDF\nexcept Exception as e:\n    print(\"PyMuPDF (fitz) is required. Install with: pip install pymupdf==1.24.7\", file=sys.stderr)\n    raise\n\n# ---------- Text utilities ----------\n\nWHITESPACE_RE = re.compile(r\"[ \\t]+\")\nMULTI_NL_RE = re.compile(r\"\\n{3,}\")\nSOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")\nHARD_HYPHEN_BREAK_RE = re.compile(r\"(\\w)-\\n(\\w)\")\nLINE_HYPHEN_END_RE = re.compile(r\"(\\w+)-\\n\")\nJOIN_NL_RE = re.compile(r\"(?<![\\.!?;:])\\n(?=\\w)\")  # join linebreaks not after end punctuation\n\n", "source": {"file": "learning/pdf_importer.py", "section": "learning/pdf_importer.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000030", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def to_json(self) -> str:\n        return json.dumps(asdict(self), ensure_ascii=False)\n\n\n@dataclass\nclass Edge:\n    src: str  # node id\n    dst: str  # node id\n    type: str  # \"depends_on\" | \"analogous_to\" | \"derived_from\" | \"applies_to\"\n    rationale: str\n    confidence: float = 0.0\n    source: Dict[str, Any] = field(default_factory=dict)\n\n    ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def to_json(self)"}, "tags": ["anton_repo"]}
{"id": "b0000031", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def to_json(self) -> str:\n        return json.dumps(asdict(self), ensure_ascii=False)\n\n\n@dataclass\nclass NamedEdge:\n    \"\"\"Temporary edge representation that refers to concepts by NAME.\"\"\"\n    src: str\n    dst: str\n    type: str\n    rationale: str\n    confidence: float\n    source: Dict[str, Any] = field(default_factory=dict)\n\n\n# ----------------- Utilities -----------------\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def to_json(self)"}, "tags": ["anton_repo"]}
{"id": "b0000032", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def slugify(s: str) -> str:\n    s = unicodedata.normalize(\"NFKD\", s)\n    s = re.sub(r\"[^\\w\\s-]\", \"\", s).strip().lower()\n    s = re.sub(r\"[\\s_-]+\", \"-\", s)\n    return s[:96] or \"unnamed\"\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def slugify(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000033", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def stable_node_id(domain: str, name: str) -> str:\n    return f\"{domain}.{slugify(name)}\"\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def stable_node_id(domain: str, name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000034", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def norm_title(s: str) -> str:\n    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def norm_title(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000035", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def chunk_text(paragraphs: List[Dict[str, Any]], max_chars: int) -> List[List[Dict[str, Any]]]:\n    chunks, cur, sz = [], [], 0\n    for p in paragraphs:\n        t = p[\"text\"]\n        if sz and (sz + len(t)) > max_chars:\n            chunks.append(cur)\n            cur, sz = [], 0\n        cur.append(p)\n        sz += len(t) + 1\n    if cur:\n        chunks.append(cur)\n    return chunks\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def chunk_text(paragraphs: List[Dict[str, Any]], max_chars: int)"}, "tags": ["anton_repo"]}
{"id": "b0000036", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def coalesce_pages(blocks: List[Dict[str, Any]]) -> List[int]:\n    return sorted(set([b[\"page\"] for b in blocks]))\n\n\n# ----------------- LLM Client -----------------\n\nclass LLMClient:\n    ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def coalesce_pages(blocks: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000037", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base: str, temperature: float = 0.6, request_timeout: float = 3600.0, retries: int = 2):\n        self.api_base = api_base.rstrip(\"/\")\n        self.temperature = temperature\n        self.request_timeout = request_timeout\n        self.retries = retries\n\n    async ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def __init__(self, api_base: str, temperature: float = 0.6, request_timeout: float = 3600.0, retries: int = 2)"}, "tags": ["anton_repo"]}
{"id": "b0000038", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def chat_json(self, system_prompt: str, user_prompt: str, model: Optional[str] = None) -> str:\n        \"\"\"\n        Calls your streaming endpoint and returns the visible answer (no SSE metadata).\n        If the model emits <think>…</think>, we discard it and keep only the content after </think>.\n        \"\"\"\n        payload = {\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ],\n            \"temperature\": self.temperature,\n            \"model\": model or QWEN_30B_INSTRUCT,\n        }\n\n        backoff = 1.0\n        for attempt in range(self.retries + 1):\n            t0 = time.perf_counter()\n            try:\n                timeout = httpx.Timeout(self.request_timeout)\n                async with httpx.AsyncClient(timeout=timeout) as client:\n                    async with client.stream(\"POST\", f\"{self.api_base}/v1/chat/stream\", json=payload) as response:\n                        response.raise_for_status()\n\n                        full_response_content = \"\"\n                        # Iterate over the streamed chunks\n                        async for chunk in response.aiter_text():\n                            for line in chunk.split('\\n'):\n                                if line.startswith('data: '):\n                                    content = line[6:]  # Remove 'data: ' prefix\n                                    if content == '[DONE]':\n                                        # End of stream marker; continue to finalize below\n                                        continue\n                                    full_response_content += content\n                                elif line.strip():\n                                    # Fallback for non-SSE format\n                                    full_response_content += line\n\n                think_split = full_response_content.split('</think>', 1)\n                if len(think_split) > 1:\n                    text = think_split[1]\n                else:\n                    text = full_response_content\n                dur = time.perf_counter() - t0\n                logger.debug(\"LLM call ok in %.2fs (attempt %d)\", dur, attempt + 1)\n                return text.strip()\n            except Exception as e:\n                dur = time.perf_counter() - t0\n                logger.warning(\"LLM call failed in %.2fs (attempt %d/%d): %s\", dur, attempt + 1, self.retries + 1, str(e))\n                if attempt >= self.retries:\n                    logger.exception(\"LLM request failed (final)\")\n                    raise\n                await asyncio.sleep(backoff + random.random() * 0.25)\n                backoff = min(backoff * 2, 8.0)\n\n\n# ----------------- Prompts -----------------\n\nSYSTEM_PROMPT = \"\"\"You extract formal knowledge from mixed sources (code files, configs, docs, commit diffs, issues) into a compact graph.\nReturn STRICT JSON ONLY that matches the schema. Do NOT include notes, prose, explanations, or markdown.\n\nSchema:\n{\n  \"concepts\": [\n    {\n      \"type\": \"concept|definition|rule|algorithm|theorem\",\n      \"name\": \"<short, canonical title>\",\n      \"summary\": \"<2-4 sentences, plain text>\",\n      \"formal\": \"<LaTeX OR plain formula OR precise signature/contract (e.g., `", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def chat_json(self, system_prompt: str, user_prompt: str, model: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000039", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def func(a: int) -> str`, CLI syntax, regex, AST/CST pattern, complexity) OR null>\",\n      \"examples\": [{\"input\":\"<minimal before/call/example>\", \"output\":\"<after/return/result>\"}],\n      \"synonyms\": [\"...\", \"...\"],\n      \"confidence\": 0.0_to_1.0\n    }\n  ],\n  \"edges\": [\n    {\n      \"src\": \"<name of source concept>\",\n      \"dst\": \"<name of target concept>\",\n      \"type\": \"depends_on|analogous_to|derived_from|applies_to\",\n      \"rationale\": \"<1 sentence why>\",\n      \"confidence\": 0.0_to_1.0\n    }\n  ]\n}\n\nMapping guidance (important):\n- Code APIs (functions/methods/classes) → usually \"algorithm\" (procedures) or \"definition\" (types/data structures).\n- Conventions/policies (lint rules, typing rules, error-handling patterns) → \"rule\".\n- Refactors/codemods (pattern→replacement, API migrations) → \"algorithm\" (procedure) or \"rule\" (policy).\n- Config keys/schemas → \"definition\" (what it is) + \"rule\" for constraints/allowed values.\n- Tests/specs → capture as \"rule\" (contract) and put minimal I/O as examples.\n\nHow to fill fields:\n- name: concise + canonical (e.g., \"Slugify\", \"LibCST Rename Call\", \"Retry Policy\").\n- formal: prefer exact signatures/contracts/patterns (type hints, CLI grammar, regex, AST patterns, Big-O).\n- examples:\n  - For pure functions: \"input\" = call/args; \"output\" = return.\n  - For refactors/migrations: \"input\" = BEFORE snippet; \"output\" = AFTER snippet.\n  - For CLI/config: \"input\" = command/config; \"output\" = expected effect/result.\n- edges:\n  - depends_on: uses/imports/calls/requires/precondition.\n  - derived_from: transformation/migration based on or generalization of another rule/API.\n  - applies_to: rule/policy applies to a target (e.g., linter rule → code style; test/spec → API).\n  - analogous_to: alternative API/pattern with similar purpose.\n\nNoise & scope rules:\n- Ignore license banners, changelog boilerplate, autogenerated files, vendor deps, duplicated code.\n- Only include high-signal, reusable rules, APIs, contracts, patterns. Skip trivial syntax explanations.\n- If nothing meaningful is present, return {\"concepts\": [], \"edges\": []}.\n\nOutput rules:\n- Output VALID JSON ONLY per schema.\n- No code fences, no markdown, no commentary.\n\"\"\"\n\n\nUSER_PROMPT_TEMPLATE = \"\"\"Extract concepts and dependencies from this repository/documentation slice.\nFollow the JSON schema in the system prompt exactly. ONLY output JSON — no extra text.\n\nDomain: {domain}\nSection path: {section_path}\nPages/Lines: {pages}\n\nFocus:\n- Capture APIs, contracts, invariants, typing/lint/security rules, refactor/codemod patterns, config schemas.\n- Prefer minimal I/O pairs for examples (function calls, before→after diffs, command→result).\n- Map code/test/config relationships to the allowed edge types (depends_on, derived_from, applies_to, analogous_to).\n\nTEXT:\n\"\"\"\n# The chunk text will be appended after the blank line above.\n\n\n# ----------------- Extraction orchestration -----------------\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def func(a: int)"}, "tags": ["anton_repo"]}
{"id": "b0000040", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def load_blocks(blocks_path: Path) -> List[Dict[str, Any]]:\n    out = []\n    with blocks_path.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            out.append(json.loads(line))\n    return out\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def load_blocks(blocks_path: Path)"}, "tags": ["anton_repo"]}
{"id": "b0000041", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def group_by_section(blocks: List[Dict[str, Any]]) -> Dict[Tuple[str, ...], List[Dict[str, Any]]]:\n    groups: Dict[Tuple[str, ...], List[Dict[str, Any]]] = {}\n    for b in blocks:\n        key = tuple(b.get(\"section_path\") or [])\n        groups.setdefault(key, []).append(b)\n    # Preserve order by page then block_index\n    for k in groups:\n        groups[k].sort(key=lambda x: (x[\"page\"], x.get(\"block_index\", 0)))\n    return groups\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def group_by_section(blocks: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000042", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def build_user_prompt(domain: str, section_path: List[str], pages: List[int], chunk_blocks: List[Dict[str, Any]]) -> str:\n    header = USER_PROMPT_TEMPLATE.format(\n        domain=domain,\n        section_path=\" > \".join(section_path),\n        pages=f\"{min(pages)}–{max(pages)}\",\n    )\n    text = []\n    for b in chunk_blocks:\n        prefix = f\"[{b.get('block_type','paragraph').upper()} p.{b['page']}] \"\n        text.append(prefix + b[\"text\"])\n    return header + \"\\n\".join(text)\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def build_user_prompt(domain: str, section_path: List[str], pages: List[int], chunk_blocks: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000043", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def try_json_load(s: str) -> Optional[Dict[str, Any]]:\n    s = s.split(\"</think>\")[1] if len(s.split(\"</think>\")) > 1 else s\n    s = s.strip()\n    try:\n        x= json.loads(s)\n        logger.info('Successfully loaded initial JSON')\n        return x\n    except Exception:\n        pass\n    logger.info('Failed initial load json from: ' + s[:100] + ' ....')\n    # Extract the largest plausible JSON object/array substring\n    first_brace = s.find(\"{\")\n    last_brace = s.rfind(\"}\")\n    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:\n        candidate = s[first_brace:last_brace + 1]\n        try:\n            x= json.loads(candidate)\n            logger.info('Successfully loaded secondary JSON')\n            return x\n        except Exception:\n            pass\n    first_bracket = s.find(\"[\")\n    last_bracket = s.rfind(\"]\")\n    if first_bracket != -1 and last_bracket != -1 and last_bracket > first_bracket:\n        candidate = s[first_bracket:last_bracket + 1]\n        try:\n            x= json.loads(candidate)\n            logger.info('Successfully loaded tertiary JSON')\n            return x\n        except Exception:\n            pass\n    logger.info('Failed loading tertiary JSON')\n    return None\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def try_json_load(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000044", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def dedupe_keep_best(nodes: List[Node]) -> List[Node]:\n    by_key: Dict[str, Node] = {}\n    ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def dedupe_keep_best(nodes: List[Node])"}, "tags": ["anton_repo"]}
{"id": "b0000045", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def key(n: Node) -> str:\n        return norm_title(n.name)\n    for n in nodes:\n        k = key(n)\n        if k not in by_key:\n            by_key[k] = n\n        else:\n            cur = by_key[k]\n            if n.confidence > cur.confidence:\n                cur.summary = n.summary or cur.summary\n                cur.formal = n.formal or cur.formal\n                cur.type = n.type or cur.type\n                cur.confidence = n.confidence\n            # merge examples\n            seen_ex = set((e.get(\"input\",\"\"), e.get(\"output\",\"\")) for e in cur.examples)\n            for e in n.examples:\n                tup = (e.get(\"input\",\"\"), e.get(\"output\",\"\"))\n                if tup not in seen_ex and any(tup):\n                    cur.examples.append(e)\n                    seen_ex.add(tup)\n            cur.synonyms = sorted(set(cur.synonyms + n.synonyms))\n            cur.tags = sorted(set(cur.tags + n.tags))\n            # merge pages\n            cur.source.setdefault(\"pages\", [])\n            for p in n.source.get(\"pages\", []):\n                if p not in cur.source[\"pages\"]:\n                    cur.source[\"pages\"].append(p)\n    return list(by_key.values())\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def key(n: Node)"}, "tags": ["anton_repo"]}
{"id": "b0000046", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "def normalize_edges(named_edges: List[NamedEdge], name_to_id: Dict[str, str]) -> List[Edge]:\n    out: List[Edge] = []\n    seen = set()\n    for e in named_edges:\n        src_key = norm_title(e.src)\n        dst_key = norm_title(e.dst)\n        if src_key not in name_to_id or dst_key not in name_to_id:\n            continue\n        src_id = name_to_id[src_key]\n        dst_id = name_to_id[dst_key]\n        key = (src_id, dst_id, e.type)\n        if key in seen:\n            continue\n        seen.add(key)\n        out.append(Edge(src=src_id, dst=dst_id, type=e.type, rationale=e.rationale, confidence=e.confidence, source=e.source))\n    return out\n\n\n# ----------------- Main async pipeline -----------------\n\nasync def process_section(\n    section_key: Tuple[str, ...],\n    section_blocks: List[Dict[str, Any]],\n    domain: str,\n    api: str,\n    max_chars: int,\n    temperature: float,\n    chunk_concurrency: int,\n    request_timeout: float,\n    retries: int,\n    global_llm_sem: asyncio.Semaphore\n) -> Tuple[List[Node], List[Edge]]:\n    client = LLMClient(api_base=api, temperature=temperature, request_timeout=request_timeout, retries=retries)\n    chunks = chunk_text(section_blocks, max_chars=max_chars)\n    total = len(chunks)\n    all_nodes: List[Node] = []\n    all_named_edges: List[NamedEdge] = []\n\n    chunk_sem = asyncio.Semaphore(max(1, min(chunk_concurrency, total)))\n\n    async ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def normalize_edges(named_edges: List[NamedEdge], name_to_id: Dict[str, str])"}, "tags": ["anton_repo"]}
{"id": "b0000047", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 18, "block_index": 1, "block_type": "code", "text": "def process_chunk(i: int, chunk: List[Dict[str, Any]]) -> Tuple[List[Node], List[NamedEdge]]:\n        async with chunk_sem:\n            pages = coalesce_pages(chunk)\n            prompt = build_user_prompt(domain, list(section_key), pages, chunk)\n            t0 = time.perf_counter()\n            try:\n                # Global limiter here:\n                async with global_llm_sem:\n                    logger.info(\n                        \"Starting chunk %d/%d for section '%s'\", i + 1, total, \" > \".join(section_key)\n                    )\n                    # Pass 1: thinking model\n                    raw_think = await client.chat_json(SYSTEM_PROMPT, prompt, model=QWEN_30B_THINKING)\n                data = normalize_extractor_json(try_json_load(raw_think))\n                if data is None:\n                    # Pass 2: instruct model converts the thinking trace into strict JSON\n                    if not raw_think or not raw_think.strip():\n                        # If the thinking pass produced nothing, try instruct on the original prompt\n                        async with global_llm_sem:\n                            raw_instr = await client.chat_json(SYSTEM_PROMPT, prompt, model=QWEN_30B_INSTRUCT)\n                    else:\n                        fix_msg = (\n                            \"Return ONLY valid JSON (no code fences, no commentary) matching the schema. \"\n                            \"Here is your previous output:\\n\" + raw_think\n                        )\n                        async with global_llm_sem:\n                            raw_instr = await client.chat_json(SYSTEM_PROMPT, fix_msg, model=QWEN_30B_INSTRUCT)\n                    data = normalize_extractor_json(try_json_load(raw_instr))\n\n                # GUARD: if still None, skip this chunk safely\n                if data is None:\n                    logger.warning(\n                        \"JSON parse/normalize failed for section %s pages %s. Skipping chunk.\",\n                        \" > \".join(section_key), pages\n                    )\n                    return [], []\n\n                # Concepts\n                concepts = data.get(\"concepts\", []) or []\n                nodes: List[Node] = []\n                for c in concepts:\n                    name = (c.get(\"name\") or \"\").strip()\n                    if not name:\n                        continue\n                    nodes.append(\n                        Node(\n                            id=\"\",  # filled after dedupe\n                            type=(c.get(\"type\") or \"concept\").lower(),\n                            name=name,\n                            summary=(c.get(\"summary\") or \"\").strip(),\n                            formal=c.get(\"formal\", None),\n                            examples=[e for e in (c.get(\"examples\") or []) if isinstance(e, dict)],\n                            source={\"section_path\": list(section_key), \"pages\": pages},\n                            tags=[domain],\n                            confidence=float(c.get(\"confidence\", 0.0) or 0.0),\n                            synonyms=[s for s in (c.get(\"synonyms\") or []) if isinstance(s, str)],\n                        )\n                    )\n\n                # Edges (keep names for now; map after merging nodes across all chunks)\n                edges_in = data.get(\"edges\", []) or []\n                named_edges: List[NamedEdge] = []\n                for e in edges_in:\n                    src = (e.get(\"src\") or \"\").strip()\n                    dst = (e.get(\"dst\") or \"\").strip()\n                    et = (e.get(\"type\") or \"\").strip().lower()\n                    if not (src and dst and et):\n                        continue\n                    named_edges.append(\n                        NamedEdge(\n                            src=src,\n                            dst=dst,\n                            type=et,\n                            rationale=(e.get(\"rationale\") or \"\").strip(),\n                            confidence=float(e.get(\"confidence\", 0.0) or 0.0),\n                            source={\"section_path\": list(section_key), \"pages\": pages},\n                        )\n                    )\n\n                dur = time.perf_counter() - t0\n                logger.info(\n                    \"Chunk %d/%d for section '%s' done in %.2fs (+%d nodes, +%d edges)\",\n                    i + 1, total, \" > \".join(section_key), dur, len(nodes), len(named_edges),\n                )\n                return nodes, named_edges\n            except Exception:\n                logger.exception(\"Chunk %d/%d failed for section '%s'\", i + 1, total, \" > \".join(section_key))\n                return [], []\n\n    tasks = [asyncio.create_task(process_chunk(i, ch)) for i, ch in enumerate(chunks)]\n    for fut in asyncio.as_completed(tasks):\n        nodes, n_edges = await fut\n        all_nodes.extend(nodes)\n        all_named_edges.extend(n_edges)\n\n    # Merge nodes across chunks, assign stable IDs\n    all_nodes = dedupe_keep_best(all_nodes)\n    for n in all_nodes:\n        n.id = stable_node_id(domain, n.name)\n\n    name_to_id = {norm_title(n.name): n.id for n in all_nodes}\n    all_edges = normalize_edges(all_named_edges, name_to_id)\n\n    return all_nodes, all_edges\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def process_chunk(i: int, chunk: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000048", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 19, "block_index": 1, "block_type": "code", "text": "def normalize_extractor_json(obj):\n    \"\"\"\n    Coerce model output into {\"concepts\":[...], \"edges\":[...]} or return None if impossible.\n    Handles cases where the model returns a top-level list, or wraps inside 'data'/'result'.\n    \"\"\"\n    if obj is None:\n        return None\n\n    # If wrapped in a common container key\n    if isinstance(obj, dict):\n        for k in (\"data\", \"result\", \"output\"):\n            if isinstance(obj.get(k), dict):\n                obj = obj[k]\n                break\n\n        concepts = obj.get(\"concepts\", [])\n        edges = obj.get(\"edges\", [])\n\n        # If concepts given as dict, convert to list\n        if isinstance(concepts, dict):\n            concepts = list(concepts.values())\n        if not isinstance(concepts, list):\n            concepts = []\n\n        if isinstance(edges, dict):\n            edges = list(edges.values())\n        if not isinstance(edges, list):\n            edges = []\n\n        return {\"concepts\": concepts, \"edges\": edges}\n\n    # If the model returned a bare list, assume it's the concepts list\n    if isinstance(obj, list):\n        # sanity check: looks like concept dicts?\n        if all(isinstance(x, dict) for x in obj):\n            return {\"concepts\": obj, \"edges\": []}\n        return None\n\n    return None\n\n\n\nasync ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def normalize_extractor_json(obj)"}, "tags": ["anton_repo"]}
{"id": "b0000049", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 20, "block_index": 1, "block_type": "code", "text": "def main_async(args):\n    blocks = load_blocks(Path(args.blocks))\n    groups = group_by_section(blocks)\n\n    outdir = Path(args.outdir)\n    outdir.mkdir(parents=True, exist_ok=True)\n    nodes_path = outdir / \"nodes.jsonl\"\n    edges_path = outdir / \"edges.jsonl\"\n    progress_path = outdir / \"progress.jsonl\"\n\n    t_start = time.perf_counter()\n\n    # Resume support (optional merge)\n    existing_nodes: Dict[str, Node] = {}\n    existing_edges: set = set()\n    completed_sections: set = set()\n\n    if nodes_path.exists():\n        with nodes_path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                if line.strip():\n                    d = json.loads(line)\n                    existing_nodes[d[\"id\"]] = Node(**d)\n    if edges_path.exists():\n        with edges_path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                if line.strip():\n                    d = json.loads(line)\n                    existing_edges.add((d[\"src\"], d[\"dst\"], d[\"type\"]))\n    if progress_path.exists():\n        with progress_path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                if line.strip():\n                    try:\n                        rec = json.loads(line)\n                        sp = tuple(rec.get(\"section_path\") or [])\n                        if sp:\n                            completed_sections.add(sp)\n                    except Exception:\n                        continue\n\n    # Process sections with bounded concurrency\n    section_sem = asyncio.Semaphore(max(1, args.section_concurrency))\n    completed = 0\n    # Filter out sections already completed\n    pending_items = [(k, v) for k, v in groups.items() if k not in completed_sections]\n    total_sections = len(pending_items)\n    if completed_sections:\n        logger.info(\"Resuming: %d/%d sections already completed; %d pending\", len(completed_sections), len(groups), total_sections)\n\n    global_llm_sem = asyncio.Semaphore(max(1, args.max_inflight))\n    write_lock = asyncio.Semaphore(1)  # Async-safe single-writer for files\n\n    async ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def main_async(args)"}, "tags": ["anton_repo"]}
{"id": "b0000050", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 21, "block_index": 1, "block_type": "code", "text": "def run_one(section_key, section_blocks):\n        async with section_sem:\n            nodes, edges = await process_section(\n                section_key=section_key,\n                section_blocks=section_blocks,\n                domain=args.domain,\n                api=args.api,\n                max_chars=args.max_chars,\n                temperature=args.temperature,\n                chunk_concurrency=args.chunk_concurrency,\n                request_timeout=args.request_timeout,\n                retries=args.retries,\n                global_llm_sem=global_llm_sem,\n            )\n            return section_key, nodes, edges\n\n    task_list = [asyncio.create_task(run_one(k, v)) for k, v in pending_items]\n\n    all_nodes: Dict[str, Node] = existing_nodes.copy()\n    all_edges: set = set(existing_edges)\n\n    for fut in asyncio.as_completed(task_list):\n        try:\n            k, nodes, edges = await fut\n        except Exception:\n            logger.exception(\"Section failed (unknown key)\")\n            k, nodes, edges = (), [], []\n        logger.info(\"Starting section: %s\", \" > \".join(k) or \"(root)\")  # <-- Add here\n        # Merge nodes\n        for n in nodes:\n            if n.id in all_nodes:\n                cur = all_nodes[n.id]\n                if n.confidence > cur.confidence:\n                    cur.summary = n.summary or cur.summary\n                    cur.formal = n.formal or cur.formal\n                    cur.type = n.type or cur.type\n                    cur.confidence = n.confidence\n                # lists\n                seen_ex = set((e.get(\"input\",\"\"), e.get(\"output\",\"\")) for e in cur.examples)\n                for e in n.examples:\n                    tup = (e.get(\"input\",\"\"), e.get(\"output\",\"\"))\n                    if tup not in seen_ex and any(tup):\n                        cur.examples.append(e)\n                        seen_ex.add(tup)\n                cur.synonyms = sorted(set(cur.synonyms + n.synonyms))\n                cur.tags = sorted(set(cur.tags + n.tags))\n                # pages\n                cur.source.setdefault(\"pages\", [])\n                for p in n.source.get(\"pages\", []):\n                    if p not in cur.source[\"pages\"]:\n                        cur.source[\"pages\"].append(p)\n            else:\n                all_nodes[n.id] = n\n\n        # Merge edges\n        for e in edges:\n            key = (e.src, e.dst, e.type)\n            if key not in all_edges:\n                all_edges.add(key)\n\n        # Incremental saving: append only new or improved items and record progress\n        nodes_written = 0\n        edges_written = 0\n        async with write_lock:\n            if nodes:\n                with nodes_path.open(\"a\", encoding=\"utf-8\") as fn:\n                    for n in nodes:\n                        prior = existing_nodes.get(n.id)\n                        should_write = False\n                        if prior is None:\n                            should_write = True\n                        elif n.confidence > prior.confidence:\n                            # Write improved version as a new line; last-win on load\n                            should_write = True\n                        if should_write:\n                            fn.write(n.to_json() + \"\\n\")\n                            existing_nodes[n.id] = n\n                            nodes_written += 1\n            if edges:\n                with edges_path.open(\"a\", encoding=\"utf-8\") as fe:\n                    for e in edges:\n                        key = (e.src, e.dst, e.type)\n                        if key not in existing_edges:\n                            fe.write(e.to_json() + \"\\n\")\n                            existing_edges.add(key)\n                            edges_written += 1\n            # Mark section as completed\n            with progress_path.open(\"a\", encoding=\"utf-8\") as fp:\n                fp.write(json.dumps({\n                    \"section_path\": list(k),\n                    \"nodes_written\": nodes_written,\n                    \"edges_written\": edges_written,\n                    \"timestamp\": time.time(),\n                }) + \"\\n\")\n            completed_sections.add(k)\n\n        completed += 1\n        logger.info(\"Progress: %d/%d sections complete\", completed, total_sections)\n        logger.info(\"Section processed: %s (+%d nodes, +%d edges; wrote %d new nodes, %d new edges)\", \" > \".join(k) or \"(root)\", len(nodes), len(edges), nodes_written, edges_written)\n\n    # Write outputs (deduplicated final snapshot)\n    with nodes_path.open(\"w\", encoding=\"utf-8\") as fn:\n        for n in sorted(all_nodes.values(), key=lambda x: x.id):\n            fn.write(n.to_json() + \"\\n\")\n\n    with edges_path.open(\"w\", encoding=\"utf-8\") as fe:\n        for (src, dst, et) in sorted(all_edges):\n            e = Edge(src=src, dst=dst, type=et, rationale=\"\", confidence=0.0, source={})\n            fe.write(e.to_json() + \"\\n\")\n\n    logger.info(\"Total runtime: %.2fs\", time.perf_counter() - t_start)\n    logger.info(\"Wrote %s\", nodes_path)\n    logger.info(\"Wrote %s\", edges_path)\n    logger.info(\"Next: Step 3 will load nodes/edges and build your Concept Graph / pgvector index.\")\n\n\n# ----------------- CLI -----------------\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def run_one(section_key, section_blocks)"}, "tags": ["anton_repo"]}
{"id": "b0000051", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 22, "block_index": 1, "block_type": "code", "text": "def parse_args():\n    ap = argparse.ArgumentParser(description=\"Step 2: Extract concepts and dependencies with your LLM.\")\n    ap.add_argument(\"blocks\", type=str, help=\"Path to blocks.jsonl from Step 1\")\n    ap.add_argument(\"--outdir\", type=str, required=True, help=\"Output directory (same pack dir)\")\n    ap.add_argument(\"--domain\", type=str, required=True, help=\"Domain tag (e.g., calculus)\")\n    ap.add_argument(\"--api\", type=str, default=\"http://localhost:8001\", help=\"Model server base URL\")\n    ap.add_argument(\"--max-chars\", type=int, default=13986, help=\"Max characters per LLM chunk\")\n    ap.add_argument(\"--temperature\", type=float, default=0.6, help=\"LLM temperature for extraction\")\n    ap.add_argument(\"--section-concurrency\", type=int, default=4, help=\"Parallel sections (beware rate limits)\")\n    ap.add_argument(\"--chunk-concurrency\", type=int, default=4, help=\"Parallel chunks per section\")\n    ap.add_argument(\"--request-timeout\", type=float, default=3600.0, help=\"Per-call timeout seconds\")\n    ap.add_argument(\"--retries\", type=int, default=2, help=\"LLM call retries\")\n    ap.add_argument(\"--max-inflight\", type=int, default=5,\n                help=\"Global cap on simultaneous LLM calls across all sections/chunks\")\n    return ap.parse_args()\n\n\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def parse_args()"}, "tags": ["anton_repo"]}
{"id": "b0000052", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 23, "block_index": 1, "block_type": "code", "text": "def main():\n    '''\n    Example command for calculus: \n    python3 concept_extractor.py packs/calc.v1/blocks.jsonl --outdir packs/calc.v1 --domain calculus --api http://localhost:8000\n    '''\n    args = parse_args()\n    asyncio.run(main_async(args))\n\n\nif __name__ == \"__main__\":\n    main()\n", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000053", "domain": "anton_repo", "section_path": ["learning/concept_extractor.py"], "page": 24, "block_index": 1, "block_type": "code", "text": "# concept_extractor.py\n# Step 2: Concept & Dependency Extractor\n#\n# What it does\n# - Reads blocks.jsonl from Step 1\n# - Groups by section and chunks text\n# - Calls your local LLM streaming endpoint\n# - Produces nodes.jsonl (concepts/rules/etc.) and edges.jsonl (dependencies)\n#\n# Usage\n#   pip install httpx==0.27.0\n#   python concept_extractor.py packs/calc.v1/blocks.jsonl \\\n#     --outdir packs/calc.v1 \\\n#     --domain calculus \\\n#     --api http://localhost:8001 \\\n#     --section-concurrency 2 \\\n#     --chunk-concurrency 3 \\\n#     --request-timeout 120 \\\n#     --retries 2\n#\n# Notes\n# - Uses logger = logging.getLogger(__name__)\n# - Concurrency:\n#     * --section-concurrency limits how many sections process in parallel\n#     * --chunk-concurrency limits parallel LLM calls per section\n# - We never keep chain-of-thought; we extract only structured JSON.\nimport argparse\nimport asyncio\nimport json\nimport logging\nimport random\nimport re\nimport time\nimport unicodedata\nfrom dataclasses import dataclass, asdict, field\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple\nimport httpx\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\nfrom server.config import QWEN_30B_INSTRUCT, QWEN_30B_THINKING\n\nlogging.basicConfig(\n    level=logging.INFO,  # Or logging.DEBUG for more detail\n    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n    handlers=[\n        logging.StreamHandler(),  # Console\n        logging.FileHandler(\"logs/concept_extractor.log\", mode=\"w\", encoding=\"utf-8\"),  # File\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# ----------------- Schema -----------------\n\n@dataclass\nclass Node:\n    id: str\n    type: str          # \"concept\" | \"definition\" | \"rule\" | \"algorithm\" | \"theorem\"\n    name: str\n    summary: str\n    formal: Optional[str]\n    examples: List[Dict[str, str]] = field(default_factory=list)  # [{\"input\": \"...\", \"output\": \"...\"}]\n    source: Dict[str, Any] = field(default_factory=dict)          # {\"pages\":[..], \"section_path\":[..]}\n    tags: List[str] = field(default_factory=list)\n    confidence: float = 0.0\n    synonyms: List[str] = field(default_factory=list)\n\n    ", "source": {"file": "learning/concept_extractor.py", "section": "learning/concept_extractor.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000054", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def read_jsonl(p: Path) -> List[Dict[str, Any]]:\n    items = []\n    with p.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                items.append(json.loads(line))\n    return items\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def read_jsonl(p: Path)"}, "tags": ["anton_repo"]}
{"id": "b0000055", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def compose_node_card(n: Dict[str, Any], max_examples: int) -> str:\n    \"\"\"Compact text that captures each node for embedding & retrieval.\"\"\"\n    lines = [f\"{n.get('name','').strip()} ({n.get('type','concept')})\"]\n    summary = n.get(\"summary\") or \"\"\n    if summary:\n        lines.append(summary.strip())\n    formal = n.get(\"formal\")\n    if formal:\n        lines.append(f\"Formal: {formal}\")\n    # add up to N examples\n    exs = [e for e in (n.get(\"examples\") or []) if isinstance(e, dict)]\n    for e in exs[:max_examples]:\n        inp = (e.get(\"input\") or \"\").strip()\n        out = (e.get(\"output\") or \"\").strip()\n        if inp or out:\n            lines.append(f\"Example: {inp} -> {out}\".strip())\n    return \"\\n\".join([s for s in lines if s])\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def compose_node_card(n: Dict[str, Any], max_examples: int)"}, "tags": ["anton_repo"]}
{"id": "b0000056", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def build_adjacency(edges: List[Dict[str, Any]]) -> Dict[str, Dict[str, List[str]]]:\n    \"\"\"\n    Returns: { edge_type: { src_node_id: [dst_node_id, ...], ... }, ... }\n    \"\"\"\n    adj: Dict[str, Dict[str, List[str]]] = {}\n    for e in edges:\n        et = (e.get(\"type\") or \"\").strip().lower() or \"depends_on\"\n        src = e.get(\"src\")\n        dst = e.get(\"dst\")\n        if not (src and dst):\n            continue\n        bucket = adj.setdefault(et, {})\n        bucket.setdefault(src, []).append(dst)\n    # dedupe lists\n    for et in adj:\n        for s in adj[et]:\n            adj[et][s] = sorted(list(set(adj[et][s])))\n    return adj\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def build_adjacency(edges: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000057", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def infer_pack_name(pack_dir: Path) -> str:\n    # e.g., packs/calc.v1 => calc.v1\n    return pack_dir.name\n\ndef index_pack(\n    pack_dir: Path,\n    model_name: str,\n    index_path: str,\n    docs_path: str,\n    domain_filter: str,\n    max_examples: int,\n    dry_run: bool,\n    test_query: str,\n    topk: int,\n):\n    nodes_path = pack_dir / \"nodes.jsonl\"\n    edges_path = pack_dir / \"edges.jsonl\"\n    if not nodes_path.exists() or not edges_path.exists():\n        raise SystemExit(f\"Missing {nodes_path} or {edges_path}\")\n\n    nodes = read_jsonl(nodes_path)\n    edges = read_jsonl(edges_path)\n\n    pack_name = infer_pack_name(pack_dir)\n\n    # Initialize RAGManager with desired files/model (must happen before another import creates the singleton).\n    rag = RAGManager(model_name=model_name, index_path=index_path, doc_store_path=docs_path)\n\n    # Build adjacency and save alongside the pack\n    adj = build_adjacency(edges)\n    (pack_dir / \"graph_adj.json\").write_text(json.dumps(adj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n    logger.info(\"Saved adjacency: %s\", pack_dir / \"graph_adj.json\")\n\n    # Index nodes into RAG\n    # We'll keep a local mapping from node_id -> vector_id for fast lookup later.\n    node_to_vec: Dict[str, int] = {}\n\n    indexed = 0\n    for n in nodes:\n        # Optional domain filter (uses node tags)\n        tags = [t for t in (n.get(\"tags\") or []) if isinstance(t, str)]\n        if domain_filter and (domain_filter not in tags):\n            continue\n\n        text_card = compose_node_card(n, max_examples=max_examples)\n\n        # stash useful metadata in source as JSON string\n        meta = {\n            \"pack\": pack_name,\n            \"node_id\": n[\"id\"],\n            \"name\": n.get(\"name\"),\n            \"type\": n.get(\"type\"),\n            \"tags\": tags,\n            \"source\": n.get(\"source\"),\n        }\n        # Calculate the new vector ID: it's the current size before adding\n        # (RAGManager.add_knowledge increments ntotal by 1).\n        vec_id = rag.index.ntotal if rag.index is not None else 0\n\n        if dry_run:\n            logger.info(\"[dry-run] would index node %s as vec_id=%d\", n[\"id\"], vec_id)\n        else:\n            rag.add_knowledge(text=text_card, source=json.dumps(meta, ensure_ascii=False))\n            node_to_vec[n[\"id\"]] = vec_id\n            indexed += 1\n\n    if not dry_run:\n        rag.save()\n        # Persist the mapping so retrieval/expansion can be fast\n        map_path = pack_dir / \"nodeid_to_vecid.json\"\n        map_path.write_text(json.dumps(node_to_vec, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n        logger.info(\"Indexed %d nodes; saved node→vector map: %s\", indexed, map_path)\n\n    # Optional quick test\n    if test_query:\n        if dry_run:\n            logger.info(\"[dry-run] Skipping test query (no index writes)\")\n            return\n        res = rag.retrieve_knowledge(test_query, top_k=topk)\n        logger.info(\"TEST QUERY: %r\", test_query)\n        for i, r in enumerate(res, 1):\n            src = r.get(\"source\", \"\")\n            try:\n                meta = json.loads(src)\n                nid = meta.get(\"node_id\")\n                name = meta.get(\"name\")\n                ntype = meta.get(\"type\")\n                logger.info(\"  %d) %s [%s]  (node_id=%s)\", i, name, ntype, nid)\n            except Exception:\n                logger.info(\"  %d) %s\", i, src[:120])\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def infer_pack_name(pack_dir: Path)"}, "tags": ["anton_repo"]}
{"id": "b0000058", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def parse_args():\n    ap = argparse.ArgumentParser(description=\"Step 3: Index nodes into FAISS (RAGManager) + save graph adjacencies.\")\n    ap.add_argument(\"--pack-dir\", required=True, help=\"Directory with nodes.jsonl and edges.jsonl\")\n    ap.add_argument(\"--model\", default=\"all-MiniLM-L6-v2\", help=\"SentenceTransformer model name\")\n    ap.add_argument(\"--index-path\", default=\"../../knowledge.index\", help=\"FAISS index path\")\n    ap.add_argument(\"--docs-path\", default=\"../../documents.pkl\", help=\"Doc-store path\")\n    ap.add_argument(\"--domain\", default=\"\", help=\"Optional tag filter (e.g., 'calculus')\")\n    ap.add_argument(\"--max-examples\", type=int, default=2, help=\"Max examples to include per node card\")\n    ap.add_argument(\"--dry-run\", type=lambda s: s.lower() in {\"1\",\"true\",\"yes\",\"y\"}, default=False)\n    ap.add_argument(\"--test-query\", default=\"\", help=\"Optional quick RAG search to validate\")\n    ap.add_argument(\"--topk\", type=int, default=5)\n    ap.add_argument(\"--log-level\", default=\"INFO\")\n    return ap.parse_args()\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def parse_args()"}, "tags": ["anton_repo"]}
{"id": "b0000059", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def main():\n    args = parse_args()\n    logging.basicConfig(level=getattr(logging, args.log_level.upper(), logging.INFO),\n                        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n    index_pack(\n        pack_dir=Path(args.pack_dir),\n        model_name=args.model,\n        index_path=args.index_path,\n        docs_path=args.docs_path,\n        domain_filter=args.domain,\n        max_examples=args.max_examples,\n        dry_run=args.dry_run,\n        test_query=args.test_query,\n        topk=args.topk,\n    )\n\nif __name__ == \"__main__\":\n    main()\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000060", "domain": "anton_repo", "section_path": ["learning/rag_indexer.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "# step3_rag_indexer.py\n# Step 3 using your existing RAGManager (FAISS + Sentence Transformers)\n#\n# What it does:\n# - Reads nodes.jsonl + edges.jsonl from a pack dir\n# - Builds a compact text \"card\" per node and indexes it into RAGManager\n# - Saves graph adjacency (from edges) and a node_id→vector_id map alongside the pack\n#\n# Usage:\n#   python3 step3_rag_indexer.py \\\n#     --pack-dir packs/calc.v1 \\\n#     --model all-MiniLM-L6-v2 \\\n#     --index-path rag/knowledge.index \\\n#     --docs-path rag/documents.pkl \\\n#     --domain calculus \\\n#     --max-examples 2 \\\n#     --dry-run false\n#\n# Optional quick test:\n#   python3 step3_rag_indexer.py ... --test-query \"Differentiate e^{x^2} sin x\" --topk 5\n#\nimport argparse\nimport json\nimport logging\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Tuple\n\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\nfrom server.agent.rag_manager import RAGManager\nimport numpy as np\n\nlogger = logging.getLogger(__name__)\n\n", "source": {"file": "learning/rag_indexer.py", "section": "learning/rag_indexer.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000061", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def to_json(self) -> str:\n        return json.dumps(asdict(self), ensure_ascii=False)\n\n\n", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:def to_json(self)"}, "tags": ["anton_repo"]}
{"id": "b0000062", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _should_index_file(file_path: str, root: str) -> bool:\n    \"\"\"Lightweight filter logic adapted from CodeIndexer._should_index_file.\"\"\"\n    # Directories to exclude\n    exclude_dirs = {\n        '__pycache__', 'venv', 'env', '.venv', '.env', '.pytest_cache',\n        'node_modules', 'dist', 'build', '.next',\n        '.git', '.svn', '.hg',\n        'data', 'datasets', 'chroma_db', 'packs',\n        '.cache', '.chainlit',\n        '.DS_Store', 'Thumbs.db'\n    }\n    # Specific extensions to exclude\n    exclude_extensions = {\n        '.pyc', '.pyo', '.pyd', '.so', '.dll', '.exe', '.bin', '.dat',\n        '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.webp', '.svg', '.pdf',\n        '.zip', '.tar', '.gz', '.7z', '.rar', '.jar', '.war',\n        '.mp3', '.mp4', '.avi', '.mov', '.flv', '.wav',\n        '.db', '.sqlite', '.mdb', '.ldb', '.npy', '.pkl', '.index',\n        '.log', '.cache', '.tmp',\n        '.idea', '.vscode', '.vs'\n    }\n    # Specific files to exclude by pattern\n    exclude_file_patterns = [\n        '.*', '*.lock', '*.min.*', 'package-lock.json', 'yarn.lock', 'poetry.lock', 'Pipfile.lock',\n        'requirements*.txt', '.env*', '.flake8', '.gitignore', '.prettierrc', '.eslintrc', 'Dockerfile', 'LICENSE',\n        '*.md5', '*.sum'\n    ]\n    # Only include these extensions\n    include_extensions = {\n        '.py', '.js', '.jsx', '.ts', '.tsx', '.html', '.css', '.scss',\n        '.json', '.yaml', '.yml', '.toml', '.md', '.rst', '.txt'\n    }\n    max_file_size_kb = 500\n\n    # Skip excluded directories\n    parts = Path(file_path).parts\n    for part in parts:\n        if part in exclude_dirs or any(fnmatch.fnmatch(part, pattern) for pattern in ['.*']):\n            return False\n\n    file_name = os.path.basename(file_path)\n    _, ext = os.path.splitext(file_path)\n    ext = ext.lower()\n\n    if any(fnmatch.fnmatch(file_name, pattern) for pattern in exclude_file_patterns):\n        return False\n    if ext in exclude_extensions:\n        return False\n    if include_extensions and ext not in include_extensions:\n        return False\n    try:\n        if os.path.getsize(file_path) > max_file_size_kb * 1024:\n            return False\n    except OSError:\n        return False\n\n    # Simple binary detection\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            sample = f.read(1024)\n            if '\\0' in sample:\n                return False\n    except UnicodeDecodeError:\n        return False\n    except Exception:\n        return False\n\n    return True\n\n\n", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:def _should_index_file(file_path: str, root: str)"}, "tags": ["anton_repo"]}
{"id": "b0000063", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _chunk_code_file(file_path: str, content: str, root: str) -> List[Dict[str, str]]:\n    \"\"\"Chunk code similar to CodeIndexer._chunk_code_file.\"\"\"\n    chunks: List[Dict[str, str]] = []\n    _, ext = os.path.splitext(file_path)\n    rel_path = os.path.relpath(file_path, root)\n\n    if ext.lower() == '.py':\n        import re\n        pattern = r'(class\\s+\\w+\\(.*?\\)|def\\s+\\w+\\(.*?\\))'\n        matches = list(re.finditer(pattern, content))\n        if not matches:\n            return [{\"text\": content, \"source\": f\"{rel_path}:FULL\"}]\n        for i, match in enumerate(matches):\n            start_pos = match.start()\n            end_pos = matches[i+1].start() if i < len(matches) - 1 else len(content)\n            chunk_content = content[start_pos:end_pos]\n            definition_line = match.group(0)\n            chunks.append({\"text\": chunk_content, \"source\": f\"{rel_path}:{definition_line.strip()}\"})\n        if matches and matches[0].start() > 0:\n            top_content = content[:matches[0].start()]\n            chunks.append({\"text\": top_content, \"source\": f\"{rel_path}:IMPORTS\"})\n        return chunks\n\n    # For others: line-based\n    lines = content.split('\\n')\n    chunk_size = 100\n    for i in range(0, len(lines), chunk_size):\n        chunk_lines = lines[i:i + chunk_size]\n        chunk_content = '\\n'.join(chunk_lines)\n        chunks.append({\"text\": chunk_content, \"source\": f\"{rel_path}:{i+1}-{i+len(chunk_lines)}\"})\n    return chunks\n\n\n", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:def _chunk_code_file(file_path: str, content: str, root: str)"}, "tags": ["anton_repo"]}
{"id": "b0000064", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def import_directory(root: str, out_path: str, domain: str = \"\") -> int:\n    root = os.path.abspath(root)\n    out = Path(out_path)\n    out.parent.mkdir(parents=True, exist_ok=True)\n\n    count = 0\n    block_id = 0\n\n    with out.open(\"w\", encoding=\"utf-8\") as fw:\n        for dirpath, dirnames, filenames in os.walk(root):\n            # Skip dot directories quickly\n            dirnames[:] = [d for d in dirnames if not d.startswith('.')]\n\n            for fname in filenames:\n                file_path = os.path.join(dirpath, fname)\n                if not _should_index_file(file_path, root):\n                    continue\n\n                rel_path = os.path.relpath(file_path, root)\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        content = f.read()\n                except Exception:\n                    continue\n\n                chunks = _chunk_code_file(file_path, content, root)\n                if not chunks:\n                    continue\n                # Emit one block per chunk as a \"page\"\n                for i, ch in enumerate(chunks, start=1):\n                    block_id += 1\n                    rec = BlockRecord(\n                        id=f\"b{block_id:07d}\",\n                        domain=domain,\n                        section_path=[rel_path],\n                        page=i,\n                        block_index=1,\n                        block_type=\"code\",\n                        text=ch.get(\"text\", \"\"),\n                        source={\"file\": rel_path, \"section\": ch.get(\"source\", rel_path)},\n                        tags=[domain] if domain else [],\n                    )\n                    fw.write(rec.to_json() + \"\\n\")\n                    count += 1\n\n    return count\n\n\n", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:def import_directory(root: str, out_path: str, domain: str = \"\")"}, "tags": ["anton_repo"]}
{"id": "b0000065", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def main():\n    ap = argparse.ArgumentParser(description=\"Import a code directory into blocks.jsonl\")\n    ap.add_argument(\"--root\", required=True, help=\"Directory to import\")\n    ap.add_argument(\"--out\", required=True, help=\"Output blocks.jsonl path\")\n    ap.add_argument(\"--domain\", default=\"\", help=\"Domain tag (e.g., code, calculus)\")\n    args = ap.parse_args()\n\n    n = import_directory(args.root, args.out, args.domain)\n    print(f\"[ok] Wrote {args.out} with {n} code blocks\")\n\n\nif __name__ == \"__main__\":\n    main()\n", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000066", "domain": "anton_repo", "section_path": ["learning/code_importer.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "\"\"\"\nCode Importer: Directory → blocks.jsonl\n\nUsage:\n  python learning/code_importer.py --root /path/to/repo --out packs/code.v1/blocks.jsonl --domain code\n\nWhat it does\n- Walks a code directory\n- Reuses CodeIndexer filters and chunking to produce logical chunks\n- Emits blocks.jsonl compatible with concept_extractor Step 2\n\nOutput schema (per line):\n{\n  id: str,\n  domain: str,\n  section_path: List[str],      # we use [rel_path] (file relative path) as the section\n  page: int,                    # chunk index within the file, starting at 1\n  block_index: int,             # always 1 per chunk (one block per page)\n  block_type: \"code\",\n  text: str,                    # the code chunk\n  source: { file: rel_path, section: chunk_source },\n  tags: [domain]\n}\n\"\"\"\nimport argparse\nimport json\nimport os\nfrom dataclasses import dataclass, asdict, field\nfrom pathlib import Path\nfrom typing import Any, Dict, List\nimport fnmatch\n\n\n@dataclass\nclass BlockRecord:\n    id: str\n    domain: str\n    section_path: List[str]\n    page: int\n    block_index: int\n    block_type: str\n    text: str\n    source: Dict[str, Any]\n    tags: List[str] = field(default_factory=list)\n\n    ", "source": {"file": "learning/code_importer.py", "section": "learning/code_importer.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000067", "domain": "anton_repo", "section_path": ["client/config.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "# config.py\n\n\"\"\"\nCentral configuration for the Anton client application.\n\"\"\"\n\n# The base URL for the Anton agent server API.\n# Centralizing this makes it easy to change for different environments (e.g., development, production).\nAPI_BASE_URL = \"http://192.168.1.250:8001\"\n\n# Default timeout for API requests in seconds.\nDEFAULT_TIMEOUT = 300.0\n\n# Default temperature for the agent's chat completions.\nDEFAULT_TEMPERATURE = 0.6\n", "source": {"file": "client/config.py", "section": "client/config.py:FULL"}, "tags": ["anton_repo"]}
{"id": "b0000068", "domain": "anton_repo", "section_path": ["client/anton_client.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base_url: str = config.API_BASE_URL, timeout: float = config.DEFAULT_TIMEOUT):\n        self.api_client = ApiClient(api_base_url, timeout)\n        logger.info(\"Anton client initialized.\")\n\n    async def stream_response(\n            self, user_prompt: str, chat_history: Optional[List[Dict[str, str]]] = None\n    ) -> AsyncIterator[Dict[str, str]]:\n        \"\"\"\n        Sends the user prompt and chat history to the server and streams the response.\n        The server now handles all context gathering and routing.\n        \"\"\"\n        assistant_response_for_memory = \"\"\n        try:\n            yield {\"type\": \"info\", \"content\": \"Sending request to agent...\"}\n            logger.info(\"Phase 1: Sending raw prompt to server for routing.\")\n\n            messages = (chat_history or []) + [{\"role\": \"user\", \"content\": user_prompt}]\n\n            # The request_data is now much simpler. The server will add tools as needed.\n            request_data = {\n                \"messages\": messages,\n                \"temperature\": config.DEFAULT_TEMPERATURE,\n            }\n\n            # --- 2. Streaming from Server ---\n            logger.info(\"Phase 2: Streaming processed response from server.\")\n            stream = self.api_client.stream_agent_chat(request_data)\n            async for chunk in stream:\n                # Parse structured events from the server\n                if chunk.startswith(\"<thought>\") and chunk.endswith(\"</thought>\"):\n                    content = chunk[9:-10]  # Remove <thought> tags\n                    yield {\"type\": \"thought\", \"content\": content}\n                elif chunk.startswith(\"<tool_result>\") and chunk.endswith(\"</tool_result>\"):\n                    content = chunk[13:-14]  # Remove <tool_result> tags\n                    yield {\"type\": \"tool_result\", \"content\": content}\n                elif chunk.startswith(\"<token>\") and chunk.endswith(\"</token>\"):\n                    content = chunk[7:-8]  # Remove <token> tags\n                    yield {\"type\": \"token\", \"content\": content}\n                    assistant_response_for_memory += content\n                else:\n                    # Fallback for any raw chunks (backward compatibility)\n                    yield {\"type\": \"token\", \"content\": chunk}\n                    assistant_response_for_memory += chunk\n\n        except Exception as e:\n            error_message = f\"API call failed: {e}\"\n            logger.error(f\"API call failed during stream: {e}\", exc_info=True)\n            yield {\"type\": \"error\", \"content\": error_message}\n            return\n\n    async ", "source": {"file": "client/anton_client.py", "section": "client/anton_client.py:def __init__(self, api_base_url: str = config.API_BASE_URL, timeout: float = config.DEFAULT_TIMEOUT)"}, "tags": ["anton_repo"]}
{"id": "b0000069", "domain": "anton_repo", "section_path": ["client/anton_client.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def close(self):\n        \"\"\"Closes the underlying API client session.\"\"\"\n        await self.api_client.close()\n", "source": {"file": "client/anton_client.py", "section": "client/anton_client.py:def close(self)"}, "tags": ["anton_repo"]}
{"id": "b0000070", "domain": "anton_repo", "section_path": ["client/anton_client.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "# client/anton_client.py\n\nimport logging\nfrom typing import AsyncIterator, Dict, List, Optional\n\nfrom client import config\nfrom client.api_client import ApiClient\n# We no longer need the ContextBuilder on the client side.\n\n# Set up a dedicated logger for this module\nlogger = logging.getLogger(__name__)\n\n\nclass AntonClient:\n    \"\"\"\n    A simplified client for interacting with the Anton agent.\n    It sends the user's request and streams the server's processed response.\n    It is no longer responsible for gathering context.\n    \"\"\"\n\n    ", "source": {"file": "client/anton_client.py", "section": "client/anton_client.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000071", "domain": "anton_repo", "section_path": ["client/api_client.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base_url: str, timeout: float):\n        \"\"\"\n        Initializes the ApiClient.\n\n        Args:\n            api_base_url: The base URL of the API server.\n            timeout: The timeout for HTTP requests.\n        \"\"\"\n        self.api_base_url = api_base_url\n        self.http_client = httpx.AsyncClient(timeout=timeout)\n        logger.info(f\"API client initialized for server at {api_base_url}\")\n\n    async ", "source": {"file": "client/api_client.py", "section": "client/api_client.py:def __init__(self, api_base_url: str, timeout: float)"}, "tags": ["anton_repo"]}
{"id": "b0000072", "domain": "anton_repo", "section_path": ["client/api_client.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def stream_agent_chat(self, request_data: Dict[str, Any]) -> AsyncIterator[str]:\n        logger.info(\"Streaming request to agent chat endpoint.\")\n        async with self.http_client.stream(\n                \"POST\", f\"{self.api_base_url}/v1/agent/chat\", json=request_data, timeout=3600\n        ) as response:\n            response.raise_for_status()\n            async for chunk in response.aiter_text():\n                yield chunk\n\n    async ", "source": {"file": "client/api_client.py", "section": "client/api_client.py:def stream_agent_chat(self, request_data: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000073", "domain": "anton_repo", "section_path": ["client/api_client.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def close(self):\n        \"\"\"Closes the underlying HTTP client session.\"\"\"\n        if not self.http_client.is_closed:\n            logger.info(\"Closing API client http session.\")\n            await self.http_client.aclose()\n", "source": {"file": "client/api_client.py", "section": "client/api_client.py:def close(self)"}, "tags": ["anton_repo"]}
{"id": "b0000074", "domain": "anton_repo", "section_path": ["client/api_client.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "# api_client.py\n\"\"\"\nHandles all direct HTTP communications with the Anton agent server.\nThis class encapsulates the logic for making API calls, handling responses,\nand managing the HTTP client session.\n\"\"\"\nimport logging\nfrom typing import AsyncIterator, Dict, Any\n\nimport httpx\n\n# Set up a dedicated logger for this module\nlogger = logging.getLogger(__name__)\n\n\nclass ApiClient:\n    \"\"\"A client for making requests to the Anton agent API.\"\"\"\n\n    ", "source": {"file": "client/api_client.py", "section": "client/api_client.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000075", "domain": "anton_repo", "section_path": ["client/main.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def main():\n    \"\"\"A simple test function to run the client from the command line.\"\"\"\n    print(\"🚀 Initializing Anton Test Suite...\")\n    client = AntonClient()\n\n    # Example prompt\n    user_input = \"Can you write a python script to list all the files in the current directory and save it as 'list_files.py'?\"\n\n    print(f\"\\n--- Streaming response for: '{user_input}' ---\\n\")\n    try:\n        # The stream_response method now yields dictionaries for structured processing\n        async for chunk in client.stream_response(user_prompt=user_input):\n            content = chunk.get(\"content\", \"\")\n            chunk_type = chunk.get(\"type\", \"token\")\n\n            if chunk_type == \"token\":\n                # For tokens, print them continuously on the same line\n                print(content, end=\"\", flush=True)\n            elif chunk_type in [\"info\", \"error\"]:\n                # For status updates or errors, print them on a new line for clarity\n                print(f\"\\n[{chunk_type.upper()}]: {content}\")\n\n    except Exception as e:\n        logging.error(f\"An error occurred in the main loop: {e}\", exc_info=True)\n    finally:\n        await client.close()\n        print(\"\\n\\n--- Test complete ---\")\n\n\nif __name__ == \"__main__\":\n    # Configure logging for the entire application\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    # Silence the overly verbose httpx logger to keep the output clean\n    logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n\n    # Run the asynchronous main function\n    asyncio.run(main())\n", "source": {"file": "client/main.py", "section": "client/main.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000076", "domain": "anton_repo", "section_path": ["client/main.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "# main.py\n\n\"\"\"\nMain entry point for running the Anton command-line client.\n\"\"\"\n\nimport asyncio\nimport logging\n\nfrom anton_client import AntonClient\n\n\nasync ", "source": {"file": "client/main.py", "section": "client/main.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000077", "domain": "anton_repo", "section_path": ["server/config.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "QWEN_30B_THINKING = 'qwen3:30b-a3b-thinking-2507-q4_K_M'\nQWEN_30B_INSTRUCT = 'qwen3:30b-a3b-instruct-2507-q4_K_M'", "source": {"file": "server/config.py", "section": "server/config.py:FULL"}, "tags": ["anton_repo"]}
{"id": "b0000078", "domain": "anton_repo", "section_path": ["server/example.txt"], "page": 1, "block_index": 1, "block_type": "code", "text": "This is an example file.", "source": {"file": "server/example.txt", "section": "server/example.txt:1-1"}, "tags": ["anton_repo"]}
{"id": "b0000079", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class ToolCall(BaseModel):\n    id: str\n    type: Literal[\"function\"] = \"function\"\n    function: dict[str, str] # e.g., {\"name\": \"get_weather\", \"arguments\": '{\"location\": \"Boston\"}'}\n\n\n# A more accurate and type-safe representation of a chat message.\n", "source": {"file": "server/helpers.py", "section": "server/helpers.py:class ToolCall(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000080", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "class OpenAIChatMessage(BaseModel):\n    role: Literal[\"system\", \"user\", \"assistant\", \"tool\"]\n    content: str | None = None\n    tool_calls: list[ToolCall] | None = None # For assistant messages that use tools.\n    tool_call_id: str | None = None          # For 'tool' role messages with results.\n\n\n# Defines the name, description, and JSON schema for a function's parameters.\n", "source": {"file": "server/helpers.py", "section": "server/helpers.py:class OpenAIChatMessage(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000081", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "class FunctionDefinition(BaseModel):\n    name: str\n    description: str\n    parameters: dict[str, Any]\n\n\n# Defines a tool, which is currently always a function.\n", "source": {"file": "server/helpers.py", "section": "server/helpers.py:class FunctionDefinition(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000082", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "class ToolDefinition(BaseModel):\n    type: Literal[\"function\"] = \"function\"\n    function: FunctionDefinition\n\n\n# The main request body for your agent.\n", "source": {"file": "server/helpers.py", "section": "server/helpers.py:class ToolDefinition(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000083", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "class AgentChatRequest(BaseModel):\n    messages: list[OpenAIChatMessage]\n    tools: list[ToolDefinition] | None = None\n    temperature: float = 0.6\n    complex: bool = False\n    model: str = QWEN_30B_THINKING", "source": {"file": "server/helpers.py", "section": "server/helpers.py:class AgentChatRequest(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000084", "domain": "anton_repo", "section_path": ["server/helpers.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "# FILE: server/helpers.py\nimport logging\nfrom typing import Any, Literal\n\nfrom pydantic import BaseModel, Field\n\nfrom server.config import QWEN_30B_THINKING\n\nlogger = logging.getLogger(__name__)\n\n\n# Represents an individual tool call made by the model.\n", "source": {"file": "server/helpers.py", "section": "server/helpers.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000085", "domain": "anton_repo", "section_path": ["server/model_server.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def get_all_resource_usage(logger_instance) -> dict:\n    \"\"\"\n    Captures a snapshot of current CPU, RAM usage.\n    GPU monitoring via pynvml is removed as Ollama abstracts this.\n    If you need GPU stats, consider `nvidia-smi` via subprocess.\n    \"\"\"\n    usage = {\n        \"cpu_percent\": psutil.cpu_percent(),\n        \"ram_percent\": psutil.virtual_memory().percent,\n        \"gpus\": [] # Placeholder, as we don't have direct pynvml access here\n    }\n    # You could add subprocess calls to `nvidia-smi` here if detailed GPU stats are critical,\n    # but be aware of the performance overhead for frequent calls.\n    return usage\n\n# --- FastAPI Lifespan (Startup/Shutdown Events) ---\n@asynccontextmanager\nasync ", "source": {"file": "server/model_server.py", "section": "server/model_server.py:def get_all_resource_usage(logger_instance)"}, "tags": ["anton_repo"]}
{"id": "b0000086", "domain": "anton_repo", "section_path": ["server/model_server.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def lifespan(app: FastAPI):\n    logger.info(\"🚀 Server starting up...\")\n\n    logger.info(\"--- OLLAMA MODEL CHECK METRICS ---\")\n\n    pre_load_usage = get_all_resource_usage(logger)\n\n    startup_start_time = time.monotonic()\n    startup_duration = time.monotonic() - startup_start_time\n\n    post_load_usage = get_all_resource_usage(logger)\n\n    # Simplified resource logging as GPU details are not directly accessible via pynvml\n    logger.info(\n        f\"[Resources] Pre-Load  - CPU: {pre_load_usage['cpu_percent']:.1f}%, RAM: {pre_load_usage['ram_percent']:.1f}%\"\n    )\n    logger.info(\n        f\"[Resources] Post-Load - CPU: {post_load_usage['cpu_percent']:.1f}%, RAM: {post_load_usage['ram_percent']:.1f}%\"\n    )\n\n    cpu_diff = post_load_usage['cpu_percent'] - pre_load_usage['cpu_percent']\n    ram_diff = post_load_usage['ram_percent'] - pre_load_usage['ram_percent']\n\n    logger.info(\n        f\"[Resources] Difference- CPU: {cpu_diff:+.1f}%, RAM: {ram_diff:+.1f}%\"\n    )\n\n    logger.info(f\"[Latency] Ollama model check complete in {startup_duration:.2f} seconds.\")\n    logger.info(\"-----------------------------\")\n\n    logger.info(\"✅ Server is fully initialized and ready to accept requests.\")\n    yield\n    logger.info(\"🌙 Server shutting down.\")\n    logger.info(\"Server shutdown complete.\")\n\n\napp = FastAPI(title=\"Ollama API Server\", version=\"1.0.0\", lifespan=lifespan)\n\n\nasync def metrics_collecting_stream_generator(\n        ollama_stream: AsyncGenerator[dict, None], # Ollama streams dictionaries\n        metrics: MetricsTracker\n) -> AsyncGenerator[str, None]:\n    chunk_count = 0\n    metrics.get_resource_usage = lambda: get_all_resource_usage(logger)\n    metrics.resource_snapshots['request_start'] = metrics.get_resource_usage()\n    try:\n        async for chunk in ollama_stream:\n            # Ollama's chat API yields dicts with a 'content' field in 'message'\n            if 'message' in chunk and 'content' in chunk['message']:\n                # Format as proper SSE with data: prefix\n                content = chunk['message']['content']\n                yield f\"data: {content}\\n\\n\"\n                chunk_count += 1\n            elif 'done' in chunk and chunk['done']:\n                # The 'done' chunk signifies the end and contains final metrics\n                yield \"data: [DONE]\\n\\n\"\n    finally:\n        metrics.end_time = time.monotonic()\n        metrics.step_token_counts['generation'] = chunk_count\n        e2e_latency = metrics.end_time - metrics.start_time\n        throughput = chunk_count / e2e_latency if e2e_latency > 0 else 0\n        metrics.resource_snapshots['request_end'] = metrics.get_resource_usage()\n        logger.info(\"--- REQUEST METRICS ---\")\n        logger.info(f\"[Latency] End-to-End: {e2e_latency:.2f} seconds\")\n        logger.info(f\"[Throughput] Chunks per Second: {throughput:.2f}\")\n        logger.info(f\"[Throughput] Total Chunks: {chunk_count}\")\n        start_usage = metrics.resource_snapshots['request_start']\n        end_usage = metrics.resource_snapshots['request_end']\n        logger.info(\n            f\"[Resources] Start - CPU: {start_usage['cpu_percent']:.1f}%, \"\n            f\"RAM: {start_usage['ram_percent']:.1f}%\"\n        )\n        logger.info(\n            f\"[Resources] End   - CPU: {end_usage['cpu_percent']:.1f}%, \"\n            f\"RAM: {end_usage['ram_percent']:.1f}%\"\n        )\n        logger.info(\"-----------------------\")\n\n\n@app.post(\"/v1/chat/stream\")\nasync ", "source": {"file": "server/model_server.py", "section": "server/model_server.py:def lifespan(app: FastAPI)"}, "tags": ["anton_repo"]}
{"id": "b0000087", "domain": "anton_repo", "section_path": ["server/model_server.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def chat_completions_stream(request: AgentChatRequest):\n    logger.info(\"Received request on /v1/chat/stream\")\n    metrics = MetricsTracker(logger)\n    client = ollama.AsyncClient(host=OLLAMA_HOST)\n\n    try:\n        ollama_options = {\n            \"temperature\": request.temperature,\n            \"num_predict\": 16384 ,\n        }\n\n        model_to_use = request.model\n        logger.info(f\"Query: \\n{request.messages}\")\n\n        # Step 2: Use the determined model for the actual chat\n        actual_ollama_stream_generator = await client.chat(\n            model=model_to_use,\n            messages=request.messages,\n            stream=True,\n            options=ollama_options,\n        )\n\n    except ollama.ResponseError as e:\n        logger.error(f\"Error from Ollama during routing or chat request: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Ollama inference error: {e.error}\")\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred during routing or Ollama call setup: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error during Ollama call setup.\")\n\n    metrics_generator = metrics_collecting_stream_generator(actual_ollama_stream_generator, metrics)\n\n    return StreamingResponse(metrics_generator, media_type=\"text/event-stream\")\n\n\nif __name__ == \"__main__\":\n    logger.info(f\"Starting Uvicorn server on {SERVER_HOST}:{SERVER_PORT}\")\n    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT)", "source": {"file": "server/model_server.py", "section": "server/model_server.py:def chat_completions_stream(request: AgentChatRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000088", "domain": "anton_repo", "section_path": ["server/model_server.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "import logging\nimport os\nimport time\nimport psutil\nimport uvicorn\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.responses import StreamingResponse\nfrom contextlib import asynccontextmanager\nfrom typing import AsyncGenerator\nimport ollama # Import the ollama client library\n\nfrom metrics import MetricsTracker\nfrom server.config import QWEN_30B_THINKING\nfrom server.helpers import AgentChatRequest\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nOLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")\n# ----------------------------\n\nSERVER_HOST = \"0.0.0.0\"\nSERVER_PORT = 8000\nMAX_SEQ_LENGTH = 8192 # This is less critical here as Ollama manages context internally\n\n", "source": {"file": "server/model_server.py", "section": "server/model_server.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000089", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __new__(cls, *args, **kwargs):\n        if cls._instance is None:\n            with cls._lock:  # Thread-safe singleton creation\n                if cls._instance is None:\n                    logger.info(\"Creating a new RAGManager instance.\")\n                    cls._instance = super(RAGManager, cls).__new__(cls)\n                    # Initialize on creation only\n                    cls._instance._init_rag(*args, **kwargs)\n        return cls._instance\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def __new__(cls, *args, **kwargs)"}, "tags": ["anton_repo"]}
{"id": "b0000090", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _init_rag(self, model_name: str = 'all-MiniLM-L6-v2', index_path: str = 'knowledge.index', doc_store_path: str = 'documents.pkl'):\n        \"\"\"Initializes the RAG components. This method is called only once.\"\"\"\n        logger.info(\"Initializing RAGManager components...\")\n        self.model: SentenceTransformer = SentenceTransformer(model_name)\n        self.embedding_dim: int = self.model.get_sentence_embedding_dimension()\n        self.index_path: str = index_path\n        self.doc_store_path: str = doc_store_path\n        \n        # Instance-level lock for protecting FAISS operations\n        self._operation_lock = threading.Lock()\n\n        self.index: Optional[faiss.Index] = None\n        self.doc_store: Dict[int, Dict[str, Any]] = {}\n\n        self._load()\n        logger.info(f\"RAGManager initialized. Knowledge base contains {self.index.ntotal} entries.\")\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def _init_rag(self, model_name: str = 'all-MiniLM-L6-v2', index_path: str = 'knowledge.index', doc_store_path: str = 'documents.pkl')"}, "tags": ["anton_repo"]}
{"id": "b0000091", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _load(self):\n        \"\"\"Loads the FAISS index and document store from disk if they exist.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.doc_store_path):\n            try:\n                self.index = faiss.read_index(self.index_path)\n                with open(self.doc_store_path, 'rb') as f:\n                    self.doc_store = pickle.load(f)\n                logger.info(\"Loaded existing knowledge base from disk.\")\n            except Exception as e:\n                logger.error(f\"Error loading knowledge base, initializing a new one: {e}\")\n                self._initialize_empty_stores()\n        else:\n            self._initialize_empty_stores()\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def _load(self)"}, "tags": ["anton_repo"]}
{"id": "b0000092", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _initialize_empty_stores(self):\n        \"\"\"Initializes a new, empty FAISS index and document store.\"\"\"\n        logger.info(\"Creating a new, empty knowledge base.\")\n        # IndexFlatL2 is a brute-force index. Good for up to ~1M vectors.\n        self.index = faiss.IndexFlatL2(self.embedding_dim)\n\n        ### NOTE: For very large datasets, consider a more advanced index for scalability.\n        # This requires a \"training\" step on your data before adding.\n        # nlist = 100  # Number of cells/clusters\n        # quantizer = faiss.IndexFlatL2(self.embedding_dim)\n        # self.index = faiss.IndexIVFPQ(quantizer, self.embedding_dim, nlist, 8, 8) # 8 bytes per vector, 8-bit precision\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def _initialize_empty_stores(self)"}, "tags": ["anton_repo"]}
{"id": "b0000093", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def save(self):\n        \"\"\"\n        ### CHANGED ###\n        Saves the current state of the index and document store to disk.\n        This is now an explicit public method.\n        Thread-safe with locking to prevent race conditions.\n        \"\"\"\n        with self._operation_lock:\n            if self.index is None:\n                logger.error(\"Cannot save, index is not initialized.\")\n                return\n\n            logger.info(f\"Saving knowledge base with {self.index.ntotal} entries to disk...\")\n            try:\n                faiss.write_index(self.index, self.index_path)\n                # ### NOTE ###: Pickle is convenient but can be insecure and break between library versions.\n                # For production, consider using a safer format like JSONL or a lightweight DB.\n                with open(self.doc_store_path, 'wb') as f:\n                    pickle.dump(self.doc_store, f)\n                logger.info(\"Knowledge base saved successfully.\")\n            except Exception as e:\n                logger.error(f\"Failed to save knowledge base: {e}\")\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def save(self)"}, "tags": ["anton_repo"]}
{"id": "b0000094", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def add_knowledge(self, text: str, source: str):\n        \"\"\"\n        Adds a text snippet and its source to the knowledge base.\n\n        ### CHANGED ### - This method no longer saves to disk automatically.\n        Call .save() explicitly after adding one or more documents.\n        Thread-safe with locking to prevent race conditions.\n        \"\"\"\n        with self._operation_lock:\n            try:\n                # The model can encode a list of sentences, so we wrap `text` in a list.\n                embedding = self.model.encode([text])\n                self.index.add(np.array(embedding, dtype=np.float32))\n\n                # The ID for the new entry is its position in the index (0-based).\n                new_id = self.index.ntotal - 1\n                self.doc_store[new_id] = {'text': text, 'source': source}\n\n                logger.debug(f\"Added new knowledge from source '{source}' to in-memory index.\")\n            except Exception as e:\n                logger.error(f\"Failed to add knowledge: {e}\", exc_info=True)\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def add_knowledge(self, text: str, source: str)"}, "tags": ["anton_repo"]}
{"id": "b0000095", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def retrieve_knowledge(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieves the top_k most relevant documents for a given query.\n        Thread-safe with locking to prevent race conditions during reads.\n        \"\"\"\n        with self._operation_lock:\n            if self.index.ntotal == 0:\n                logger.warning(\"Attempted to retrieve knowledge from an empty index.\")\n                return []\n\n            try:\n                query_embedding = self.model.encode([query])\n                distances, indices = self.index.search(np.array(query_embedding, dtype=np.float32), top_k)\n\n                # Retrieve the documents corresponding to the top indices, ensuring they exist.\n                results = [self.doc_store[i] for i in indices[0] if i in self.doc_store and i != -1]\n                return results\n            except Exception as e:\n                logger.error(f\"Failed to retrieve knowledge: {e}\", exc_info=True)\n                return []\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def retrieve_knowledge(self, query: str, top_k: int = 3)"}, "tags": ["anton_repo"]}
{"id": "b0000096", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def rebuild_index(self) -> int:\n        \"\"\"\n        Rebuild the FAISS index from the current document store to remove orphaned vectors.\n        This addresses the issue where deleted documents leave vectors in the FAISS index.\n        Thread-safe with locking to prevent race conditions.\n        \n        Returns:\n            Number of documents in the rebuilt index\n        \"\"\"\n        with self._operation_lock:\n            if not self.doc_store:\n                # If no documents, create an empty index\n                self.index = faiss.IndexFlatL2(self.embedding_dim)\n                logger.info(\"Rebuilt empty FAISS index\")\n                return 0\n            \n            try:\n                logger.info(f\"Rebuilding FAISS index from {len(self.doc_store)} documents...\")\n                \n                # Create new index\n                new_index = faiss.IndexFlatL2(self.embedding_dim)\n                \n                # Re-embed all current documents and add to new index\n                texts = []\n                doc_ids = []\n                \n                # Collect texts in order of document IDs\n                for doc_id in sorted(self.doc_store.keys()):\n                    if doc_id in self.doc_store:\n                        texts.append(self.doc_store[doc_id]['text'])\n                        doc_ids.append(doc_id)\n                \n                if texts:\n                    # Encode all texts at once for efficiency\n                    embeddings = self.model.encode(texts)\n                    embeddings_array = np.array(embeddings, dtype=np.float32)\n                    \n                    # Add to the new index\n                    new_index.add(embeddings_array)\n                    logger.info(f\"Added {len(embeddings)} embeddings to rebuilt index\")\n                \n                # Replace the old index\n                self.index = new_index\n                \n                # Create a new document store with sequential IDs\n                new_doc_store = {}\n                for i, old_doc_id in enumerate(doc_ids):\n                    new_doc_store[i] = self.doc_store[old_doc_id]\n                \n                self.doc_store = new_doc_store\n                \n                logger.info(f\"Successfully rebuilt FAISS index with {self.index.ntotal} vectors\")\n                return self.index.ntotal\n                \n            except Exception as e:\n                logger.error(f\"Failed to rebuild FAISS index: {e}\", exc_info=True)\n                return 0\n\n# Create a singleton instance to be imported by other modules\nrag_manager = RAGManager()", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:def rebuild_index(self)"}, "tags": ["anton_repo"]}
{"id": "b0000097", "domain": "anton_repo", "section_path": ["server/agent/rag_manager.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "\"\"\"\nManages the Retrieval-Augmented Generation (RAG) knowledge base.\n\nHandles embedding, storing, and retrieving knowledge snippets using\na FAISS vector store and a sentence-transformer model.\n\"\"\"\nimport os\nimport pickle\nimport logging\nimport threading\nfrom typing import List, Dict, Any, Optional\n\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\n\n# Configure a basic logger\nlogger = logging.getLogger(__name__)\n\nclass RAGManager:\n    \"\"\"\n    A singleton class to manage the FAISS vector store and document store for the agent's knowledge.\n\n    ### CHANGED ###\n    - Refactored the singleton pattern to be more robust.\n    - Decoupled adding knowledge from saving to disk for huge performance gains on batch additions.\n    - Added comprehensive type hints.\n    - Added threading.Lock for concurrency safety in add_knowledge/save/rebuild_index operations.\n    \"\"\"\n    _instance: Optional['RAGManager'] = None\n    _lock = threading.Lock()  # Class-level lock for singleton creation\n\n    ", "source": {"file": "server/agent/rag_manager.py", "section": "server/agent/rag_manager.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000098", "domain": "anton_repo", "section_path": ["server/agent/react_agent.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base_url: str, tools: List[Dict], knowledge_store: KnowledgeStore, max_iterations: int = 10, domain_pack_dir: str = '../../learning/packs'):\n        self.api_base_url = api_base_url\n        self.tools = tools\n        self.knowledge_store = knowledge_store\n        self.max_iterations = max_iterations\n        self.domain_pack_dir = domain_pack_dir\n        \n    async ", "source": {"file": "server/agent/react_agent.py", "section": "server/agent/react_agent.py:def __init__(self, api_base_url: str, tools: List[Dict], knowledge_store: KnowledgeStore, max_iterations: int = 10, domain_pack_dir: str = '../../learning/packs')"}, "tags": ["anton_repo"]}
{"id": "b0000099", "domain": "anton_repo", "section_path": ["server/agent/react_agent.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def get_react_system_prompt(self, user_prompt:str) -> str:\n        \"\"\"Get the system prompt for the ReAct agent with relevant learnings\"\"\"\n        # Query relevant knowledge from RAG to enhance the system prompt\n        relevant_knowledge = self.knowledge_store.query_relevant_knowledge(\"react agent reasoning tools\", max_results=3)\n        \n        # Get relevant learnings from the learning loop\n        relevant_learnings = await learning_loop.get_relevant_learnings(user_prompt or \"\")\n        \n        base_prompt = f\"\"\"You are Anton, an intelligent, helpful AI assistant that uses the ReAct (Reason-Act) pattern.\n        As Anton, you are NOT just an LLM, you actually have a large amount of source code that helps power your responses and your capabilities. \n        You should NEVER tell the user that you are an LLM or that you have limitations. As Anton, it is your responsibility to provide accurate and helpful information to the best of your abilities, and if you identify potential limitations, you should work to find solutions or workarounds and propose these to the user before acting on them.\n\nYou can REASON about problems, take ACTIONS using tools, and provide RESPONSES to users.\n\nFor each turn, you should:\n1. REASON: Think about what you need to do\n2. ACT: Use tools if needed to gather information or perform actions  \n3. RESPOND: Provide a helpful response to the user\n\nFormat your responses as:\n\n<think>\nYour reasoning about what to do next...\n</think>\n\nThen either:\n- Use a tool if you need to gather information or perform an action\n- Provide a direct response if you have enough information\n\nYou have access to these capabilities:\n- File operations (read, write, list directories)\n- Access to your own source code via the file operations and embeddings\n- Persistent memory, including the ability to recall parts of past interactions using RAG\n- Code analysis and search\n- Web search \n- Knowledge retrieval\n- A large amount of general knowledge. You can answer questions about anything!\n\nCoding Rules:\n- Under NO circumstances are you to do any coding tasks before checking out to a new branch. Call this branch feature/<feature_name>\n- You MUST ensure that your code compiles\n\nAvailable tools:\n{self._format_tools_compact()}\n\nTo call a tool, output a JSON object wrapped in tool tags. Do NOT emit the example literally:\n\nExample (do not copy as-is):\n&lt;tool_call&gt;\n{{\n  \"name\": \"read_file\",\n  \"arguments\": {{\"file_path\": \"server/agent/react_agent.py\"}}\n}}\n&lt;/tool_call&gt;\n\nRules:\n- Use only ONE tool per turn\n- Always wait for tool results before deciding next actions\n- Never include multiple tool calls in the same response\n- Summarize tool results before providing your final answer\n- Use \"Final Answer:\" when you are ready to reply to the user. Example: User Prompt: \"Hello!\" Response: \"Final Answer: Hello! How can I assist you today?\"\n- Tool results will be provided as OBSERVATIONS - acknowledge and use them\n\nWhen a tool completes, you will see an OBSERVATION message. Always process this before continuing.\n\nYou MUST always remember that when you are ready to reply to the user, start your response with \"Final Answer:\"\n\nAlways think step by step and be helpful to the user.\n\"\"\"\n        # Add relevant knowledge if available\n        if relevant_knowledge:\n            base_prompt += \"\\n\\nRelevant past knowledge:\\n\"\n            for knowledge in relevant_knowledge[:2]:\n                base_prompt += f\"- {knowledge[:200]}...\\n\"\n                \n        # Add relevant learnings if available\n        if relevant_learnings:\n            base_prompt += \"\\n\\nRelevant past learnings and capabilities:\\n\"\n            for learning in relevant_learnings[:3]:\n                base_prompt += f\"- {learning[:200]}...\\n\"\n\n        if user_prompt and self.domain_pack_dir:\n            self.domain_pack_dir = (\n                self.knowledge_store.select_pack_by_embedding(user_prompt, \"learning/packs/calc.v1\")\n            )\n            bundle = self.knowledge_store.build_domain_knowledge_context(\n                query=user_prompt,\n                pack_dir=self.domain_pack_dir,\n                topk=5,\n                expand_radius=1,\n                max_nodes=8,\n                max_examples_per_node=1\n            )\n            if bundle:\n                base_prompt += \"\\n\\n# Domain knowledge\\n\"\n                base_prompt += (\n                    \"You have access to the following formal rules and concepts relevant to the user's request.\\n\"\n                    \"Use these rules directly when solving; prefer formal definitions over prose.\\n\\n\"\n                    + bundle\n                )\n                \n        return base_prompt\n    \n    ", "source": {"file": "server/agent/react_agent.py", "section": "server/agent/react_agent.py:def get_react_system_prompt(self, user_prompt:str)"}, "tags": ["anton_repo"]}
{"id": "b0000100", "domain": "anton_repo", "section_path": ["server/agent/react_agent.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _format_tools_compact(self) -> str:\n        \"\"\"Format tools in a compact way to reduce prompt bloat\"\"\"\n        if not self.tools:\n            return \"No tools available\"\n        \n        tool_summaries = []\n        for tool in self.tools:\n            if isinstance(tool, dict):\n                name = tool.get('name', 'unknown')\n                if name == 'unknown':\n                    tool = tool.get('function')\n                    name = tool.get('name', 'unknown')\n                description = tool.get('description', 'No description')\n                parameters = tool.get('parameters', '{}')\n                # Limit description length to avoid bloat\n                short_desc = description[:100] + \"...\" if len(description) > 100 else description\n                tool_summaries.append(f\"- {name}: {short_desc}, Parameters: {parameters}\")\n            else:\n                tool_summaries.append(f\"- {str(tool)}\")\n        \n        return \"\\n\".join(tool_summaries)\n\n    async def process_request(\n        self,\n        initial_messages: List[Dict[str, str]],\n        logger: Any\n    ) -> AsyncGenerator[str, None]:\n        \"\"\"\n        Process a request using the ReAct pattern with KnowledgeStore for state management.\n        Handles the complete reasoning and tool-use loop without external dependencies.\n        Integrates learning loop for experience tracking and improvement.\n        \"\"\"\n        logger.info(\"Starting ReAct agent processing...\")\n        \n        # Start learning task tracking\n        user_prompt = None\n        for msg in initial_messages:\n            if msg[\"role\"] == \"user\":\n                user_prompt = msg[\"content\"]\n                break\n        \n        if user_prompt:\n            learning_loop.start_task(user_prompt)\n        \n        # Initialize conversation in knowledge store\n        for msg in initial_messages:\n            self.knowledge_store.add_message(msg[\"role\"], msg[\"content\"])\n        \n        # Build messages for the LLM\n        messages = self.knowledge_store.get_messages_for_llm()\n        \n        # Add system prompt\n        system_prompt = await self.get_react_system_prompt(user_prompt)\n        react_messages = [{\"role\": SYSTEM_ROLE, \"content\": system_prompt}]\n        \n        # Add context if available\n        context_summary = self.knowledge_store.build_context_summary()\n        if context_summary and context_summary != \"No significant context yet.\":\n            react_messages.append({\n                \"role\": SYSTEM_ROLE, \n                \"content\": f\"Current context:\\n{context_summary}\"\n            })\n        \n        # Add conversation history\n        react_messages.extend(messages)\n        \n        # Track iterations to prevent infinite loops\n        iteration = 0\n        \n        while iteration < self.max_iterations:\n            iteration += 1\n            logger.info(f\"ReAct iteration {iteration}/{self.max_iterations}\")\n            \n            self.knowledge_store.add_context(\n                f\"Starting ReAct iteration {iteration}\",\n                ContextType.THOUGHT,\n                ImportanceLevel.LOW,\n                \"react_agent\"\n            )\n            \n            # Get response from LLM with incremental streaming and parsing\n            response_buffer = \"\"\n            thinking_content = \"\"\n            thinking_started = True\n            thinking_ended = False\n            answering = False\n            content_after_thinking = \"\"\n            pre_think_buffer = \"\"\n            \n            async for token in self._execute_llm_request(react_messages, logger):\n                response_buffer += token\n                \n                # Incremental parsing for better streaming\n                if not thinking_ended:\n                    # Check for start of thinking block\n                    if not thinking_started and \"<think>\" in response_buffer:\n                        thinking_started = True\n                        # Extract any content before <think>\n                        before_think = response_buffer.split(\"<think>\")[0]\n                        if before_think:\n                            pre_think_buffer += before_think\n                        yield f'<thought>{response_buffer.split(\"<think>\")[1]}</thought>'\n                    \n                    # Check for end of thinking block\n                    if thinking_started and \"</think>\" in response_buffer:\n                        thinking_ended = True\n                        # Extract thinking content\n                        think_match = re.search(r'<think>(.*?)</think>', response_buffer, re.DOTALL)\n                        if think_match:\n                            thinking_content = (pre_think_buffer + think_match.group(1)).strip()\n                            if thinking_content:\n                                # Yield structured thinking event for Chainlit UI\n                                logger.info(f\"Agent thinking: {thinking_content}\")\n                                self.knowledge_store.add_context(\n                                    thinking_content,\n                                    ContextType.THOUGHT,\n                                    ImportanceLevel.MEDIUM,\n                                    \"react_agent\"\n                                )\n                                # Record thinking in learning loop\n                                learning_loop.record_action(\"thinking\", {\"content\": thinking_content[:200] + \"...\"})\n                        \n                        # Get content after thinking block\n                        content_after_thinking = response_buffer.rsplit(\"</think>\", 1)[-1]\n                        yield f'<token>{content_after_thinking}</token>'\n                    else:\n                        yield f'<thought>{token}</thought>'\n                else:\n                    # We're past thinking, accumulate remaining content\n                    content_after_thinking = response_buffer.rsplit(\"</think>\", 1)[-1]\n                    if answering:\n                        yield f'<token>{token}</token>'\n                    if 'Final Answer:' in content_after_thinking and not answering:\n                        answering = True\n\n            \n            # Process the complete response\n            logger.info(f\"ReAct agent response: {response_buffer}\")\n            \n            # Use extracted thinking content if available, otherwise try to extract it\n            if not thinking_content:\n                thinking_match = re.search(r'<think>(.*?)</think>', response_buffer, re.DOTALL)\n                if thinking_match:\n                    thinking_content = (pre_think_buffer + thinking_match.group(1)).strip()\n                    self.knowledge_store.add_context(\n                        thinking_content,\n                        ContextType.THOUGHT,\n                        ImportanceLevel.MEDIUM,\n                        \"react_agent\"\n                    )\n                    logger.info(f\"Agent thinking: {thinking_content}\")\n                    # Record thinking in learning loop\n                    learning_loop.record_action(\"thinking\", {\"content\": thinking_content[:200] + \"...\"})\n                    # Yield structured thinking event for Chainlit UI\n                    yield f\"<thought>{thinking_content}</thought>\"\n            \n            # Extract content after thinking markers and tool code blocks\n            content = content_after_thinking or re.split(r'</think>', response_buffer, maxsplit=1)[-1].strip()\n            logger.info(f\"Content after thinking: {content}\")\n            # Check if agent made tool calls before yielding the content\n            from server.agent import config\n            \n            # Collect tool results for streaming to UI\n            tool_results_for_ui = []\n            \n            # Create callback to capture actual tool results\n            async ", "source": {"file": "server/agent/react_agent.py", "section": "server/agent/react_agent.py:def _format_tools_compact(self)"}, "tags": ["anton_repo"]}
{"id": "b0000101", "domain": "anton_repo", "section_path": ["server/agent/react_agent.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def tool_result_callback(tool_result_summary):\n                \"\"\"Capture actual tool results for UI streaming\"\"\"\n                tool_results_for_ui.append(tool_result_summary)\n                # Record tool use in learning loop\n                learning_loop.record_action(\"tool_use\", {\n                    \"tool_name\": tool_result_summary[\"name\"],\n                    \"arguments\": tool_result_summary[\"arguments\"],\n                    \"success\": tool_result_summary[\"status\"] == \"success\"\n                })\n            \n            made_tool_calls = await process_tool_calls(\n                content, \n                config.TOOL_CALL_REGEX,  # Use existing tool call regex\n                react_messages,\n                logger,\n                self.knowledge_store,\n                tool_result_callback\n            )\n            \n            # Stream captured tool results to UI\n            for tool_result_summary in tool_results_for_ui:\n                import json\n                yield f\"<tool_result>{json.dumps(tool_result_summary)}</tool_result>\"\n            \n            if made_tool_calls:\n                self.knowledge_store.add_context(\n                    \"Tool calls made\",\n                    ContextType.ACTION,\n                    ImportanceLevel.MEDIUM,\n                    \"react_agent\"\n                )\n                pass\n            \n            # Add to conversation (use original content with tool calls for internal tracking)\n            self.knowledge_store.add_message(ASSISTANT_ROLE, content)\n            react_messages.append({\"role\": ASSISTANT_ROLE, \"content\": content})\n            \n            if made_tool_calls:\n                # If tools were called, continue the loop to let agent process results\n                logger.info(\"Tools were executed, continuing ReAct loop...\")\n                self.knowledge_store.add_context(\n                    \"Tool calls completed, processing results...\",\n                    ContextType.ACTION,\n                    ImportanceLevel.MEDIUM,\n                    \"react_agent\"\n                )\n                continue\n            else:\n                # No tool calls, check if this looks like a final response\n                if content.strip().startswith('Final Answer:'):\n                    logger.info(\"Agent provided final response, ending ReAct loop\")\n                    self.knowledge_store.mark_complete(content)\n                    \n                    # Complete learning task\n                    success = \"error\" not in content.lower() and \"failed\" not in content.lower()\n                    learning_loop.complete_task(success, content[:200])\n                    break\n                else:\n                    # Agent might need another iteration to complete the task\n                    logger.info(\"Response doesn't appear final, continuing...\")\n                    continue\n        \n        if iteration >= self.max_iterations:\n            logger.warning(f\"ReAct agent reached max iterations ({self.max_iterations})\")\n            final_msg = \"\\n\\n[Task completed - reached maximum iterations]\"\n            self.knowledge_store.add_context(\n                \"Reached maximum iterations\",\n                ContextType.THOUGHT,\n                ImportanceLevel.HIGH,\n                \"react_agent\",\n                {\"reason\": \"max_iterations\"}\n            )\n            \n            # Complete learning task as partially successful (timeout)\n            learning_loop.complete_task(False, \"Reached maximum iterations without completion\")\n            yield final_msg\n    \n    async def _execute_llm_request(\n        self,\n        messages: List[Dict[str, str]],\n        logger: Any\n    ) -> AsyncGenerator[str, None]:\n        \"\"\"\n        Execute LLM request directly, replacing dependency on doer.py\n        Tools parameter removed as it's unused by Ollama - tools are described in system prompt instead.\n        \"\"\"\n        request_payload = {\n            \"messages\": messages,\n            \"temperature\": 0.6,\n            'complex': True,\n        }\n\n        async with httpx.AsyncClient(timeout=None) as client:\n            try:\n                async with client.stream(\"POST\", f\"{self.api_base_url}/v1/chat/stream\", json=request_payload) as response:\n                    response.raise_for_status()\n                    last_emitted = \"\"  # track cumulative text we've already emitted\n                    async for chunk in response.aiter_text():\n                        for raw in chunk.split(\"\\n\"):\n                            if not raw.strip():\n                                continue\n                            if raw.startswith(\"data: \"):\n                                payload = raw[6:]\n                                if payload == \"[DONE]\":\n                                    return\n                                # Try JSON; fall back to raw text\n                                try:\n                                    obj = json.loads(payload)\n                                    # common keys: \"delta\", \"content\", \"message\"\n                                    piece = obj.get(\"delta\") or obj.get(\"content\") or obj.get(\"message\") or \"\"\n                                except Exception:\n                                    piece = payload\n\n                                # If the server sends cumulative text, only emit the new suffix\n                                if piece.startswith(last_emitted):\n                                    delta = piece[len(last_emitted):]\n                                else:\n                                    # not cumulative; treat as incremental\n                                    delta = piece\n                                if delta:\n                                    last_emitted = piece if piece.startswith(last_emitted) else last_emitted + delta\n                                    yield delta\n\n            except httpx.RequestError as e:\n                logger.error(f\"ReActAgent: API request to model server failed: {e}\")\n                yield f\"\\n[ERROR: Could not connect to the model server: {e}]\\n\"\n            except Exception as e:\n                logger.error(f\"ReActAgent: An unexpected error occurred during model streaming: {e}\", exc_info=True)\n                yield f\"\\n[ERROR: An unexpected error occurred: {e}]\\n\"", "source": {"file": "server/agent/react_agent.py", "section": "server/agent/react_agent.py:def tool_result_callback(tool_result_summary)"}, "tags": ["anton_repo"]}
{"id": "b0000102", "domain": "anton_repo", "section_path": ["server/agent/react_agent.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "# filepath: /home/lucas/anton_new/server/agent/react_agent.py\n\"\"\"\nReAct (Reason-Act) Agent implementation that handles the complete reasoning and tool-use loop.\nCentralized state management through KnowledgeStore, eliminating ConversationState redundancy.\n\"\"\"\nimport json\nimport re\nimport time\nimport logging\nfrom urllib import response\nimport httpx\nfrom typing import AsyncGenerator, List, Dict, Any, Optional\n\nfrom torch import chunk\n\nfrom server.agent.knowledge_store import KnowledgeStore, ContextType, ImportanceLevel\nfrom server.agent.tool_executor import process_tool_calls\nfrom server.agent.config import SYSTEM_ROLE, ASSISTANT_ROLE, USER_ROLE\nfrom server.agent.learning_loop import learning_loop\n\nlogger = logging.getLogger(__name__)\n\nclass ReActAgent:\n    \"\"\"\n    Single-agent ReAct implementation that combines reasoning and acting in one flow.\n    Uses KnowledgeStore for centralized state management and includes direct LLM interaction.\n    \"\"\"\n    \n    ", "source": {"file": "server/agent/react_agent.py", "section": "server/agent/react_agent.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000103", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class CapabilityConfidence(Enum):\n    LOW = \"low\"         # Initial evidence observed\n    MEDIUM = \"medium\"   # Multiple evidence points observed\n    HIGH = \"high\"       # Consistently demonstrated\n\n\nclass LearningLoop:\n    \"\"\"\n    Central class responsible for managing the agent's learning cycle with\n    asynchronous capability tracking and LLM-powered analysis.\n    \"\"\"\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:class CapabilityConfidence(Enum)"}, "tags": ["anton_repo"]}
{"id": "b0000104", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base_url: str = MODEL_SERVER_URL):\n        self.current_task: Optional[Dict] = None\n        self.experiences: List[Dict] = []\n        self.reflection_frequency: int = 5  # Number of tasks before triggering reflection\n        self.tasks_since_reflection: int = 0\n        self.performance_metrics: Dict[str, List[float]] = {\n            \"success_rate\": [],\n            \"task_duration\": [],\n            \"steps_taken\": []\n        }\n        \n        # Capability tracking\n        self.capabilities: Dict[str, Dict] = {}\n        self.capability_domains: Set[str] = {\n            \"file_operations\", \"code_generation\", \"data_analysis\", \n            \"web_interaction\", \"problem_solving\", \"explanation\",\n            \"tool_use\", \"planning\", \"reasoning\", \"learning\"\n        }\n        self.capability_evidence_threshold: int = 2  # Min examples needed to confirm capability\n        \n        # For async processing\n        self.api_base_url = api_base_url\n        self._executor = ThreadPoolExecutor(max_workers=3)\n        self._processing_queue = asyncio.Queue()\n        self._is_processing = False\n        self._background_task = None\n        \n        # Start background processing\n        self._start_background_processing()\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def __init__(self, api_base_url: str = MODEL_SERVER_URL)"}, "tags": ["anton_repo"]}
{"id": "b0000105", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _start_background_processing(self):\n        \"\"\"Start background task for processing capabilities and reflections\"\"\"\n        loop = asyncio.get_event_loop()\n        self._background_task = asyncio.create_task(self._process_queue())\n        logger.info(\"Started background processing for learning loop\")\n        \n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _start_background_processing(self)"}, "tags": ["anton_repo"]}
{"id": "b0000106", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _process_queue(self):\n        \"\"\"Process tasks in the background\"\"\"\n        self._is_processing = True\n        try:\n            while True:\n                try:\n                    task_type, task_data = await self._processing_queue.get()\n                    \n                    if task_type == \"capability_analysis\":\n                        await self._analyze_capability_with_llm(**task_data)\n                    elif task_type == \"reflection\":\n                        await self._reflect_on_experiences_with_llm(**task_data)\n                    \n                    self._processing_queue.task_done()\n                except Exception as e:\n                    logger.error(f\"Error in background processing: {e}\", exc_info=True)\n                    await asyncio.sleep(1)  # Prevent tight loop if errors occur\n        except asyncio.CancelledError:\n            logger.info(\"Background processing task cancelled\")\n            self._is_processing = False\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _process_queue(self)"}, "tags": ["anton_repo"]}
{"id": "b0000107", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def start_task(self, task_prompt: str) -> None:\n        \"\"\"Begins tracking a new task.\"\"\"\n        self.current_task = {\n            \"prompt\": task_prompt,\n            \"start_time\": time.time(),\n            \"actions\": [],\n            \"success\": False,\n            \"feedback\": \"\",\n            \"steps_taken\": 0,\n            \"potential_capabilities\": self._identify_potential_capabilities(task_prompt),\n        }\n        logger.info(f\"Learning loop tracking started for task: {task_prompt[:50]}...\")\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def start_task(self, task_prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000108", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def record_action(self, action_type: str, action_details: Dict) -> None:\n        \"\"\"Records an action taken during the current task.\"\"\"\n        if not self.current_task:\n            logger.warning(\"Attempted to record action but no task is being tracked\")\n            return\n\n        self.current_task[\"actions\"].append({\n            \"type\": action_type,\n            \"details\": action_details,\n            \"timestamp\": time.time()\n        })\n        self.current_task[\"steps_taken\"] += 1\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def record_action(self, action_type: str, action_details: Dict)"}, "tags": ["anton_repo"]}
{"id": "b0000109", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def complete_task(self, success: bool, feedback: str) -> Dict:\n        \"\"\"\n        Completes the current task and triggers reflection if needed.\n        This method is synchronous but queues async processing.\n        \"\"\"\n        if not self.current_task:\n            logger.warning(\"Attempted to complete task but no task is being tracked\")\n            return {}\n\n        self.current_task[\"success\"] = success\n        self.current_task[\"feedback\"] = feedback\n        self.current_task[\"end_time\"] = time.time()\n        self.current_task[\"duration\"] = self.current_task[\"end_time\"] - self.current_task[\"start_time\"]\n\n        # Store this experience\n        self.experiences.append(self.current_task)\n\n        logger.info(f\"Task completed (success: {success})\")\n        logger.debug('Task details:\\n' + json.dumps(self.current_task, indent=4))\n\n        # Update performance metrics\n        self.performance_metrics[\"success_rate\"].append(1.0 if success else 0.0)\n        self.performance_metrics[\"task_duration\"].append(self.current_task[\"duration\"])\n        self.performance_metrics[\"steps_taken\"].append(self.current_task[\"steps_taken\"])\n\n        # Queue capability analysis if the task was successful\n        if success:\n            logger.info(\"Queueing asynchronous capability analysis\")\n            task_data = {\"task\": self.current_task.copy()}\n            asyncio.create_task(self._add_to_queue(\"capability_analysis\", task_data))\n\n        # Queue reflection if we've reached the frequency threshold\n        self.tasks_since_reflection += 1\n        if self.tasks_since_reflection >= self.reflection_frequency:\n            logger.info(\"Queueing asynchronous reflection\")\n            recent_experiences = self.experiences[-self.reflection_frequency:]\n            task_data = {\"experiences\": recent_experiences}\n            asyncio.create_task(self._add_to_queue(\"reflection\", task_data))\n            self.tasks_since_reflection = 0\n\n        completed_task = self.current_task.copy()\n        self.current_task = None\n        return completed_task\n    \n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def complete_task(self, success: bool, feedback: str)"}, "tags": ["anton_repo"]}
{"id": "b0000110", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def _add_to_queue(self, task_type: str, task_data: Dict):\n        \"\"\"Add a task to the processing queue\"\"\"\n        await self._processing_queue.put((task_type, task_data))\n        \n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _add_to_queue(self, task_type: str, task_data: Dict)"}, "tags": ["anton_repo"]}
{"id": "b0000111", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def _analyze_capability_with_llm(self, task: Dict) -> None:\n        \"\"\"\n        Uses the LLM to analyze capabilities demonstrated in a completed task.\n        This runs asynchronously to avoid blocking the main process.\n        \"\"\"\n        if not task.get(\"success\", False):\n            logger.info(\"Skipping capability analysis for unsuccessful task\")\n            return\n            \n        try:\n            logger.info(f\"Analyzing capabilities for task: {task['prompt'][:50]}...\")\n            \n            # Create a prompt for capability analysis\n            actions_text = \"\\n\".join([\n                f\"- {i+1}. {action['type']}: {json.dumps(action['details'])[:100]}...\"\n                for i, action in enumerate(task.get(\"actions\", []))\n            ])\n            \n            prompt = f\"\"\"Analyze the completed task and identify capabilities that were demonstrated.\n            \nTask prompt: {task['prompt']}\n\nActions taken:\n{actions_text}\n\nFeedback: {task.get('feedback', 'No feedback provided')}\n\nIdentify the specific capabilities demonstrated in this task. Consider the following capability domains:\n{', '.join(self.capability_domains)}\n\nFor each capability you identify:\n1. Provide the capability name\n2. Rate the confidence level (LOW, MEDIUM, HIGH) that this capability was demonstrated\n3. Explain the specific evidence from the task that demonstrates this capability\n4. Describe the approach used to demonstrate this capability\n5. Suggest how this capability could be improved\n\nFormat your response as JSON with this structure:\n{{\n    \"capabilities\": [\n        {{\n            \"name\": \"capability_name\",\n            \"confidence\": \"MEDIUM\",\n            \"evidence\": \"specific evidence from the task\",\n            \"approach\": \"approach used to demonstrate this capability\",\n            \"improvement\": \"how this capability could be improved\"\n        }}\n    ]\n}}\n\nThink carefully about which capabilities were truly demonstrated. Only include capabilities with clear evidence.\n\"\"\"\n\n            # Call the LLM for capability analysis\n            messages = [\n                {\"role\": SYSTEM_ROLE, \"content\": \"You are a capability analyzer for an AI system. Analyze completed tasks to identify capabilities.\"},\n                {\"role\": USER_ROLE, \"content\": prompt}\n            ]\n            \n            response = await self._call_llm_api(messages)\n            \n            # Parse the LLM response to extract capability data\n            capability_data = self._extract_json_from_response(response)\n            \n            if not capability_data or \"capabilities\" not in capability_data:\n                logger.warning(\"Failed to extract capability data from LLM response\")\n                return\n                \n            # Update capability registry with the analysis results\n            for capability in capability_data[\"capabilities\"]:\n                await self._register_capability_evidence(\n                    capability[\"name\"], \n                    task,\n                    capability[\"confidence\"], \n                    capability[\"evidence\"],\n                    capability[\"approach\"],\n                    capability.get(\"improvement\", \"\")\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error during capability analysis: {e}\", exc_info=True)\n    \n    async def _register_capability_evidence(\n        self, \n        capability_name: str, \n        task: Dict, \n        confidence_level: str, \n        evidence_text: str,\n        approach_text: str,\n        improvement_text: str\n    ) -> None:\n        \"\"\"\n        Registers evidence of a capability in the system.\n        \"\"\"\n        capability_name = capability_name.lower().strip()\n        # Normalize domain name to match our predefined set\n        matched_domain = self._match_capability_domain(capability_name)\n        \n        if not matched_domain:\n            logger.warning(f\"Capability '{capability_name}' doesn't match any known domain\")\n            return\n            \n        # Convert confidence level string to enum\n        try:\n            confidence = CapabilityConfidence[confidence_level.upper()]\n        except (KeyError, AttributeError):\n            confidence = CapabilityConfidence.LOW\n        \n        # Create evidence record\n        evidence = {\n            \"task_prompt\": task[\"prompt\"],\n            \"evidence_text\": evidence_text,\n            \"approach\": approach_text,\n            \"improvement\": improvement_text,\n            \"actions\": [action[\"type\"] for action in task[\"actions\"]],\n            \"timestamp\": time.time(),\n            \"duration\": task[\"duration\"],\n            \"steps_taken\": task[\"steps_taken\"],\n            \"confidence\": confidence.value\n        }\n        \n        # Update capabilities registry\n        if matched_domain not in self.capabilities:\n            # Create new capability entry\n            self.capabilities[matched_domain] = {\n                \"first_seen\": time.time(),\n                \"evidence\": [evidence],\n                \"confidence\": confidence.value,\n                \"best_evidence\": evidence,\n                \"improvement_suggestions\": [improvement_text] if improvement_text else []\n            }\n            logger.info(f\"Registered first evidence of capability: {matched_domain}\")\n            \n            # Create initial knowledge entry for this capability\n            await self._create_capability_knowledge(matched_domain, evidence)\n            \n        else:\n            # Update existing capability\n            self.capabilities[matched_domain][\"evidence\"].append(evidence)\n            evidence_count = len(self.capabilities[matched_domain][\"evidence\"])\n            \n            # Update confidence based on evidence count and this evidence's confidence\n            confidence_values = [CapabilityConfidence[e[\"confidence\"].upper()].value \n                               if isinstance(e[\"confidence\"], str) else e[\"confidence\"] \n                               for e in self.capabilities[matched_domain][\"evidence\"]]\n            \n            # Use the most frequent confidence level\n            from collections import Counter\n            most_common_confidence = Counter(confidence_values).most_common(1)[0][0]\n            self.capabilities[matched_domain][\"confidence\"] = most_common_confidence\n                \n            # Check if this is better evidence (higher confidence or fewer steps)\n            current_best = self.capabilities[matched_domain][\"best_evidence\"]\n            current_best_confidence = CapabilityConfidence[current_best[\"confidence\"].upper()].value if isinstance(current_best[\"confidence\"], str) else current_best[\"confidence\"]\n            new_confidence = confidence.value\n            \n            if (new_confidence > current_best_confidence or \n                (new_confidence == current_best_confidence and evidence[\"steps_taken\"] < current_best[\"steps_taken\"])):\n                self.capabilities[matched_domain][\"best_evidence\"] = evidence\n                \n                # Update RAG knowledge with this better evidence\n                await self._create_capability_knowledge(matched_domain, evidence)\n                \n            # Add unique improvement suggestion\n            if improvement_text and improvement_text not in self.capabilities[matched_domain][\"improvement_suggestions\"]:\n                self.capabilities[matched_domain][\"improvement_suggestions\"].append(improvement_text)\n                \n            logger.info(f\"Added evidence for capability: {matched_domain} (total: {evidence_count})\")\n\n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _analyze_capability_with_llm(self, task: Dict)"}, "tags": ["anton_repo"]}
{"id": "b0000112", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def _create_capability_knowledge(self, capability_domain: str, evidence: Dict) -> None:\n        \"\"\"Creates knowledge entries for capability evidence\"\"\"\n        capability_learning = (\n            f\"CAPABILITY EVIDENCE - {capability_domain}: \"\n            f\"I have demonstrated the ability to {evidence['approach']}. \"\n            f\"Evidence: {evidence['evidence_text'][:200]}. \"\n            f\"This took {evidence['steps_taken']} steps and {evidence['duration']:.1f} seconds.\"\n        )\n        \n        if evidence.get(\"improvement\"):\n            capability_learning += f\" To improve: {evidence['improvement']}\"\n        \n        # Store in RAG system with specific metadata for capabilities\n        rag_manager.add_knowledge(\n            text=capability_learning,\n            source=f\"capability_{capability_domain}_{int(time.time())}\",\n        )\n        logger.info(f\"Created knowledge entry for capability: {capability_domain}\")\n\n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _create_capability_knowledge(self, capability_domain: str, evidence: Dict)"}, "tags": ["anton_repo"]}
{"id": "b0000113", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def _reflect_on_experiences_with_llm(self, experiences: List[Dict]) -> None:\n        \"\"\"\n        Uses the LLM to reflect on experiences and extract patterns/learnings.\n        This runs asynchronously to avoid blocking the main process.\n        \"\"\"\n        if not experiences:\n            logger.info(\"No experiences to reflect on\")\n            return\n            \n        successful_experiences = [exp for exp in experiences if exp.get(\"success\", False)]\n        \n        if not successful_experiences:\n            logger.info(\"No successful experiences to learn from in recent tasks\")\n            return\n            \n        try:\n            logger.info(\"Reflecting on recent experiences...\")\n            \n            # Format experiences for the prompt\n            experiences_text = \"\"\n            for i, exp in enumerate(successful_experiences[:5]):  # Limit to 5 experiences\n                actions_summary = \", \".join([action[\"type\"] for action in exp.get(\"actions\", [])][:5])\n                experiences_text += f\"\"\"\nExperience {i+1}:\n- Task: {exp[\"prompt\"][:200]}...\n- Actions: {actions_summary}...\n- Success: {exp[\"success\"]}\n- Steps: {exp[\"steps_taken\"]}\n- Duration: {exp[\"duration\"]:.1f} seconds\n\"\"\"\n                \n            prompt = f\"\"\"Reflect on these successful task experiences and extract patterns, insights, and learnings:\n\n{experiences_text}\n\nFor each pattern or insight you identify:\n1. Describe the pattern or insight\n2. Explain how it can be applied to future tasks\n3. Note any conditions or limitations of this pattern\n\nFormat your response as JSON with this structure:\n{{\n    \"learnings\": [\n        {{\n            \"pattern\": \"description of the pattern\",\n            \"application\": \"how to apply this pattern\",\n            \"conditions\": \"when this pattern is applicable\",\n            \"task_types\": [\"list\", \"of\", \"relevant\", \"task\", \"types\"]\n        }}\n    ]\n}}\n\nFocus on extracting meaningful, actionable patterns that would help an AI assistant perform better on future tasks.\n\"\"\"\n\n            # Call LLM for reflection\n            messages = [\n                {\"role\": SYSTEM_ROLE, \"content\": \"You are a reflection system for an AI assistant, extracting learnings from past experiences.\"},\n                {\"role\": USER_ROLE, \"content\": prompt}\n            ]\n            \n            response = await self._call_llm_api(messages)\n            \n            # Parse the response to extract learnings\n            reflection_data = self._extract_json_from_response(response)\n            \n            if not reflection_data or \"learnings\" not in reflection_data:\n                logger.warning(\"Failed to extract learning data from LLM response\")\n                return\n                \n            # Store learnings in the RAG system\n            for learning in reflection_data[\"learnings\"]:\n                learning_text = (\n                    f\"PATTERN: {learning['pattern']} \"\n                    f\"APPLICATION: {learning['application']} \"\n                    f\"CONDITIONS: {learning['conditions']}\"\n                )\n                \n                # Add task type tags for better retrieval\n                task_types = learning.get(\"task_types\", [])\n                \n                # Store in RAG system with metadata\n                rag_manager.add_knowledge(\n                    text=learning_text,\n                    source=f\"reflection_{int(time.time())}\",\n                )\n                logger.info(f\"Stored new learning pattern: {learning['pattern'][:50]}...\")\n                \n        except Exception as e:\n            logger.error(f\"Error during reflection process: {e}\", exc_info=True)\n\n    async ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _reflect_on_experiences_with_llm(self, experiences: List[Dict])"}, "tags": ["anton_repo"]}
{"id": "b0000114", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def get_relevant_learnings(self, current_prompt: str) -> List[str]:\n        \"\"\"Retrieves relevant past learnings for the current task.\"\"\"\n        try:\n            # Identify potential capability domains\n            potential_domains = self._identify_potential_capabilities(current_prompt)\n            \n            # Build a more focused query combining the prompt with capability domains\n            enhanced_query = current_prompt\n            if potential_domains:\n                domain_text = \" \".join(potential_domains)\n                enhanced_query = f\"{current_prompt} {domain_text}\"\n            \n            # Get relevant documents with metadata filtering\n            relevant_docs = rag_manager.retrieve_knowledge(\n                query=enhanced_query, \n                top_k=5,\n            )\n            \n            # Get capability-specific evidence\n            capability_learnings = []\n            for domain in potential_domains:\n                if domain in self.capabilities and self.capabilities[domain][\"confidence\"] != CapabilityConfidence.LOW.value:\n                    best_evidence = self.capabilities[domain].get(\"best_evidence\")\n                    if best_evidence:\n                        capability_learnings.append(\n                            f\"CAPABILITY ({domain}): {best_evidence['approach']} (confidence: {self.capabilities[domain]['confidence']})\"\n                        )\n            \n            # Combine and deduplicate learnings\n            all_learnings = [doc[\"text\"] for doc in relevant_docs] + capability_learnings\n            return list(dict.fromkeys(all_learnings))  # Remove duplicates while preserving order\n            \n        except Exception as e:\n            logger.error(f\"Error retrieving relevant learnings: {e}\", exc_info=True)\n            return []\n\n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def get_relevant_learnings(self, current_prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000115", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def get_performance_report(self) -> Dict:\n        \"\"\"Generates a report on the agent's learning progress.\"\"\"\n        if not self.performance_metrics[\"success_rate\"]:\n            return {\"error\": \"No performance data available yet\"}\n\n        # Calculate moving averages\n        window_size = min(10, len(self.performance_metrics[\"success_rate\"]))\n        recent_success_rate = sum(self.performance_metrics[\"success_rate\"][-window_size:]) / window_size\n\n        # Calculate improvement trends\n        improvement = {}\n        for metric, values in self.performance_metrics.items():\n            if len(values) >= window_size * 2:\n                earlier_avg = sum(values[-window_size * 2:-window_size]) / window_size\n                recent_avg = sum(values[-window_size:]) / window_size\n                if metric == \"success_rate\":\n                    improvement[metric] = recent_avg - earlier_avg\n                else:\n                    # For duration and steps, lower is better\n                    improvement[metric] = earlier_avg - recent_avg\n\n        # Add capability information to the report\n        capability_summary = {\n            \"total_capabilities\": len(self.capabilities),\n            \"capability_domains\": {\n                domain: {\n                    \"evidence_count\": len(data[\"evidence\"]),\n                    \"confidence\": data.get(\"confidence\", CapabilityConfidence.LOW.value)\n                }\n                for domain, data in self.capabilities.items()\n            },\n            \"strongest_capabilities\": sorted(\n                [(domain, data.get(\"confidence\", CapabilityConfidence.LOW.value)) \n                for domain, data in self.capabilities.items()],\n                key=lambda x: (\n                    0 if x[1] == CapabilityConfidence.HIGH.value else \n                    1 if x[1] == CapabilityConfidence.MEDIUM.value else 2,\n                    -len(self.capabilities[x[0]][\"evidence\"])\n                )\n            )[:3]\n        }\n\n        return {\n            \"total_tasks\": len(self.experiences),\n            \"recent_success_rate\": recent_success_rate,\n            \"improvement_trends\": improvement,\n            \"learnings_count\": rag_manager.index.ntotal if hasattr(rag_manager, 'index') else \"unknown\",\n            \"capabilities\": capability_summary\n        }\n        \n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def get_performance_report(self)"}, "tags": ["anton_repo"]}
{"id": "b0000116", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def get_capability_evidence(self, capability_domain: str) -> List[Dict]:\n        \"\"\"\n        Retrieves evidence of a specific capability.\n        Returns examples of the agent demonstrating this capability.\n        \"\"\"\n        if capability_domain not in self.capabilities:\n            return []\n        \n        return self.capabilities[capability_domain][\"evidence\"]\n    \n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def get_capability_evidence(self, capability_domain: str)"}, "tags": ["anton_repo"]}
{"id": "b0000117", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def get_capabilities_by_confidence(self, min_confidence: CapabilityConfidence = CapabilityConfidence.MEDIUM) -> Dict[str, Dict]:\n        \"\"\"\n        Returns capabilities that meet or exceed the given confidence level.\n        \"\"\"\n        return {\n            domain: data for domain, data in self.capabilities.items()\n            if data.get(\"confidence\", CapabilityConfidence.LOW.value) >= min_confidence.value\n        }\n\n    async def _call_llm_api(\n        self,\n        messages: List[Dict[str, str]],\n    ) -> str:\n        \"\"\"\n        Execute LLM request directly, replacing dependency on doer.py\n        Tools parameter removed as it's unused by Ollama - tools are described in system prompt instead.\n        \"\"\"\n        request_payload = {\n            \"messages\": messages,\n            \"temperature\": 0.6,\n            'complex': True,\n        }\n\n        async with httpx.AsyncClient(timeout=None) as client:\n            try:\n                async with client.stream(\"POST\", f\"{self.api_base_url}/v1/chat/stream\", json=request_payload) as response:\n                    response.raise_for_status()\n                    \n                    full_response_content = \"\"\n                    # Iterate over the streamed chunks\n                    async for chunk in response.aiter_text():\n                        for line in chunk.split('\\n'):\n                            if line.startswith('data: '):\n                                content = line[6:]  # Remove 'data: ' prefix\n                                if content == '[DONE]':\n                                    return\n                                full_response_content += content\n                            elif line.strip():\n                                # Fallback for non-SSE format\n                                full_response_content += line\n                learning_response = full_response_content.split('</think>')[1] if len(full_response_content.split('</think>')) > 1 else full_response_content\n                logger.info(f\"ReActAgent: Received response from model server: {learning_response}...\")\n                return learning_response\n\n            except httpx.RequestError as e:\n                # Added self here to match your original method signature\n                logger.error(f\"ReActAgent: API request to model server failed: {e}\")\n                return f\"\\n[ERROR: Could not connect to the model server: {e}]\\n\"\n            except Exception as e:\n                logger.error(f\"ReActAgent: An unexpected error occurred during model streaming: {e}\", exc_info=True)\n                return f\"\\n[ERROR: An unexpected error occurred: {e}]\\n\"\n    \n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def get_capabilities_by_confidence(self, min_confidence: CapabilityConfidence = CapabilityConfidence.MEDIUM)"}, "tags": ["anton_repo"]}
{"id": "b0000118", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def _extract_json_from_response(self, response: str) -> Dict:\n        \"\"\"Extract JSON from LLM response, handling various formats\"\"\"\n        try:\n            # Try direct JSON parsing\n            return json.loads(response)\n        except json.JSONDecodeError:\n            # Try to extract JSON from text\n            import re\n            json_match = re.search(r'```json\\n(.*?)\\n```', response, re.DOTALL)\n            if json_match:\n                try:\n                    return json.loads(json_match.group(1))\n                except json.JSONDecodeError:\n                    pass\n                    \n            # Try to find any JSON-like structure\n            json_pattern = re.search(r'({[\\s\\S]*})', response)\n            if json_pattern:\n                try:\n                    return json.loads(json_pattern.group(1))\n                except json.JSONDecodeError:\n                    pass\n                    \n            logger.warning(\"Could not extract valid JSON from response\")\n            return {}\n        \n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _extract_json_from_response(self, response: str)"}, "tags": ["anton_repo"]}
{"id": "b0000119", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "def _identify_potential_capabilities(self, prompt: str) -> List[str]:\n        \"\"\"\n        Identifies which capability domains a task might involve.\n        Uses simple keyword matching but could use more sophisticated classification.\n        \"\"\"\n        domains = []\n        prompt_lower = prompt.lower()\n        \n        domain_keywords = {\n            \"file_operations\": [\"file\", \"read\", \"write\", \"save\", \"open\", \"directory\", \"folder\", \"path\"],\n            \"code_generation\": [\"code\", \"function\", \"script\", \"program\", \"implement\", \"develop\", \"programming\"],\n            \"data_analysis\": [\"data\", \"analyze\", \"csv\", \"statistics\", \"plot\", \"dataset\", \"visualization\"],\n            \"web_interaction\": [\"web\", \"url\", \"http\", \"api\", \"request\", \"website\", \"browser\", \"internet\"],\n            \"problem_solving\": [\"solve\", \"problem\", \"puzzle\", \"challenge\", \"solution\", \"figure out\", \"resolve\"],\n            \"explanation\": [\"explain\", \"describe\", \"summarize\", \"how does\", \"what is\", \"why\", \"teach\"],\n            \"tool_use\": [\"use\", \"tool\", \"execute\", \"run\", \"apply\", \"utility\", \"command\"],\n            \"planning\": [\"plan\", \"steps\", \"strategy\", \"approach\", \"roadmap\", \"organize\", \"structure\"],\n            \"reasoning\": [\"reason\", \"logic\", \"deduce\", \"infer\", \"why\", \"because\", \"therefore\", \"conclude\"],\n            \"learning\": [\"learn\", \"adapt\", \"improve\", \"train\", \"understand\", \"study\", \"practice\"]\n        }\n        \n        for domain, keywords in domain_keywords.items():\n            if any(keyword in prompt_lower for keyword in keywords):\n                domains.append(domain)\n                \n        return domains\n    \n    ", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _identify_potential_capabilities(self, prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000120", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 18, "block_index": 1, "block_type": "code", "text": "def _match_capability_domain(self, capability_name: str) -> Optional[str]:\n        \"\"\"Match a capability name to a standard domain\"\"\"\n        capability_lower = capability_name.lower()\n        \n        # Direct match\n        if capability_lower in self.capability_domains:\n            return capability_lower\n            \n        # Fuzzy match based on substring\n        for domain in self.capability_domains:\n            if domain in capability_lower or capability_lower in domain:\n                return domain\n                \n        # Keyword-based matching as fallback\n        domain_keywords = {\n            \"file_operations\": [\"file\", \"directory\", \"folder\", \"read\", \"write\"],\n            \"code_generation\": [\"code\", \"program\", \"script\", \"implement\"],\n            \"data_analysis\": [\"data\", \"analysis\", \"statistics\", \"visualization\"],\n            \"web_interaction\": [\"web\", \"http\", \"api\", \"request\"],\n            \"problem_solving\": [\"problem\", \"solution\", \"solve\", \"resolve\"],\n            \"explanation\": [\"explain\", \"description\", \"summarize\"],\n            \"tool_use\": [\"tool\", \"utility\", \"execute\", \"run\"],\n            \"planning\": [\"plan\", \"strategy\", \"steps\", \"approach\"],\n            \"reasoning\": [\"reason\", \"logic\", \"inference\", \"deduction\"],\n            \"learning\": [\"learn\", \"adapt\", \"improve\", \"study\"]\n        }\n        \n        for domain, keywords in domain_keywords.items():\n            if any(keyword in capability_lower for keyword in keywords):\n                return domain\n                \n        # No match found\n        return None\n\n\n# Singleton instance\nlearning_loop = LearningLoop()", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:def _match_capability_domain(self, capability_name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000121", "domain": "anton_repo", "section_path": ["server/agent/learning_loop.py"], "page": 19, "block_index": 1, "block_type": "code", "text": "\"\"\"\nManages the agent's learning loop process:\n1. Experience collection\n2. Reflection\n3. Knowledge storage \n4. Knowledge application\n5. Performance tracking\n6. Capability evidence tracking\n\"\"\"\n\nimport logging\nimport json\nimport time\nimport asyncio\nimport httpx\nfrom typing import AsyncGenerator, Dict, List, Any, Optional, Set\nfrom enum import Enum\nfrom concurrent.futures import ThreadPoolExecutor\nfrom server.agent.rag_manager import rag_manager\nfrom server.agent.config import MODEL_SERVER_URL, SYSTEM_ROLE, ASSISTANT_ROLE, USER_ROLE\n\nlogger = logging.getLogger(__name__)\n\n\n", "source": {"file": "server/agent/learning_loop.py", "section": "server/agent/learning_loop.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000122", "domain": "anton_repo", "section_path": ["server/agent/config.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def get_generation_kwargs(tokenizer: Any, temperature: float = 0.6, max_new_tokens: int = 1024) -> dict[str, Any]:\n    \"\"\"Constructs the generation arguments for the model.\"\"\"\n    return {\n        \"max_new_tokens\": max_new_tokens,\n        \"pad_token_id\": tokenizer.eos_token_id,\n        \"do_sample\": True,\n        \"temperature\": temperature,\n        \"top_p\": 0.95,\n        \"top_k\": 20,\n        \"min_p\": 0,\n    }", "source": {"file": "server/agent/config.py", "section": "server/agent/config.py:def get_generation_kwargs(tokenizer: Any, temperature: float = 0.6, max_new_tokens: int = 1024)"}, "tags": ["anton_repo"]}
{"id": "b0000123", "domain": "anton_repo", "section_path": ["server/agent/config.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "# agent/config.py\n\n\"\"\"\nCentral configuration for the agent, including model parameters and constants.\n\"\"\"\nimport re\nfrom typing import Any\n\n# --- Agent Behavior ---\nMAX_TURNS = 10\nLOOP_DETECTION_THRESHOLD = 2\n# --- Roles ---\nUSER_ROLE = \"user\"\nASSISTANT_ROLE = \"assistant\"\nSYSTEM_ROLE = \"system\"\n\nAGENT_SERVER_HOST = \"0.0.0.0\"\nAGENT_SERVER_PORT = 8001\nMODEL_SERVER_URL = \"http://localhost:8000\"\n\n# --- Regex Patterns ---\nTOOL_CALL_REGEX = re.compile(r\"<tool_(?:code|call)>(.*?)</tool_(?:code|call)>\", re.DOTALL)\nTHOUGHT_SUMMARY_REGEX = re.compile(r\"<thought_summary>(.*?)</thought_summary>\", re.DOTALL)\nSENTENCE_END_REGEX = re.compile(r\"[.?!](?:\\s|$)\")\n\n", "source": {"file": "server/agent/config.py", "section": "server/agent/config.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000124", "domain": "anton_repo", "section_path": ["server/agent/tool_executor.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def execute_tool_async(tool_name: str, tool_args: dict, logger) -> str:\n    \"\"\"\n    Looks up a tool by name in the registry and executes it with the given arguments.\n    Uses asyncio.to_thread to run blocking IO-bound tools in a thread pool.\n    \"\"\"\n    try:\n        logger.info(f\"Executing tool '{tool_name}' with args: {tool_args}\")\n        # Run the potentially blocking tool in a thread pool\n        result = await asyncio.to_thread(tool_manager.run_tool, tool_name, tool_args)\n        return result\n    except Exception as e:\n        logger.error(f\"Error executing tool '{tool_name}': {e}\", exc_info=True)\n        return f'{{\"error\": \"Failed to execute tool: {str(e)}\"}}'\n\n\n", "source": {"file": "server/agent/tool_executor.py", "section": "server/agent/tool_executor.py:def execute_tool_async(tool_name: str, tool_args: dict, logger)"}, "tags": ["anton_repo"]}
{"id": "b0000125", "domain": "anton_repo", "section_path": ["server/agent/tool_executor.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def execute_tool(tool_name: str, tool_args: dict, logger) -> str:\n    \"\"\"\n    Synchronous version for backward compatibility.\n    Looks up a tool by name in the registry and executes it with the given arguments.\n    \"\"\"\n    try:\n        logger.info(f\"Executing tool '{tool_name}' with args: {tool_args}\")\n        # Assumes the tool's value is a dict with a 'run' callable\n        result = tool_manager.run_tool(tool_name, tool_args)\n        return json.dumps(result)\n    except Exception as e:\n        logger.error(f\"Error executing tool '{tool_name}': {e}\", exc_info=True)\n        return f'{{\"error\": \"Failed to execute tool: {str(e)}\"}}'", "source": {"file": "server/agent/tool_executor.py", "section": "server/agent/tool_executor.py:def execute_tool(tool_name: str, tool_args: dict, logger)"}, "tags": ["anton_repo"]}
{"id": "b0000126", "domain": "anton_repo", "section_path": ["server/agent/tool_executor.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "# agent/tool_executor.py\n\n\"\"\"\nHandles the execution of tools from the tool registry.\n\"\"\"\n\nimport html\nfrom server.agent.tools.tool_manager import tool_manager\n\n# agent/tool_handler.py\n\n\"\"\"\nHandles parsing and execution of tool calls from the model's output.\n\"\"\"\nimport json\nimport asyncio\nfrom typing import Any\n\n\nasync def process_tool_calls(\n        response_buffer: str,\n        tool_call_regex: Any,\n        messages: list[dict],\n        logger: Any,\n        knowledge_store = None,  # Updated parameter to use KnowledgeStore\n        result_callback = None  # Callback to stream tool results to UI\n) -> bool:\n    \"\"\"\n    Parses and executes all tool calls from the model's response buffer.\n    Now updates a knowledge store with information about accessed files and tool results.\n    Executes independent tool calls in parallel for better performance.\n\n    Returns:\n        True if at least one tool was called, False otherwise.\n    \"\"\"\n    tool_calls_made = False\n    response_buffer = html.unescape(response_buffer)\n    matches = tool_call_regex.finditer(response_buffer)\n\n    # Collect all tool calls first\n    tool_calls = []\n    for match in matches:\n        tool_calls_made = True\n        tool_call_content = match.group(1).strip()\n\n        try:\n            tool_data = json.loads(tool_call_content)\n            tool_name = tool_data.get(\"name\")\n            if not tool_name:\n                raise KeyError(\"'name' not found in tool data.\")\n            \n            tool_args = tool_data.get(\"arguments\", {})\n            tool_calls.append({\n                \"name\": tool_name,\n                \"arguments\": tool_args,\n                \"raw_content\": tool_call_content\n            })\n        except (json.JSONDecodeError, KeyError) as e:\n            error_msg = f\"Error: Invalid tool call format. Reason: {e}\"\n            logger.error(f\"{error_msg}\\nContent: {tool_call_content}\")\n            # Convert tool error to user role for Ollama compatibility\n            messages.append({\"role\": \"user\", \"content\": f\"Tool error: {error_msg}\"})\n\n    # Execute all valid tool calls - but enforce single tool per turn for safety\n    logger.info('Detected tool calls:\\n' + str(tool_calls))\n    if tool_calls:\n        # Limit to single tool per turn to avoid dependency issues\n        if len(tool_calls) > 1:\n            logger.warning(f\"Multiple tool calls detected ({len(tool_calls)}), executing only the first one to avoid dependencies\")\n            tool_calls = [tool_calls[0]]\n        \n        logger.info(f\"Executing {len(tool_calls)} tool call...\")\n        \n        # Execute the tool call\n        tool_call = tool_calls[0]\n        tool_name = tool_call[\"name\"]\n        \n        try:\n            result = await execute_tool_async(tool_name, tool_call[\"arguments\"], logger)\n            \n            if isinstance(result, Exception):\n                logger.error(f\"Tool {tool_name} failed with exception: {result}\")\n                tool_result = f\"Error: {str(result)}\"\n                status = \"error\"\n            else:\n                tool_result = result\n                logger.info(f\"Tool {tool_name} completed successfully\")\n                status = \"success\"\n\n            # Update knowledge store for file operations\n            if knowledge_store is not None:\n                knowledge_store.update_from_tool_execution(tool_name, tool_call[\"arguments\"], tool_result)\n\n            # Stream tool result to UI if callback provided\n            if result_callback:\n                # Create a concise, user-facing summary of the tool result\n                brief_result = str(tool_result)[:200] + \"...\" if len(str(tool_result)) > 200 else str(tool_result)\n                \n                tool_result_summary = {\n                    \"name\": tool_name,\n                    \"status\": status,\n                    \"brief_result\": brief_result,\n                    \"arguments\": tool_call[\"arguments\"]\n                }\n                await result_callback(tool_result_summary)\n\n            # Append the structured tool result to messages as system role for better model understanding\n            # Use \"system\" role instead of \"user\" to clearly indicate this is an observation\n            messages.append({\n                \"role\": \"system\",\n                \"content\": f\"OBSERVATION: Tool '{tool_name}' result: {tool_result}\"\n            })\n                \n        except Exception as e:\n            logger.error(f\"Error during tool execution: {e}\", exc_info=True)\n            messages.append({\"role\": \"system\", \"content\": f\"TOOL_ERROR: {tool_name} failed: {str(e)}\"})\n            \n            # Stream error to UI if callback provided\n            if result_callback:\n                error_summary = {\n                    \"name\": tool_name,\n                    \"status\": \"error\", \n                    \"brief_result\": f\"Error: {str(e)}\",\n                    \"arguments\": tool_call[\"arguments\"]\n                }\n                await result_callback(error_summary)\n\n    return tool_calls_made\n\n\n\n\nasync ", "source": {"file": "server/agent/tool_executor.py", "section": "server/agent/tool_executor.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000127", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, refresh_interval_hours: float = 24.0):\n        \"\"\"\n        Initialize the refresher service.\n\n        Args:\n            refresh_interval_hours: How often to refresh the index (in hours)\n        \"\"\"\n        self.refresh_interval = refresh_interval_hours * 3600  # Convert to seconds\n        self.running = False\n        self.thread = None\n        self.last_refresh_time = None\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def __init__(self, refresh_interval_hours: float = 24.0)"}, "tags": ["anton_repo"]}
{"id": "b0000128", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def start(self):\n        \"\"\"Start the background refresh thread.\"\"\"\n        if self.running:\n            return\n\n        self.running = True\n        self.thread = threading.Thread(target=self._refresh_loop, daemon=True)\n        self.thread.start()\n        logger.info(\"Code index refresher service started.\")\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def start(self)"}, "tags": ["anton_repo"]}
{"id": "b0000129", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def stop(self):\n        \"\"\"Stop the background refresh thread.\"\"\"\n        self.running = False\n        if self.thread:\n            self.thread.join(timeout=1.0)\n        logger.info(\"Code index refresher service stopped.\")\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def stop(self)"}, "tags": ["anton_repo"]}
{"id": "b0000130", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _refresh_loop(self):\n        \"\"\"Main refresh loop that runs in the background.\"\"\"\n        while self.running:\n            try:\n                # Perform the refresh\n                logger.info(\"Starting scheduled code index refresh...\")\n                start_time = time.time()\n                files_updated = code_indexer.refresh_index()\n\n                # Save the RAG index if any files were updated\n                if files_updated > 0:\n                    rag_manager.save()\n\n                elapsed_time = time.time() - start_time\n                self.last_refresh_time = datetime.now()\n\n                logger.info(\n                    f\"Code index refresh completed in {elapsed_time:.1f} seconds. \"\n                    f\"{files_updated} files updated.\"\n                )\n\n                # Sleep until next refresh interval\n                time.sleep(self.refresh_interval)\n\n            except Exception as e:\n                logger.error(f\"Error during code index refresh: {e}\", exc_info=True)\n                # If there was an error, wait a bit before retrying\n                time.sleep(300)  # 5 minutes\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def _refresh_loop(self)"}, "tags": ["anton_repo"]}
{"id": "b0000131", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def force_refresh(self) -> int:\n        \"\"\"\n        Force an immediate refresh of the code index.\n\n        Returns:\n            Number of files updated\n        \"\"\"\n        try:\n            logger.info(\"Forcing code index refresh...\")\n            start_time = time.time()\n            files_updated = code_indexer.refresh_index()\n\n            # Save the RAG index if any files were updated\n            if files_updated > 0:\n                rag_manager.save()\n\n            elapsed_time = time.time() - start_time\n            self.last_refresh_time = datetime.now()\n\n            logger.info(\n                f\"Forced code index refresh completed in {elapsed_time:.1f} seconds. \"\n                f\"{files_updated} files updated.\"\n            )\n\n            return files_updated\n\n        except Exception as e:\n            logger.error(f\"Error during forced code index refresh: {e}\", exc_info=True)\n            return 0\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def force_refresh(self)"}, "tags": ["anton_repo"]}
{"id": "b0000132", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def get_status(self) -> dict:\n        \"\"\"\n        Get the current status of the refresher service.\n\n        Returns:\n            Dictionary with status information\n        \"\"\"\n        return {\n            \"running\": self.running,\n            \"refresh_interval_hours\": self.refresh_interval / 3600,\n            \"last_refresh\": self.last_refresh_time.isoformat() if self.last_refresh_time else None\n        }\n\n\n# Create a global instance\ncode_refresher = CodeIndexRefresher()", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:def get_status(self)"}, "tags": ["anton_repo"]}
{"id": "b0000133", "domain": "anton_repo", "section_path": ["server/agent/code_index_refresher.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "\"\"\"\nBackground service that periodically refreshes the code index.\n\"\"\"\nimport time\nimport threading\nimport logging\nfrom datetime import datetime\n\nfrom server.agent.code_indexer import code_indexer\nfrom server.agent.rag_manager import rag_manager\n\nlogger = logging.getLogger(__name__)\n\n\nclass CodeIndexRefresher:\n    \"\"\"\n    A service that periodically refreshes the code index in the background.\n    \"\"\"\n\n    ", "source": {"file": "server/agent/code_index_refresher.py", "section": "server/agent/code_index_refresher.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000134", "domain": "anton_repo", "section_path": ["server/agent/knowledge_handler.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def save_reflection(original_task: str, reflection_data: dict, logger: Any) -> None:\n    \"\"\"\n    ### UPDATED ###\n    Saves the structured reflection data to the RAG knowledge base.\n\n    This now uses the RAGManager to embed and store the new knowledge.\n    \"\"\"\n    logger.info(f\"Saving reflection to knowledge base: \\\"{reflection_data.get('summary', 'N/A')}\\\"\")\n    try:\n        # 1. 🧠 Format the learned insight into a text document for storage.\n        # This text will be converted into a vector for semantic search.\n        knowledge_text = (\n            f\"Regarding the task '{original_task}', a key learning was identified.\\n\"\n            f\"Summary of outcome: {reflection_data['summary']}\\n\"\n            f\"Key Takeaway: {reflection_data['key_takeaway']}\\n\"\n            f\"Strategy Used: {reflection_data['strategy']}\"\n        )\n\n        # 2. Add the new knowledge to the in-memory RAG index.\n        # The source helps identify where this knowledge came from.\n        rag_manager.add_knowledge(\n            text=knowledge_text,\n            source=f\"reflection_on_{original_task[:30]}\"  # A descriptive source\n        )\n\n        # 3. 💾 Persist the updated index and document store to disk.\n        # This saves all knowledge added since the last save.\n        rag_manager.save()\n\n        logger.info(\"Successfully saved reflection to the RAG knowledge base.\")\n\n    except Exception as e:\n        logger.error(f\"Failed to save reflection to RAG knowledge base. Error: {e}\", exc_info=True)\n\n", "source": {"file": "server/agent/knowledge_handler.py", "section": "server/agent/knowledge_handler.py:def save_reflection(original_task: str, reflection_data: dict, logger: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000135", "domain": "anton_repo", "section_path": ["server/agent/knowledge_handler.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "\"\"\"\nHandles parsing and processing of <learn> tags from the model's output.\n\"\"\"\nimport json\nimport re\nfrom typing import Any, Dict\n\nfrom server.agent.rag_manager import rag_manager\n\nLEARN_TAG_REGEX = re.compile(r\"<learn>(.*?)</learn>\", re.DOTALL)\n\n\nasync def process_learning_request(\n    response_buffer: str,\n    logger: Any\n) -> bool:\n    learn_match = LEARN_TAG_REGEX.search(response_buffer)\n    if not learn_match:\n        return False\n\n    learn_content = learn_match.group(1).strip()\n    logger.info(\"Detected <learn> tag. Attempting to process.\")\n\n    try:\n        learn_data = json.loads(learn_content)\n        new_knowledge = learn_data.get(\"new_knowledge\")\n        source = learn_data.get(\"source\")\n\n        if not new_knowledge or not source:\n            raise KeyError(\"JSON must contain 'new_knowledge' and 'source' keys.\")\n\n        # Add the extracted information to the knowledge base\n        rag_manager.add_knowledge(text=new_knowledge, source=source)\n        logger.info(\"Successfully processed and stored new knowledge.\")\n\n    except (json.JSONDecodeError, KeyError) as e:\n        # Log the error but don't interrupt the flow. The agent doesn't need\n        # to know about a failure to learn.\n        error_msg = f\"Error: Invalid <learn> tag content. Reason: {e}\"\n        logger.error(f\"{error_msg}\\nContent: {learn_content}\")\n\n    return True\n\n\nasync def process_code_question(\n        question: str,\n        logger: Any\n) -> Dict:\n    \"\"\"\n    Process a question about the agent's code by finding relevant code snippets.\n\n    Args:\n        question: The question about the code\n        logger: Logger instance\n\n    Returns:\n        Dictionary with relevant code snippets\n    \"\"\"\n    from server.agent.rag_manager import rag_manager\n\n    logger.info(f\"Processing code-related question: {question}\")\n\n    try:\n        # Get relevant code snippets\n        relevant_snippets = rag_manager.retrieve_knowledge(query=question, top_k=5)\n\n        # Format snippets for readability\n        formatted_snippets = []\n        for snippet in relevant_snippets:\n            source = snippet.get(\"source\", \"Unknown source\")\n            text = snippet.get(\"text\", \"\").strip()\n            formatted_snippets.append({\n                \"source\": source,\n                \"text\": text[:1000] + (\"...\" if len(text) > 1000 else \"\")\n            })\n\n        return {\n            \"question\": question,\n            \"snippets\": formatted_snippets\n        }\n\n    except Exception as e:\n        logger.error(f\"Error processing code question: {e}\", exc_info=True)\n        return {\n            \"question\": question,\n            \"error\": str(e),\n            \"snippets\": []\n        }\n\n\nasync ", "source": {"file": "server/agent/knowledge_handler.py", "section": "server/agent/knowledge_handler.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000136", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def read_jsonl(p: Path) -> List[Dict[str, Any]]:\n    out = []\n    if not p.exists():\n        return out\n    with p.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                out.append(json.loads(line))\n    return out\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def read_jsonl(p: Path)"}, "tags": ["anton_repo"]}
{"id": "b0000137", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def write_jsonl(p: Path, rows: List[Dict[str, Any]]):\n    with p.open(\"a\", encoding=\"utf-8\") as f:\n        for r in rows:\n            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def write_jsonl(p: Path, rows: List[Dict[str, Any]])"}, "tags": ["anton_repo"]}
{"id": "b0000138", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def save_json(p: Path, obj: Any):\n    p.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def save_json(p: Path, obj: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000139", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def slug(s: str) -> str:\n    return re.sub(r\"[^\\w\\-]+\", \"-\", s.strip().lower())\n\n# ---------------------------- LLM client ----------------------------\n\nclass AgentClient:\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def slug(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000140", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def __init__(self, base: str, path: str = \"/react/stream\", timeout: float = 180.0):\n        self.base = base.rstrip(\"/\")\n        self.path = path\n        self.timeout = httpx.Timeout(timeout)\n\n    async ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def __init__(self, base: str, path: str = \"/react/stream\", timeout: float = 180.0)"}, "tags": ["anton_repo"]}
{"id": "b0000141", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def ask(self, user_prompt: str) -> str:\n        # Sends ONE user message to the agent and streams back plaintext.\n        payload = {\"messages\":[{\"role\":\"user\",\"content\":user_prompt}]}\n        buf = []\n        async with httpx.AsyncClient(timeout=self.timeout) as client:\n            async with client.stream(\"POST\", f\"{self.base}{self.path}\", json=payload) as resp:\n                resp.raise_for_status()\n                async for chunk in resp.aiter_text():\n                    for line in chunk.split(\"\\n\"):\n                        if not line.strip(): \n                            continue\n                        if line.startswith(\"data: \"):\n                            data = line[6:]\n                            if data == \"[DONE]\":\n                                text = \"\".join(buf)\n                                # keep only post-</think> region if present\n                                tail = text.rsplit(\"</think>\", 1)[-1]\n                                return tail.strip()\n                            buf.append(data)\n                        else:\n                            buf.append(line)\n        text = \"\".join(buf)\n        return text.rsplit(\"</think>\", 1)[-1].strip()\n\n\nclass LLMClient:\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def ask(self, user_prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000142", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def __init__(self, api_base: str, temperature: float = 0.2, request_timeout: float = 120.0):\n        self.api_base = api_base.rstrip(\"/\")\n        self.temperature = temperature\n        self.request_timeout = request_timeout\n\n    async ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def __init__(self, api_base: str, temperature: float = 0.2, request_timeout: float = 120.0)"}, "tags": ["anton_repo"]}
{"id": "b0000143", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def chat_once(self, system_prompt: str, user_prompt: str, model: Optional[str] = None) -> str:\n        payload = {\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ],\n            \"temperature\": self.temperature,\n            \"complex\": True,\n            \"model\": model or QWEN_30B_THINKING,\n        }\n        timeout = httpx.Timeout(self.request_timeout)\n        async with httpx.AsyncClient(timeout=timeout) as client:\n            async with client.stream(\"POST\", f\"{self.api_base}/v1/chat/stream\", json=payload) as response:\n                response.raise_for_status()\n\n                full_response_content = \"\"\n                # Iterate over the streamed chunks\n                async for chunk in response.aiter_text():\n                    for line in chunk.split('\\n'):\n                        if line.startswith('data: '):\n                            content = line[6:]  # Remove 'data: ' prefix\n                            if content == '[DONE]':\n                                # End of stream marker; continue to finalize below\n                                continue\n                            full_response_content += content\n                        elif line.strip():\n                            # Fallback for non-SSE format\n                            full_response_content += line\n        # Fallback\n        text = \"\".join(full_response_content).strip()\n        end = text.rfind(\"</think>\")\n        return text[end + len(\"</think>\") :] if end != -1 else text\n\n# ---------------------------- Drill schema ----------------------------\n\nDRILL_GEN_SYSTEM = \"\"\"You generate focused practice problems (drills) for a given concept.\nReturn STRICT JSON ONLY per the schema. No prose, no code fences.\n\nSchema:\n{{\n  \"drills\": [\n    {{\n      \"task_family\": \"derivative_at_point|derivative_expr|limit|integral_definite|integral_indefinite|evaluate\",\n      \"problem\": \"<one clear problem statement in LaTeX-friendly text>\",\n      \"answer_exact\": \"<exact LaTeX or plain math>\",\n      \"difficulty\": \"easy|medium|hard\",\n      \"uses_concepts\": [\"<primary concept name>\", \"...\"]\n    }}\n  ]\n}}\n\nRules:\n- Choose task_family ONLY from the list above (no proofs/theory-only questions).\n- derivative_at_point: define f(x)=... and include \"at x = a\" (small integer a).\n- derivative_expr: define f(x)=... and ask for f'(x).\n- limit: include \"as x -> a\" (or x→a) with a concrete a.\n- integral_definite: use \\\\int ... dx with bounds \"from a to b\".\n- integral_indefinite: use \\\\int ... dx and include + C in the exact answer.\n- evaluate: define f(x)=... and ask to evaluate at x = a.\n- If the target concept is a theorem/definition and not directly computable, generate drills for a closely-related prerequisite rule that demonstrates its use.\n- Return at most {max_per} drills.\n\"\"\"\n\n\n\n\nDRILL_GEN_USER_TMPL = \"\"\"Target concept: {name} ({ctype})\nFormal: {formal}\nSummary: {summary}\n\nReturn drills now as JSON matching the schema.\n\"\"\"\n\nANSWER_STYLE_CONTRACT = \"\"\"You must follow this output contract.\n\nAnswer Style (MANDATORY):\n- Output exactly ONE line starting with: Final Answer:\n- Give the simplest exact value in LaTeX (e.g., \\\\frac{1}{4}, \\\\sqrt{6}/12). For indefinite integrals: include + C.\n- Optionally append a decimal approximation in parentheses with 3 sig figs.\n- Do NOT restate the question, do NOT include steps, do NOT repeat the final line.\n\"\"\"\n\nSOLVE_SYSTEM_TMPL = \"\"\"You are a precise problem solver. Use the provided domain rules.\nPrefer formal rules over prose and obey the Answer Style.\n\n{contract}\n\nWhen ready, output only the final line as specified.\n\"\"\"\n\nSOLVE_USER_TMPL = \"\"\"# Domain rules\n{bundle}\n\n# Problem\n{problem}\n\"\"\"\n\n# ---------------------------- Data structures ----------------------------\n\n@dataclass\nclass Attempt:\n    ts: float\n    node_id: str\n    node_name: str\n    problem: str\n    candidate: str\n    verdict: str\n    expected: Optional[str]\n    difficulty: str\n\n@dataclass\nclass Mastery:\n    attempts: int = 0\n    correct: int = 0\n    streak: int = 0\n    last_ts: float = 0.0\n\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def chat_once(self, system_prompt: str, user_prompt: str, model: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000144", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def update(self, ok: bool):\n        self.attempts += 1\n        self.correct += (1 if ok else 0)\n        self.streak = self.streak + 1 if ok else 0\n        self.last_ts = time.time()\n\n# ---------------------------- Core pipeline ----------------------------\n\nclass SelfStudy:\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def update(self, ok: bool)"}, "tags": ["anton_repo"]}
{"id": "b0000145", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def __init__(self, pack_dir: str, api_base: str, domain: str, temperature: float, solver, solver_url, agent_path, evaluator: bool = False):\n        self.pack_dir = Path(pack_dir)\n        self.domain = domain\n        self.solver = solver  # pass from args\n        self.solver_url = solver_url or api_base  # default to same URL if not given\n        self.agent_path = agent_path\n        self.agent = AgentClient(self.solver_url, self.agent_path) if self.solver == \"agent\" else None\n        self.client = LLL = LLMClient(api_base=api_base, temperature=temperature)\n        self.adj, self.nodes = load_pack(pack_dir)\n        self.pack_name = self.pack_dir.name\n        # Attach to existing RAG singleton; ensure it's initialized (paths already set in your app)\n        self.rag: RAGManager = rag_manager\n        # Evaluator mode disables domain bundle (RAG) during solving for baseline comparison\n        self.evaluator = evaluator\n\n        # Files\n        self.attempts_path = self.pack_dir / \"self_study_attempts.jsonl\"\n        self.mastery_path = self.pack_dir / \"mastery.json\"\n        self.examples_aug = self.pack_dir / \"examples_aug.jsonl\"\n\n        # Load mastery\n        self.mastery: Dict[str, Mastery] = {}\n        if self.mastery_path.exists():\n            try:\n                raw = json.loads(self.mastery_path.read_text(encoding=\"utf-8\"))\n                for nid, st in raw.items():\n                    self.mastery[nid] = Mastery(**st)\n            except Exception:\n                logger.warning(\"Could not load mastery.json; starting fresh.\")\n\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def __init__(self, pack_dir: str, api_base: str, domain: str, temperature: float, solver, solver_url, agent_path, evaluator: bool = False)"}, "tags": ["anton_repo"]}
{"id": "b0000146", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def _format_bundle(self, query_text: str) -> str:\n        # Use your existing bundle builder\n        node_ids = rag_topk_nodes(self.rag, query_text, self.pack_name, topk=5)\n        expanded = expand_nodes(node_ids, self.adj, edge_types=(\"depends_on\",), radius=1)\n        ordered = list(dict.fromkeys(node_ids + [x for x in expanded if x not in node_ids]))\n        return format_context(self.nodes, ordered, max_nodes=8, max_examples_per_node=1)\n\n    async ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _format_bundle(self, query_text: str)"}, "tags": ["anton_repo"]}
{"id": "b0000147", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def _gen_drills_for_node(self, node: Dict[str, Any], max_per: int) -> List[Dict[str, Any]]:\n        sys = DRILL_GEN_SYSTEM.format(max_per=max_per)\n        usr = DRILL_GEN_USER_TMPL.format(\n            name=node.get(\"name\",\"\"),\n            ctype=node.get(\"type\",\"concept\"),\n            formal=node.get(\"formal\") or \"n/a\",\n            summary=(node.get(\"summary\") or \"\")[:400],\n        )\n        # Pass 1: thinking model\n        raw = await self.client.chat_once(sys, usr, model=QWEN_30B_THINKING)\n        data = self._try_json(raw) or {}\n        drills: List[Dict[str, Any]] = []\n        if isinstance(data.get(\"drills\"), list):\n            for d in data[\"drills\"]:\n                prob = (d.get(\"problem\") or \"\").strip()\n                ans  = (d.get(\"answer_exact\") or \"\").strip()\n                diff = (d.get(\"difficulty\") or \"medium\").lower()\n                fam  = (d.get(\"task_family\") or \"\").strip()\n                if prob and ans and fam:\n                    drills.append({\"problem\": prob, \"answer_exact\": ans, \"difficulty\": diff, \"task_family\": fam})\n\n        if drills:\n            return drills[:max_per]\n\n        # Pass 2: instruct model to coerce previous output to strict JSON\n        fix_msg = (\n            \"Return ONLY valid JSON (no code fences, no commentary) matching the schema. \"\n            \"Here is your previous output:\\n\" + (raw or \"\")\n        )\n        raw2 = await self.client.chat_once(sys, fix_msg, model=QWEN_30B_INSTRUCT)\n        data2 = self._try_json(raw2) or {}\n        if isinstance(data2.get(\"drills\"), list):\n            for d in data2[\"drills\"]:\n                prob = (d.get(\"problem\") or \"\").strip()\n                ans  = (d.get(\"answer_exact\") or \"\").strip()\n                diff = (d.get(\"difficulty\") or \"medium\").lower()\n                fam  = (d.get(\"task_family\") or \"\").strip()\n                if prob and ans and fam:\n                    drills.append({\"problem\": prob, \"answer_exact\": ans, \"difficulty\": diff, \"task_family\": fam})\n        if drills:\n            return drills[:max_per]\n\n        # ---- Fallback: use a computable prerequisite ----\n        nid = node[\"id\"]\n        prereqs = self.adj.get(\"depends_on\", {}).get(nid, [])\n        for pid in prereqs:\n            pnode = self.nodes.get(pid)\n            if not pnode:\n                continue\n            if pnode.get(\"type\",\"concept\") not in (\"rule\",\"algorithm\",\"definition\",\"concept\"):\n                continue\n            usr2 = DRILL_GEN_USER_TMPL.format(\n                name=pnode.get(\"name\",\"\"),\n                ctype=pnode.get(\"type\",\"concept\"),\n                formal=pnode.get(\"formal\") or \"n/a\",\n                summary=(pnode.get(\"summary\") or \"\")[:400],\n            )\n            raw2 = await self.client.chat_once(sys, usr2, model=QWEN_30B_THINKING)\n            data2 = self._try_json(raw2) or {}\n            drills2: List[Dict[str, Any]] = []\n            if isinstance(data2.get(\"drills\"), list):\n                for d in data2[\"drills\"]:\n                    prob = (d.get(\"problem\") or \"\").strip()\n                    ans  = (d.get(\"answer_exact\") or \"\").strip()\n                    diff = (d.get(\"difficulty\") or \"medium\").lower()\n                    fam  = (d.get(\"task_family\") or \"\").strip()\n                    if prob and ans and fam:\n                        drills2.append({\"problem\": prob, \"answer_exact\": ans, \"difficulty\": diff, \"task_family\": fam})\n            if not drills2 and raw2:\n                # Try instruct coercion for prereq as well\n                fix2 = (\n                    \"Return ONLY valid JSON (no code fences, no commentary) matching the schema. \"\n                    \"Here is your previous output:\\n\" + raw2\n                )\n                raw2b = await self.client.chat_once(sys, fix2, model=QWEN_30B_INSTRUCT)\n                data2b = self._try_json(raw2b) or {}\n                if isinstance(data2b.get(\"drills\"), list):\n                    for d in data2b[\"drills\"]:\n                        prob = (d.get(\"problem\") or \"\").strip()\n                        ans  = (d.get(\"answer_exact\") or \"\").strip()\n                        diff = (d.get(\"difficulty\") or \"medium\").lower()\n                        fam  = (d.get(\"task_family\") or \"\").strip()\n                        if prob and ans and fam:\n                            drills2.append({\"problem\": prob, \"answer_exact\": ans, \"difficulty\": diff, \"task_family\": fam})\n            if drills2:\n                logger.info(\"Fallback drills generated via prerequisite: %s\", pnode.get(\"name\"))\n                return drills2[:max_per]\n\n        logger.info(\"No drills generated for %s\", node.get(\"name\"))\n        return []\n\n\n    async ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _gen_drills_for_node(self, node: Dict[str, Any], max_per: int)"}, "tags": ["anton_repo"]}
{"id": "b0000148", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def _solve(self, problem: str) -> str:\n        if self.solver == \"agent\":\n            # Let the AGENT fetch context. Just give it the wrapper + problem.\n            user = f\"\"\"{ANSWER_STYLE_CONTRACT}\n\n            Problem:\n            {problem}\n            \"\"\"\n            text = await self.agent.ask(user)\n        else:\n            # Default behavior (respects evaluator flag outside of evaluator compare loop)\n            use_bundle = not self.evaluator\n            text = await self._solve_variant(problem, use_bundle=use_bundle)\n        # Extract single \"Final Answer:\" line or fall back to whole text\n        m = re.search(r\"(Final Answer:\\s*.+)\", text, flags=re.IGNORECASE)\n        line = m.group(1).strip() if m else text.strip()\n        # Normalize spacing\n        logger.info(\" \".join(line.split()))\n        return \" \".join(line.split())\n\n    async ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _solve(self, problem: str)"}, "tags": ["anton_repo"]}
{"id": "b0000149", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def _solve_variant(self, problem: str, use_bundle: bool) -> str:\n        bundle = self._format_bundle(problem) if use_bundle else \"\"\n        if not use_bundle:\n            logger.info(\"Evaluator (baseline): solving without domain bundle\")\n        sys = SOLVE_SYSTEM_TMPL.format(contract=ANSWER_STYLE_CONTRACT)\n        usr = SOLVE_USER_TMPL.format(bundle=bundle, problem=problem)\n        text = await self.client.chat_once(sys, usr)\n        m = re.search(r\"(Final Answer:\\s*.+)\", text, flags=re.IGNORECASE)\n        line = m.group(1).strip() if m else text.strip()\n        logger.info(\" \".join(line.split()))\n        return \" \".join(line.split())\n\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _solve_variant(self, problem: str, use_bundle: bool)"}, "tags": ["anton_repo"]}
{"id": "b0000150", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def _verify(self, problem: str, candidate: str, expected_exact: Optional[str] = None, task_family: Optional[str] = None):\n        clean = re.sub(r'(?is)^\\s*final answer:\\s*', '', candidate).strip()\n        context: Dict[str, Any] = {\"task_family\": task_family} if task_family else {}\n        if expected_exact:\n            context[\"expected_exact\"] = expected_exact\n        req = VerifyRequest(domain=self.domain, problem=problem, candidate=clean, context=context or None)\n        res = run_verify(req)\n        if getattr(res, 'verdict', None) and res.verdict.name != 'UNKNOWN':\n            return res.verdict, res.expected, res.to_dict()\n\n        # Local lightweight fallback: try numeric equivalence when expected is known\n        if expected_exact:\n            try:\n                from sympy import sympify\n                ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _verify(self, problem: str, candidate: str, expected_exact: Optional[str] = None, task_family: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000151", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def to_expr(s: str):\n                    s = s.strip().strip('$')\n                    s = s.replace('\\\\,', '')\n                    # crude latex conversions\n                    s = re.sub(r\"\\\\frac\\{([^{}]+)\\}\\{([^{}]+)\\}\", r\"(\\1)/(\\2)\", s)\n                    s = re.sub(r\"\\\\sqrt\\{([^{}]+)\\}\", r\"sqrt(\\1)\", s)\n                    s = s.replace('^', '**')\n                    return sympify(s)\n                ce = to_expr(clean)\n                ee = to_expr(expected_exact)\n                if ce.equals(ee):\n                    from server.agent.verifiers.types import Verdict as V\n                    return V.CORRECT, str(ee), {\"verdict\": \"correct\", \"fallback\": \"sympy.equals\"}\n            except Exception:\n                pass\n        return res.verdict, res.expected, res.to_dict()\n\n    @staticmethod\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def to_expr(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000152", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "def _try_json(s: str) -> Optional[Dict[str, Any]]:\n        s = s.strip()\n        try:\n            return json.loads(s)\n        except Exception:\n            pass\n        i, j = s.find(\"{\"), s.rfind(\"}\")\n        if i != -1 and j != -1 and j > i:\n            try:\n                return json.loads(s[i:j+1])\n            except Exception:\n                return None\n        return None\n\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _try_json(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000153", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 18, "block_index": 1, "block_type": "code", "text": "def _update_mastery(self, nid: str, ok: bool):\n        st = self.mastery.get(nid) or Mastery()\n        st.update(ok)\n        self.mastery[nid] = st\n\n    ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _update_mastery(self, nid: str, ok: bool)"}, "tags": ["anton_repo"]}
{"id": "b0000154", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 19, "block_index": 1, "block_type": "code", "text": "def _persist_mastery(self):\n        save_json(self.mastery_path, {k: asdict(v) for k, v in self.mastery.items()})\n\n    async def study_epoch(\n        self,\n        drills_per_node: int,\n        sample_nodes: int,\n        save_good_examples: bool = False,\n        seed: int = 0,\n    ):\n        random.seed(seed)\n        # pick target nodes: prioritize lower mastery or unpracticed rules\n        candidates = [n for n in self.nodes.values() if n.get(\"type\",\"concept\") in (\"rule\",\"theorem\",\"algorithm\",\"concept\",\"definition\")]\n        random.shuffle(candidates)\n        # sort by (low streak, low accuracy)\n        ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def _persist_mastery(self)"}, "tags": ["anton_repo"]}
{"id": "b0000155", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 20, "block_index": 1, "block_type": "code", "text": "def score(n):\n            st = self.mastery.get(n[\"id\"])\n            if not st or st.attempts == 0:\n                return (0.0, 0.0)\n            acc = st.correct / max(1, st.attempts)\n            return (acc, st.streak)\n        candidates.sort(key=score)\n        targets = candidates[:sample_nodes]\n\n        attempts_batch: List[Dict[str, Any]] = []\n        examples_batch: List[Dict[str, Any]] = []\n\n        # accuracy counters\n        accuracy = {\"rag\": {\"total\": 0, \"correct\": 0}, \"baseline\": {\"total\": 0, \"correct\": 0}, \"agent\": {\"total\": 0, \"correct\": 0}}\n\n        for idx, node in enumerate(targets, 1):\n            logger.info(\"Node %d/%d: %s (%s)\", idx, len(targets), node.get(\"name\"), node.get(\"id\"))\n\n            drills = await self._gen_drills_for_node(node, drills_per_node)\n            if not drills:\n                logger.info(\"No drills generated for %s\", node.get(\"name\"))\n                continue\n\n            for d in drills:\n                prob = d[\"problem\"]\n                diff = d[\"difficulty\"]\n                family = d.get(\"task_family\")\n                expected_exact = d.get(\"answer_exact\")\n\n                # Decide which variants to run\n                run_variants = []\n                if self.solver == \"agent\":\n                    run_variants = [(\"agent\", None)]\n                elif self.evaluator:\n                    run_variants = [(\"baseline\", False), (\"rag\", True)]\n                else:\n                    run_variants = [(\"rag\", True)]\n\n                for mode, use_bundle in run_variants:\n                    try:\n                        if mode == \"agent\":\n                            cand = await self._solve(prob)\n                        else:\n                            cand = await self._solve_variant(prob, use_bundle=use_bundle)  # type: ignore[arg-type]\n                    except Exception:\n                        logger.exception(\"Solve failed; skipping drill variant (%s).\", mode)\n                        continue\n\n                    verdict, expected, meta = self._verify(prob, cand, expected_exact=expected_exact, task_family=family)\n                    logger.info(\"Verdict (%s) for '%s': %s\", mode, node.get(\"name\"), verdict.value)\n                    if (verdict == Verdict.UNKNOWN):\n                        logger.warning(\"Meta: \\n\" + str(meta))\n\n                    # Log attempt\n                    rec = asdict(Attempt(\n                        ts=time.time(),\n                        node_id=node[\"id\"],\n                        node_name=node.get(\"name\",\"\"),\n                        problem=prob,\n                        candidate=cand,\n                        verdict=verdict.value,\n                        expected=expected,\n                        difficulty=diff,\n                    ))\n                    rec[\"mode\"] = mode\n                    attempts_batch.append(rec)\n\n                    # Update counters\n                    if mode in accuracy:\n                        accuracy[mode][\"total\"] += 1\n                        if verdict == Verdict.CORRECT:\n                            accuracy[mode][\"correct\"] += 1\n\n                    # Update mastery only if correct on any variant\n                    if verdict == Verdict.CORRECT:\n                        self._update_mastery(node[\"id\"], True)\n\n                    # Optionally harvest good examples back into nodes bank\n                    if save_good_examples and verdict == Verdict.CORRECT:\n                        try:\n                            examples_batch.append({\n                                \"node_id\": node[\"id\"],\n                                \"name\": node.get(\"name\",\"\"),\n                                \"problem\": prob,\n                                \"answer\": cand.replace(\"Final Answer:\", \"\").strip(),\n                                \"mode\": mode,\n                            })\n                        except Exception:\n                            pass\n\n        # Persist artifacts\n        if attempts_batch:\n            write_jsonl(self.attempts_path, attempts_batch)\n            logger.info(\"Wrote %d attempts → %s\", len(attempts_batch), self.attempts_path)\n        if examples_batch:\n            write_jsonl(self.examples_aug, examples_batch)\n            logger.info(\"Wrote %d harvested examples → %s\", len(examples_batch), self.examples_aug)\n        self._persist_mastery()\n        logger.info(\"Mastery updated → %s\", self.mastery_path)\n\n        # Print a compact accuracy summary\n        try:\n            ", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def score(n)"}, "tags": ["anton_repo"]}
{"id": "b0000156", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 21, "block_index": 1, "block_type": "code", "text": "def rate(ok, tot):\n                return (ok / tot) if tot else 0.0\n            rag_ok, rag_tot = accuracy[\"rag\"][\"correct\"], accuracy[\"rag\"][\"total\"]\n            base_ok, base_tot = accuracy[\"baseline\"][\"correct\"], accuracy[\"baseline\"][\"total\"]\n            agent_ok, agent_tot = accuracy[\"agent\"][\"correct\"], accuracy[\"agent\"][\"total\"]\n            logger.info(\"--- EVALUATION SUMMARY ---\")\n            logger.info(\"RAG: %d/%d (%.1f%%)\", rag_ok, rag_tot, 100*rate(rag_ok, rag_tot))\n            logger.info(\"Baseline: %d/%d (%.1f%%)\", base_ok, base_tot, 100*rate(base_ok, base_tot))\n            if agent_tot:\n                logger.info(\"Agent: %d/%d (%.1f%%)\", agent_ok, agent_tot, 100*rate(agent_ok, agent_tot))\n        except Exception:\n            pass\n\n# ---------------------------- CLI ----------------------------\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def rate(ok, tot)"}, "tags": ["anton_repo"]}
{"id": "b0000157", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 22, "block_index": 1, "block_type": "code", "text": "def parse_args():\n    ap = argparse.ArgumentParser(description=\"Self-study / Mastery runner\")\n    ap.add_argument(\"--pack-dir\", default=\"learning/packs/calc.v1\", help=\"Path to pack dir (with nodes.jsonl, graph_adj.json)\")\n    ap.add_argument(\"--api\", default=\"http://localhost:8000\", help=\"LLM server base URL (same /v1/chat/stream endpoint)\")\n    ap.add_argument(\"--domain\", default=\"calculus\", help=\"Verifier domain key (e.g., calculus)\")\n    ap.add_argument(\"--drills-per-node\", type=int, default=2)\n    ap.add_argument(\"--sample-nodes\", type=int, default=8)\n    ap.add_argument(\"--temperature\", type=float, default=0.6)\n    ap.add_argument(\"--save-good-examples\", action=\"store_true\")\n    ap.add_argument(\"--log-level\", default=\"INFO\")\n    ap.add_argument(\"--solver\", choices=[\"model\",\"agent\"], default=\"model\")\n    ap.add_argument(\"--solver-url\", required=False, default=\"http://localhost:8001\", help=\"Base URL for solver (model or agent)\")\n    ap.add_argument(\"--agent-path\", default=\"/v1/agent/chat\", help=\"Agent streaming path (override to match your server)\")\n    ap.add_argument(\"--evaluator\", action=\"store_true\", help=\"Run baseline without domain embeddings/bundle during solving\")\n    return ap.parse_args()\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def parse_args()"}, "tags": ["anton_repo"]}
{"id": "b0000158", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 23, "block_index": 1, "block_type": "code", "text": "def main():\n    args = parse_args()\n    logging.basicConfig(level=getattr(logging, args.log_level.upper(), logging.INFO),\n                        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n    ss = SelfStudy(\n        pack_dir=args.pack_dir,\n        api_base=args.api,          # still used for drill generation (model)\n        domain=args.domain,\n        temperature=args.temperature,\n        solver=args.solver,\n        solver_url=args.solver_url,\n    agent_path=args.agent_path,\n    evaluator=args.evaluator,\n    )\n    asyncio.run(ss.study_epoch(\n            drills_per_node=args.drills_per_node,\n            sample_nodes=args.sample_nodes,\n            save_good_examples=args.save_good_examples,\n        ))\n\nif __name__ == \"__main__\":\n    main()\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:def main()"}, "tags": ["anton_repo"]}
{"id": "b0000159", "domain": "anton_repo", "section_path": ["server/agent/self_study.py"], "page": 24, "block_index": 1, "block_type": "code", "text": "# server/agent/self_study.py\n# Step 6: Self-study / Mastery tracker (domain-agnostic with plugins)\n#\n# What it does\n# - Loads nodes.jsonl (+graph_adj.json) for a pack\n# - Generates drills per concept node with the LLM (strict JSON)\n# - Solves each drill using your domain bundle (RAG + graph expansion)\n# - Verifies via pluggable verifier (e.g., calculus→SymPy)\n# - Logs attempts and updates per-node mastery stats\n#\n# Usage\n#   python -m server.agent.self_study \\\n#     --pack-dir packs/calc.v1 \\\n#     --api http://127.0.0.1:8001 \\\n#     --domain calculus \\\n#     --drills-per-node 2 \\\n#     --sample-nodes 8 \\\n#     --temperature 0.2 \\\n#     --save-good-examples\n#\n# Outputs (in pack dir)\n#   self_study_attempts.jsonl   # one line per attempt\n#   mastery.json                # per-node rolling stats\n#   examples_aug.jsonl          # harvested good examples (optional)\n#\nimport argparse\nimport asyncio\nimport json\nimport logging\nimport random\nimport re\nimport time\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport httpx\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))\nfrom server.agent.rag_manager import RAGManager, rag_manager  # existing singleton\nfrom server.agent.concept_graph import load_pack, rag_topk_nodes, expand_nodes, format_context\nfrom server.agent.verifiers.types import VerifyRequest, Verdict\nfrom server.agent.verifiers.base import verify as run_verify\nfrom server.config import QWEN_30B_INSTRUCT, QWEN_30B_THINKING\nimport server.agent.verifiers\nlogger = logging.getLogger(__name__)\n\n# ---------------------------- Small utilities ----------------------------\n\n", "source": {"file": "server/agent/self_study.py", "section": "server/agent/self_study.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000160", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, repo_root: Optional[str] = None):\n        \"\"\"Initialize the code indexer with repository root path.\"\"\"\n        self.repo_root = self._find_repo_root() if repo_root is None else repo_root\n        # Track indexed files and their content hashes to detect changes\n        self.indexed_files_meta: Dict[str, str] = {}  # path -> content_hash\n        self.source_to_ids: Dict[str, List[int]] = {}  # source -> list of document IDs\n\n        # Directories to exclude (expanded list)\n        self.exclude_dirs = {\n            # Python-specific\n            '__pycache__', 'venv', 'env', '.venv', '.env', '.pytest_cache',\n            # JS/TS-specific\n            'node_modules', 'dist', 'build', '.next',\n            # Version control\n            '.git', '.svn', '.hg',\n            # Data directories\n            'data', 'datasets', 'chroma_db',\n            # Cache and output directories\n            '.cache', '.chainlit',\n            # OS-specific\n            '.DS_Store', 'Thumbs.db'\n        }\n\n        # Specific extensions to exclude (expanded)\n        self.exclude_extensions = {\n            # Python bytecode\n            '.pyc', '.pyo', '.pyd',\n            # Binaries\n            '.so', '.dll', '.exe', '.bin', '.dat',\n            # Images\n            '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.webp', '.svg', '.pdf',\n            # Archives\n            '.zip', '.tar', '.gz', '.7z', '.rar', '.jar', '.war',\n            # Media\n            '.mp3', '.mp4', '.avi', '.mov', '.flv', '.wav',\n            # Data files\n            '.db', '.sqlite', '.mdb', '.ldb', '.npy', '.pkl', '.index',\n            # Log and cache files\n            '.log', '.cache', '.tmp',\n            # IDE/editor files\n            '.idea', '.vscode', '.vs'\n        }\n\n        # Specific files to exclude by pattern\n        self.exclude_file_patterns = [\n            '.*',          # All hidden files\n            '*.lock',      # Lock files\n            '*.min.*',     # Minified files\n            'package-lock.json',\n            'yarn.lock',\n            'poetry.lock',\n            'Pipfile.lock',\n            'requirements*.txt',\n            '.env*',\n            '.flake8',\n            '.gitignore',\n            '.prettierrc',\n            '.eslintrc',\n            'Dockerfile',\n            'LICENSE',\n            '*.md5',\n            '*.sum'\n        ]\n\n        # Only include these extensions\n        self.include_extensions = {\n            # Code files\n            '.py', '.js', '.jsx', '.ts', '.tsx', '.html', '.css', '.scss',\n            # Configuration files\n            '.json', '.yaml', '.yml', '.toml',\n            # Documentation\n            '.md', '.rst', '.txt'\n        }\n\n        self.max_file_size_kb = 500  # Reduced to 500KB to avoid very large files\n        self._load_indexed_files_meta()\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def __init__(self, repo_root: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000161", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _find_repo_root(self) -> str:\n        \"\"\"Find the Git repository root using git command.\"\"\"\n        try:\n            result = subprocess.run(\n                ['git', 'rev-parse', '--show-toplevel'],\n                capture_output=True, text=True, check=True\n            )\n            return result.stdout.strip()\n        except (subprocess.SubprocessError, FileNotFoundError):\n            logger.warning(\"Could not determine Git repo root. Using current directory.\")\n            return os.getcwd()\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _find_repo_root(self)"}, "tags": ["anton_repo"]}
{"id": "b0000162", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _should_index_file(self, file_path: str) -> bool:\n        \"\"\"\n        Determine whether a file should be indexed based on multiple filtering criteria.\n        Returns True if the file should be indexed, False otherwise.\n        \"\"\"\n        # Skip files in excluded directories\n        parts = Path(file_path).parts\n        for part in parts:\n            if part in self.exclude_dirs or any(fnmatch.fnmatch(part, pattern) for pattern in ['.*']):\n                return False\n\n        # Get file name and extension\n        file_name = os.path.basename(file_path)\n        _, ext = os.path.splitext(file_path)\n        ext = ext.lower()\n\n        # Skip files matching exclude patterns\n        if any(fnmatch.fnmatch(file_name, pattern) for pattern in self.exclude_file_patterns):\n            return False\n\n        # Skip files with excluded extensions\n        if ext in self.exclude_extensions:\n            return False\n\n        # Skip files that aren't in the include list (if specified)\n        if self.include_extensions and ext not in self.include_extensions:\n            return False\n\n        # Skip files that are too large\n        try:\n            if os.path.getsize(file_path) > self.max_file_size_kb * 1024:\n                logger.info(f\"Skipping large file: {file_path}\")\n                return False\n        except OSError:\n            return False\n\n        # Simple binary file detection\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                # Try to read the first few kb to see if it's text\n                sample = f.read(1024)\n                # If sample contains null bytes, it's probably binary\n                if '\\0' in sample:\n                    logger.info(f\"Skipping binary file: {file_path}\")\n                    return False\n        except UnicodeDecodeError:\n            logger.info(f\"Skipping binary file (decode error): {file_path}\")\n            return False\n        except Exception as e:\n            logger.warning(f\"Error checking file {file_path}: {e}\")\n            return False\n\n        return True\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _should_index_file(self, file_path: str)"}, "tags": ["anton_repo"]}
{"id": "b0000163", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _compute_content_hash(self, content: str) -> str:\n        \"\"\"\n        Compute a hash of file content to detect changes.\n        \"\"\"\n        return hashlib.md5(content.encode('utf-8')).hexdigest()\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _compute_content_hash(self, content: str)"}, "tags": ["anton_repo"]}
{"id": "b0000164", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def _load_indexed_files_meta(self) -> None:\n        \"\"\"\n        Load metadata about indexed files from the document store.\n        This helps us track what's already indexed and their content hashes.\n        \"\"\"\n        if not hasattr(rag_manager, 'doc_store') or not hasattr(rag_manager, 'index'):\n            logger.warning(\"RAG manager not properly initialized, can't load indexed files metadata\")\n            return\n\n        try:\n            # Build source_to_ids mapping from the current document store\n            self.source_to_ids = {}\n            for doc_id, doc in rag_manager.doc_store.items():\n                source = doc.get('source', '')\n\n                # Check if this is a code file source (contains a path)\n                if ':' in source:  # Format is typically \"path:section\"\n                    file_path = source.split(':', 1)[0]  # Extract just the file path part\n\n                    if file_path not in self.source_to_ids:\n                        self.source_to_ids[file_path] = []\n                    self.source_to_ids[file_path].append(doc_id)\n\n            # Update indexed_files_meta\n            for file_path in self.source_to_ids.keys():\n                abs_path = os.path.join(self.repo_root, file_path)\n                if os.path.exists(abs_path):\n                    try:\n                        with open(abs_path, 'r', encoding='utf-8') as f:\n                            content = f.read()\n                            self.indexed_files_meta[file_path] = self._compute_content_hash(content)\n                    except Exception:\n                        pass  # Skip files that can't be read\n\n            logger.info(f\"Loaded metadata for {len(self.indexed_files_meta)} previously indexed files\")\n\n        except Exception as e:\n            logger.error(f\"Error loading indexed files metadata: {e}\", exc_info=True)\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _load_indexed_files_meta(self)"}, "tags": ["anton_repo"]}
{"id": "b0000165", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def _chunk_code_file(self, file_path: str, content: str) -> List[Dict[str, str]]:\n        \"\"\"\n        Split a code file into logical chunks for better retrieval.\n\n        For Python files, this tries to chunk by class and function definitions.\n        For other files, it uses simpler line-based chunking.\n        \"\"\"\n        chunks = []\n        _, ext = os.path.splitext(file_path)\n        rel_path = os.path.relpath(file_path, self.repo_root)\n\n        # If it's a Python file, use more sophisticated chunking\n        if ext.lower() == '.py':\n            # Simple implementation for Python files - split by classes and functions\n            import re\n\n            # Pattern for class and function definitions\n            pattern = r'(class\\s+\\w+\\(.*?\\)|def\\s+\\w+\\(.*?\\))'\n\n            # Get all matches of the pattern\n            matches = list(re.finditer(pattern, content))\n\n            if not matches:\n                # If no matches, treat the whole file as a chunk\n                chunks.append({\n                    \"text\": content,\n                    \"source\": f\"{rel_path}:FULL\"\n                })\n                return chunks\n\n            # Process each chunk\n            for i, match in enumerate(matches):\n                start_pos = match.start()\n                # If it's the last match, go to the end of the file\n                end_pos = matches[i+1].start() if i < len(matches) - 1 else len(content)\n\n                chunk_content = content[start_pos:end_pos]\n                # Get the definition line\n                definition_line = match.group(0)\n\n                chunks.append({\n                    \"text\": chunk_content,\n                    \"source\": f\"{rel_path}:{definition_line.strip()}\"\n                })\n\n            # Also add the imports and module-level code at the top\n            if matches and matches[0].start() > 0:\n                top_content = content[:matches[0].start()]\n                chunks.append({\n                    \"text\": top_content,\n                    \"source\": f\"{rel_path}:IMPORTS\"\n                })\n\n            return chunks\n\n        # For other files, use simpler line-based chunking\n        lines = content.split('\\n')\n        chunk_size = 100  # Number of lines per chunk\n\n        for i in range(0, len(lines), chunk_size):\n            chunk_lines = lines[i:i + chunk_size]\n            chunk_content = '\\n'.join(chunk_lines)\n\n            chunks.append({\n                \"text\": chunk_content,\n                \"source\": f\"{rel_path}:{i+1}-{i+len(chunk_lines)}\"\n            })\n\n        return chunks\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _chunk_code_file(self, file_path: str, content: str)"}, "tags": ["anton_repo"]}
{"id": "b0000166", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def _remove_previous_chunks(self, rel_path: str) -> None:\n        \"\"\"\n        Remove all previously indexed chunks for a specific file.\n        \"\"\"\n        # Get all document IDs that need to be removed\n        doc_ids_to_remove = []\n\n        # Find all documents with sources starting with this file path\n        for source, ids in list(self.source_to_ids.items()):\n            if source == rel_path or source.startswith(f\"{rel_path}:\"):\n                doc_ids_to_remove.extend(ids)\n                # Remove from the source_to_ids mapping\n                del self.source_to_ids[source]\n\n        if not doc_ids_to_remove:\n            return\n\n        # Remove documents from the document store\n        removed_count = 0\n        for doc_id in doc_ids_to_remove:\n            if doc_id in rag_manager.doc_store:\n                del rag_manager.doc_store[doc_id]\n                removed_count += 1\n\n        # Rebuild the FAISS index to remove orphaned vectors\n        if removed_count > 0:\n            rag_manager.rebuild_index()\n            logger.info(f\"Removed {removed_count} previous chunks for {rel_path} and rebuilt FAISS index\")\n        else:\n            logger.info(f\"No chunks found to remove for {rel_path}\")\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def _remove_previous_chunks(self, rel_path: str)"}, "tags": ["anton_repo"]}
{"id": "b0000167", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def index_file(self, file_path: str) -> bool:\n        \"\"\"\n        Index a single file by chunking it and adding to the RAG system.\n        If the file was previously indexed, check if it changed before reindexing.\n        \"\"\"\n        if not self._should_index_file(file_path):\n            return False\n\n        try:\n            # Get relative path for storage\n            rel_path = os.path.relpath(file_path, self.repo_root)\n\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            # Compute content hash to check for changes\n            content_hash = self._compute_content_hash(content)\n\n            # Check if file already indexed and unchanged\n            if rel_path in self.indexed_files_meta and self.indexed_files_meta[rel_path] == content_hash:\n                logger.debug(f\"Skipping unchanged file: {rel_path}\")\n                return False\n\n            # File is new or changed, remove previous chunks if they exist\n            if rel_path in self.indexed_files_meta:\n                self._remove_previous_chunks(rel_path)\n\n            # Create new chunks and add to RAG\n            chunks = self._chunk_code_file(file_path, content)\n\n            # Track the document IDs for each chunk by source\n            for chunk in chunks:\n                # Add the chunk to RAG manager\n                rag_manager.add_knowledge(\n                    text=chunk[\"text\"],\n                    source=chunk[\"source\"]\n                )\n\n                # Get the document ID for this chunk (it's the last one added)\n                doc_id = rag_manager.index.ntotal - 1\n\n                # Track the source -> ID mapping\n                source = chunk[\"source\"]\n                if source not in self.source_to_ids:\n                    self.source_to_ids[source] = []\n                self.source_to_ids[source].append(doc_id)\n\n            # Update the indexed files metadata\n            self.indexed_files_meta[rel_path] = content_hash\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Error indexing file {file_path}: {e}\")\n            return False\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def index_file(self, file_path: str)"}, "tags": ["anton_repo"]}
{"id": "b0000168", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def index_directory(self, dir_path: str = None) -> int:\n        \"\"\"\n        Recursively index all code files in the given directory.\n        Returns the number of files indexed.\n        \"\"\"\n        if dir_path is None:\n            dir_path = self.repo_root\n\n        files_indexed = 0\n\n        try:\n            for root, dirs, files in os.walk(dir_path):\n                # Skip excluded directories\n                dirs[:] = [d for d in dirs if d not in self.exclude_dirs and not d.startswith('.')]\n\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    if self.index_file(file_path):\n                        files_indexed += 1\n\n            return files_indexed\n\n        except Exception as e:\n            logger.error(f\"Error indexing directory {dir_path}: {e}\")\n            return files_indexed\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def index_directory(self, dir_path: str = None)"}, "tags": ["anton_repo"]}
{"id": "b0000169", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def refresh_index(self) -> int:\n        \"\"\"\n        Re-index only the files that have changed since the last indexing.\n        Returns the number of files updated.\n        \"\"\"\n        files_updated = 0\n\n        try:\n            # Get list of files tracked by git\n            result = subprocess.run(\n                ['git', 'ls-files', '--full-name'],\n                capture_output=True, text=True, check=True,\n                cwd=self.repo_root\n            )\n            all_files = result.stdout.strip().split('\\n')\n\n            # Get list of modified files\n            result = subprocess.run(\n                ['git', 'ls-files', '--modified', '--full-name'],\n                capture_output=True, text=True, check=True,\n                cwd=self.repo_root\n            )\n            modified_files = result.stdout.strip().split('\\n') if result.stdout.strip() else []\n\n            # Index all new and modified files\n            for file in all_files:\n                if not file:\n                    continue\n\n                file_path = os.path.join(self.repo_root, file)\n\n                # If file is not already indexed or has been modified\n                is_modified = file in modified_files\n                rel_path = os.path.relpath(file_path, self.repo_root)\n\n                if rel_path not in self.indexed_files_meta or is_modified:\n                    if self.index_file(file_path):\n                        files_updated += 1\n\n            return files_updated\n\n        except Exception as e:\n            logger.error(f\"Error refreshing index: {e}\")\n            return files_updated\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def refresh_index(self)"}, "tags": ["anton_repo"]}
{"id": "b0000170", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def get_indexed_files_count(self) -> int:\n        \"\"\"Return the number of indexed files.\"\"\"\n        return len(self.indexed_files_meta)\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def get_indexed_files_count(self)"}, "tags": ["anton_repo"]}
{"id": "b0000171", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def get_stats(self) -> Dict:\n        \"\"\"Return statistics about the indexed codebase.\"\"\"\n        file_extensions = {}\n\n        for file_path in self.indexed_files_meta.keys():\n            _, ext = os.path.splitext(file_path)\n            ext = ext.lower()\n            if ext in file_extensions:\n                file_extensions[ext] += 1\n            else:\n                file_extensions[ext] = 1\n\n        return {\n            \"total_files\": len(self.indexed_files_meta),\n            \"file_extensions\": file_extensions,\n            \"knowledge_entries\": rag_manager.index.ntotal if hasattr(rag_manager, 'index') else 0\n        }\n\n# Create a global instance for use across the application\ncode_indexer = CodeIndexer()", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:def get_stats(self)"}, "tags": ["anton_repo"]}
{"id": "b0000172", "domain": "anton_repo", "section_path": ["server/agent/code_indexer.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "\"\"\"\nA service that indexes all code in the repository for self-reflection capabilities.\nWith improved filtering and proper update logic to avoid duplicate entries.\n\"\"\"\nimport os\nimport logging\nimport fnmatch\nimport hashlib\nfrom pathlib import Path\nfrom typing import List, Dict, Set, Optional, Tuple\nimport subprocess\n\nfrom server.agent.rag_manager import rag_manager\n\nlogger = logging.getLogger(__name__)\n\nclass CodeIndexer:\n    \"\"\"\n    Scans the codebase, chunks code files appropriately, and adds them to the RAG system.\n    Includes robust filtering and proper updating to prevent duplication.\n    \"\"\"\n\n    ", "source": {"file": "server/agent/code_indexer.py", "section": "server/agent/code_indexer.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000173", "domain": "anton_repo", "section_path": ["server/agent/models.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class AgentAction(BaseModel):\n    \"\"\"\n    A model representing a specific action to be taken by the agent.\n\n    Note: This model was in the original code but is not actively used\n    in the agent loop. It is preserved here for potential future use.\n    \"\"\"\n    action: str\n    data: list | str", "source": {"file": "server/agent/models.py", "section": "server/agent/models.py:class AgentAction(BaseModel)"}, "tags": ["anton_repo"]}
{"id": "b0000174", "domain": "anton_repo", "section_path": ["server/agent/models.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "# agent/models.py\n\n\"\"\"\nContains Pydantic models for data structures used throughout the agent.\n\"\"\"\nfrom pydantic import BaseModel\n\n\n", "source": {"file": "server/agent/models.py", "section": "server/agent/models.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000175", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class ContextType(Enum):\n    \"\"\"Types of context information\"\"\"\n    FILE_CONTENT = \"file_content\"\n    DIRECTORY_LISTING = \"directory_listing\"\n    TOOL_EXECUTION = \"tool_execution\"\n    PLANNER_INSIGHT = \"planner_insight\"\n    EVALUATOR_FEEDBACK = \"evaluator_feedback\"\n    TASK_PROGRESS = \"task_progress\"\n    MESSAGE = \"message\"\n    THOUGHT = \"thought\"\n    ACTION = \"action\"\n\n\n", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:class ContextType(Enum)"}, "tags": ["anton_repo"]}
{"id": "b0000176", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "class ImportanceLevel(Enum):\n    \"\"\"Importance levels for context prioritization\"\"\"\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n\n@dataclass\nclass ContextItem:\n    \"\"\"Represents a single piece of context with metadata\"\"\"\n    content: str\n    context_type: ContextType\n    importance: ImportanceLevel\n    timestamp: float\n    source: str\n    metadata: Dict[str, Any] = None\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:class ImportanceLevel(Enum)"}, "tags": ["anton_repo"]}
{"id": "b0000177", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def __post_init__(self):\n        if self.metadata is None:\n            self.metadata = {}\n\n\nclass KnowledgeStore:\n    \"\"\"\n    Centralized knowledge management that tracks and persists context across all agent components.\n    Integrates with existing RAG manager for persistent storage.\n    \"\"\"\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def __post_init__(self)"}, "tags": ["anton_repo"]}
{"id": "b0000178", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def __init__(self):\n        # In-memory context tracking (similar to existing context_store)\n        self.explored_files: Set[str] = set()\n        self.code_content: Dict[str, str] = {}\n        self.task_progress: List[str] = []\n        \n        # Enhanced context management\n        self.context_items: List[ContextItem] = []\n        self.importance_weights = {\n            ImportanceLevel.LOW: 1.0,\n            ImportanceLevel.MEDIUM: 2.0, \n            ImportanceLevel.HIGH: 4.0,\n            ImportanceLevel.CRITICAL: 8.0\n        }\n        \n        # Conversation state management (replaces ConversationState)\n        self.messages: List[Dict[str, str]] = []\n        self.tool_outputs: Dict[str, Any] = {}\n        self.start_time = time.time()\n        self.is_complete = False\n        self.final_response = \"\"\n    \n    def add_context(\n        self, \n        content: str, \n        context_type: ContextType,\n        importance: ImportanceLevel = ImportanceLevel.MEDIUM,\n        source: str = \"unknown\",\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> None:\n        \"\"\"Add a new context item with importance weighting\"\"\"\n        context_item = ContextItem(\n            content=content,\n            context_type=context_type,\n            importance=importance,\n            timestamp=time.time(),\n            source=source,\n            metadata=metadata or {}\n        )\n        \n        self.context_items.append(context_item)\n        \n        # Update legacy fields for backward compatibility\n        if context_type == ContextType.FILE_CONTENT:\n            file_path = metadata.get(\"file_path\") if metadata else None\n            if file_path:\n                self.explored_files.add(file_path)\n                self.code_content[file_path] = content\n        elif context_type == ContextType.TASK_PROGRESS:\n            self.task_progress.append(content)\n        \n        # Persist high importance items immediately to RAG\n        if importance in [ImportanceLevel.HIGH, ImportanceLevel.CRITICAL]:\n            self._persist_to_rag(context_item)\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def __init__(self)"}, "tags": ["anton_repo"]}
{"id": "b0000179", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def update_from_tool_execution(self, tool_name: str, tool_args: dict, result: str) -> None:\n        \"\"\"Update knowledge store from tool execution results\"\"\"\n        if tool_name == \"read_file\":\n            file_path = tool_args.get(\"file_path\")\n            if file_path:\n                # Determine importance based on file type and size\n                importance = self._determine_file_importance(file_path, result)\n                self.add_context(\n                    content=result[:10000] if len(result) > 10000 else result,\n                    context_type=ContextType.FILE_CONTENT,\n                    importance=importance,\n                    source=f\"tool_execution_{tool_name}\",\n                    metadata={\"file_path\": file_path, \"full_size\": len(result)}\n                )\n        \n        elif tool_name == \"list_directory\":\n            path = tool_args.get(\"path\", \".\")\n            self.explored_files.add(path)  # Add directory to explored files\n            self.add_context(\n                content=result,\n                context_type=ContextType.DIRECTORY_LISTING,\n                importance=ImportanceLevel.LOW,\n                source=f\"tool_execution_{tool_name}\",\n                metadata={\"directory_path\": path}\n            )\n            \n        else:\n            # Generic tool execution tracking\n            self.add_context(\n                content=f\"Tool {tool_name} executed with result: {result[:500]}\",\n                context_type=ContextType.TOOL_EXECUTION,\n                importance=ImportanceLevel.LOW,\n                source=f\"tool_execution_{tool_name}\",\n                metadata={\"tool_args\": tool_args}\n            )\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def update_from_tool_execution(self, tool_name: str, tool_args: dict, result: str)"}, "tags": ["anton_repo"]}
{"id": "b0000180", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def add_planner_insight(self, insight: str, importance: ImportanceLevel = ImportanceLevel.MEDIUM) -> None:\n        \"\"\"Add insights from planner analysis\"\"\"\n        self.add_context(\n            content=insight,\n            context_type=ContextType.PLANNER_INSIGHT,\n            importance=importance,\n            source=\"planner\"\n        )\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def add_planner_insight(self, insight: str, importance: ImportanceLevel = ImportanceLevel.MEDIUM)"}, "tags": ["anton_repo"]}
{"id": "b0000181", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def add_evaluator_feedback(self, feedback: str, importance: ImportanceLevel = ImportanceLevel.HIGH) -> None:\n        \"\"\"Add evaluator feedback to knowledge store\"\"\"\n        self.add_context(\n            content=feedback,\n            context_type=ContextType.EVALUATOR_FEEDBACK,\n            importance=importance,\n            source=\"evaluator\"\n        )\n        \n        # Evaluator feedback is always important, so persist it\n        self._persist_to_rag(self.context_items[-1])\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def add_evaluator_feedback(self, feedback: str, importance: ImportanceLevel = ImportanceLevel.HIGH)"}, "tags": ["anton_repo"]}
{"id": "b0000182", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def get_prioritized_context(self, max_items: int = 10, context_types: Optional[List[ContextType]] = None) -> List[ContextItem]:\n        \"\"\"Get context items prioritized by importance and recency\"\"\"\n        filtered_items = self.context_items\n        \n        if context_types:\n            filtered_items = [item for item in filtered_items if item.context_type in context_types]\n        \n        # Sort by importance weight and recency (more recent = higher score)\n        current_time = time.time()\n        scored_items = []\n        \n        for item in filtered_items:\n            # Calculate recency score (more recent = higher score, decay over time)\n            age_hours = (current_time - item.timestamp) / 3600\n            recency_score = max(0.1, 1.0 / (1.0 + age_hours * 0.1))  # Decay over time\n            \n            # Combine importance weight with recency\n            total_score = self.importance_weights[item.importance] * recency_score\n            scored_items.append((total_score, item))\n        \n        # Sort by score (highest first) and return top items\n        scored_items.sort(key=lambda x: x[0], reverse=True)\n        return [item for _, item in scored_items[:max_items]]\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def get_prioritized_context(self, max_items: int = 10, context_types: Optional[List[ContextType]] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000183", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def build_context_summary(self) -> str:\n        \"\"\"Build a comprehensive context summary for planner\"\"\"\n        summary_parts = []\n        \n        # Get prioritized context\n        priority_items = self.get_prioritized_context(max_items=15)\n        \n        if self.explored_files:\n            summary_parts.append(\"Explored files: \" + \", \".join(list(self.explored_files)[:10]))\n        \n        if self.code_content:\n            summary_parts.append(\"Retrieved file contents:\")\n            for filename in list(self.code_content.keys())[:5]:\n                summary_parts.append(f\"- {filename}\")\n        \n        if self.task_progress:\n            summary_parts.append(\"Progress so far:\")\n            for step in self.task_progress[-5:]:  # Last 5 progress items\n                summary_parts.append(f\"- {step}\")\n        \n        # Add high-priority insights\n        high_priority = [item for item in priority_items if item.importance in [ImportanceLevel.HIGH, ImportanceLevel.CRITICAL]]\n        if high_priority:\n            summary_parts.append(\"\\nKey insights:\")\n            for item in high_priority[:3]:\n                summary_parts.append(f\"- [{item.context_type.value}] {item.content[:200]}...\")\n        \n        return \"\\n\".join(summary_parts)\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def build_context_summary(self)"}, "tags": ["anton_repo"]}
{"id": "b0000184", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def get_legacy_context_store(self) -> dict:\n        \"\"\"Return legacy context store format for backward compatibility\"\"\"\n        return {\n            \"explored_files\": self.explored_files,\n            \"code_content\": self.code_content,\n            \"task_progress\": self.task_progress\n        }\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def get_legacy_context_store(self)"}, "tags": ["anton_repo"]}
{"id": "b0000185", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def _determine_file_importance(self, file_path: str, content: str) -> ImportanceLevel:\n        \"\"\"Determine importance of a file based on path and content characteristics\"\"\"\n        # Configuration files and main modules are high importance\n        important_patterns = [\n            \"config\", \"main\", \"app\", \"server\", \"client\", \n            \"requirements\", \"setup\", \"package\", \"Dockerfile\"\n        ]\n        \n        if any(pattern in file_path.lower() for pattern in important_patterns):\n            return ImportanceLevel.HIGH\n            \n        # Large files or files with many functions/classes are medium importance\n        if len(content) > 5000 or content.count(\"def \") > 5 or content.count(\"class \") > 2:\n            return ImportanceLevel.MEDIUM\n            \n        return ImportanceLevel.LOW\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def _determine_file_importance(self, file_path: str, content: str)"}, "tags": ["anton_repo"]}
{"id": "b0000186", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def _persist_to_rag(self, context_item: ContextItem) -> None:\n        \"\"\"Persist important context to RAG for long-term memory\"\"\"\n        try:\n            # Format context for RAG storage\n            rag_content = f\"[{context_item.context_type.value}] {context_item.content}\"\n            \n            # Add to RAG knowledge base\n            rag_manager.add_knowledge(\n                text=rag_content,\n                source=f\"{context_item.source}_{context_item.timestamp}\"\n            )\n            logger.debug(f\"Successfully persisted context to RAG: {context_item.context_type.value}\")\n        except Exception as e:\n            # Log the error but don't fail - RAG persistence is not critical\n            logger.error(f\"Failed to persist context to RAG: {e}\", exc_info=True)\n\n    def build_domain_knowledge_context(\n        self,\n        query: str,\n        pack_dir: str,\n        topk: int = 5,\n        expand_radius: int = 1,\n        max_nodes: int = 8,\n        max_examples_per_node: int = 1\n    ) -> str:\n        \"\"\"\n        Retrieve top concepts for the query from the given pack, expand by prerequisites,\n        and return a compact context string to feed the LLM.\n        \"\"\"\n        try:\n            adj, nodes_by_id = load_pack(pack_dir)\n            pack_name = Path(pack_dir).name  # e.g., 'calc.v1'\n            # 1) RAG top-k\n            node_ids = rag_topk_nodes(rag_manager, query, pack_name, topk=topk)\n            if not node_ids:\n                return \"\"\n            # 2) Graph expand\n            expanded = expand_nodes(node_ids, adj, edge_types=(\"depends_on\",), radius=expand_radius)\n            # Keep retrieved nodes first, then add prereqs (dedup while preserving order)\n            keep_order = dict.fromkeys(node_ids + [x for x in expanded if x not in node_ids])\n            ordered_ids = list(keep_order.keys())\n            # 3) Format\n            context = format_context(nodes_by_id, ordered_ids, max_nodes=max_nodes, max_examples_per_node=max_examples_per_node)\n            return context\n        except Exception as e:\n            logger.error(f\"Failed to build domain knowledge context: {e}\", exc_info=True)\n            return \"\"\n        \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def _persist_to_rag(self, context_item: ContextItem)"}, "tags": ["anton_repo"]}
{"id": "b0000187", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def select_pack_by_embedding(self, prompt: str, fallback=\"packs/calc.v1\") -> str:\n        centroids = load_centroids()\n        if not centroids:\n            return fallback\n        q = rag_manager.model.encode([prompt])[0]  # (dim,)\n        best_pack, best_sim = None, -1.0\n        for pack_dir, data in centroids.items():\n            c = np.array(data[\"centroid\"], dtype=np.float32)\n            sim = float(np.dot(q, c) / (np.linalg.norm(q) * np.linalg.norm(c) + 1e-9))\n            if sim > best_sim:\n                best_pack, best_sim = pack_dir, sim\n        # add a floor so random chit-chat doesn’t select a pack\n        return best_pack if best_sim >= 0.35 else fallback\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def select_pack_by_embedding(self, prompt: str, fallback=\"packs/calc.v1\")"}, "tags": ["anton_repo"]}
{"id": "b0000188", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def query_relevant_knowledge(self, query: str, max_results: int = 5) -> List[str]:\n        \"\"\"Query RAG for relevant past knowledge\"\"\"\n        try:\n            # Query both RAG and current context\n            rag_results = rag_manager.retrieve_knowledge(query, top_k=max_results)\n            \n            # Handle different return types from RAG manager (dict or string)\n            rag_texts = []\n            for result in rag_results:\n                if isinstance(result, dict):\n                    rag_texts.append(result.get('text', ''))\n                elif isinstance(result, str):\n                    rag_texts.append(result)\n                else:\n                    rag_texts.append(str(result))\n            \n            # Also search current context items\n            query_lower = query.lower()\n            relevant_current = [\n                item.content for item in self.context_items \n                if query_lower in item.content.lower()\n            ][:max_results//2]\n            \n            return rag_texts + relevant_current\n        except Exception as e:\n            logger.error(f\"Failed to query knowledge: {e}\", exc_info=True)\n            return []\n\n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def query_relevant_knowledge(self, query: str, max_results: int = 5)"}, "tags": ["anton_repo"]}
{"id": "b0000189", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def start_learning_task(self, user_prompt: str):\n        \"\"\"Start tracking a task in the learning loop.\"\"\"\n        learning_loop.start_task(user_prompt)\n\n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def start_learning_task(self, user_prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000190", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def add_learning_action(self, action_type: str, details: dict):\n        \"\"\"Record an action in the current learning task.\"\"\"\n        learning_loop.record_action(action_type, details)\n\n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def add_learning_action(self, action_type: str, details: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000191", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "def complete_learning_task(self, success: bool, feedback: str):\n        \"\"\"Complete the current learning task.\"\"\"\n        return learning_loop.complete_task(success, feedback)\n\n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def complete_learning_task(self, success: bool, feedback: str)"}, "tags": ["anton_repo"]}
{"id": "b0000192", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 18, "block_index": 1, "block_type": "code", "text": "def get_relevant_past_experiences(self, prompt: str):\n        \"\"\"Get relevant past learnings for the current task.\"\"\"\n        return learning_loop.get_relevant_learnings(prompt)\n    \n    # Conversation state management methods (replacing ConversationState)\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def get_relevant_past_experiences(self, prompt: str)"}, "tags": ["anton_repo"]}
{"id": "b0000193", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 19, "block_index": 1, "block_type": "code", "text": "def add_message(self, role: str, content: str, metadata: Optional[Dict] = None):\n        \"\"\"Add a message to the conversation\"\"\"\n        message = {\"role\": role, \"content\": content}\n        if metadata:\n            message.update(metadata)\n        self.messages.append(message)\n        \n        # Also track as context item for advanced prioritization\n        self.add_context(\n            content=content,\n            context_type=ContextType.MESSAGE,\n            importance=ImportanceLevel.MEDIUM,\n            source=f\"message_{role}\",\n            metadata={\"role\": role, **(metadata or {})}\n        )\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def add_message(self, role: str, content: str, metadata: Optional[Dict] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000194", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 20, "block_index": 1, "block_type": "code", "text": "def add_tool_output(self, tool_name: str, output: Any, metadata: Optional[Dict] = None):\n        \"\"\"Store tool execution results\"\"\"\n        self.tool_outputs[tool_name] = {\n            \"output\": output,\n            \"timestamp\": time.time(),\n            \"metadata\": metadata or {}\n        }\n        \n        # Track as context item with high importance\n        self.add_context(\n            content=f\"Tool {tool_name}: {str(output)[:500]}\",\n            context_type=ContextType.TOOL_EXECUTION,\n            importance=ImportanceLevel.HIGH,\n            source=f\"tool_{tool_name}\",\n            metadata={\"tool_name\": tool_name, \"tool_args\": metadata.get(\"args\", {}) if metadata else {}}\n        )\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def add_tool_output(self, tool_name: str, output: Any, metadata: Optional[Dict] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000195", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 21, "block_index": 1, "block_type": "code", "text": "def get_messages_for_llm(self) -> List[Dict[str, str]]:\n        \"\"\"Get messages formatted for LLM consumption\"\"\"\n        return [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in self.messages]\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def get_messages_for_llm(self)"}, "tags": ["anton_repo"]}
{"id": "b0000196", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 22, "block_index": 1, "block_type": "code", "text": "def mark_complete(self, final_response: str):\n        \"\"\"Mark conversation as complete\"\"\"\n        self.is_complete = True\n        self.final_response = final_response\n        self.add_context(\n            content=final_response,\n            context_type=ContextType.MESSAGE,\n            importance=ImportanceLevel.HIGH,\n            source=\"final_response\",\n            metadata={\"final\": True}\n        )\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def mark_complete(self, final_response: str)"}, "tags": ["anton_repo"]}
{"id": "b0000197", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 23, "block_index": 1, "block_type": "code", "text": "def get_duration(self) -> float:\n        \"\"\"Get conversation duration in seconds\"\"\"\n        return time.time() - self.start_time\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def get_duration(self)"}, "tags": ["anton_repo"]}
{"id": "b0000198", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 24, "block_index": 1, "block_type": "code", "text": "def reset_conversation(self, preserve_important_context: bool = True):\n        \"\"\"\n        Reset conversation state for a new conversation.\n        \n        Args:\n            preserve_important_context: If True, keeps CRITICAL and HIGH importance contexts\n                                      from previous sessions. If False, starts completely fresh.\n        \"\"\"\n        # Clear session-specific state\n        self.messages = []\n        self.tool_outputs = {}\n        self.start_time = time.time()\n        self.is_complete = False\n        self.final_response = \"\"\n        \n        # Handle context isolation\n        if preserve_important_context:\n            # Keep only CRITICAL and HIGH importance contexts from previous sessions\n            preserved_context = [\n                item for item in self.context_items \n                if item.importance in [ImportanceLevel.CRITICAL, ImportanceLevel.HIGH]\n            ]\n            self.context_items = preserved_context\n            logger.info(f\"Reset conversation, preserved {len(preserved_context)} important context items\")\n        else:\n            # Complete fresh start - clear all context\n            self.context_items = []\n            logger.info(\"Reset conversation with complete fresh start\")\n    \n    ", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def reset_conversation(self, preserve_important_context: bool = True)"}, "tags": ["anton_repo"]}
{"id": "b0000199", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 25, "block_index": 1, "block_type": "code", "text": "def start_new_session(self):\n        \"\"\"Start a completely new session with fresh context\"\"\"\n        self.reset_conversation(preserve_important_context=False)", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:def start_new_session(self)"}, "tags": ["anton_repo"]}
{"id": "b0000200", "domain": "anton_repo", "section_path": ["server/agent/knowledge_store.py"], "page": 26, "block_index": 1, "block_type": "code", "text": "\"\"\"\nCentralized knowledge management system that tracks context across planner, doer, and evaluator components.\nProvides persistent storage, context prioritization, and knowledge transfer capabilities.\n\"\"\"\nfrom pathlib import Path\nimport time\nimport logging\nfrom typing import Dict, Set, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\n\nimport numpy as np\nfrom server.agent.concept_graph import load_pack, rag_topk_nodes, expand_nodes, format_context\nfrom server.agent.learning_loop import learning_loop\nfrom server.agent.pack_builder import load_centroids\nfrom server.agent.rag_manager import rag_manager\n\n# Configure logger for knowledge store\nlogger = logging.getLogger(__name__)\n\n", "source": {"file": "server/agent/knowledge_store.py", "section": "server/agent/knowledge_store.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000201", "domain": "anton_repo", "section_path": ["server/agent/pack_builder.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def build_pack_centroids(packs_root=\"learning/packs\"):\n    centroids = {}\n    for pack_dir in sorted(Path(packs_root).iterdir()):\n        nodes_path = pack_dir / \"nodes.jsonl\"\n        if not nodes_path.exists(): \n            continue\n        texts = []\n        with nodes_path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                node = json.loads(line)\n                name = node.get(\"name\",\"\")\n                summ = (node.get(\"summary\") or \"\")[:300]\n                texts.append(f\"{name}\\n{summ}\")\n        if not texts: \n            continue\n        emb = rag_manager.model.encode(texts)  # (N, dim)\n        centroid = emb.mean(axis=0).tolist()\n        centroids[str(pack_dir)] = {\"centroid\": centroid}\n    CENTROIDS_PATH.write_text(json.dumps(centroids), encoding=\"utf-8\")\n    return centroids\n\n", "source": {"file": "server/agent/pack_builder.py", "section": "server/agent/pack_builder.py:def build_pack_centroids(packs_root=\"learning/packs\")"}, "tags": ["anton_repo"]}
{"id": "b0000202", "domain": "anton_repo", "section_path": ["server/agent/pack_builder.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def load_centroids():\n    if CENTROIDS_PATH.exists():\n        return json.loads(CENTROIDS_PATH.read_text(encoding=\"utf-8\"))\n    return build_pack_centroids()", "source": {"file": "server/agent/pack_builder.py", "section": "server/agent/pack_builder.py:def load_centroids()"}, "tags": ["anton_repo"]}
{"id": "b0000203", "domain": "anton_repo", "section_path": ["server/agent/pack_builder.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "import json\nfrom pathlib import Path\n\nfrom server.agent.rag_manager import rag_manager\n\n\nCENTROIDS_PATH = Path(\"server/agent/packs/pack_centroids.json\")\n\n", "source": {"file": "server/agent/pack_builder.py", "section": "server/agent/pack_builder.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000204", "domain": "anton_repo", "section_path": ["server/agent/message_handler.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def prepare_initial_messages(request_messages: List[OpenAIChatMessage]) -> List[Dict[str, Any]]:\n    \"\"\"Prepares the initial list of messages for the agent from the request.\"\"\"\n    # This is a good place to inject a system prompt if needed.\n    return [msg.model_dump() for msg in request_messages]\n\n\ndef handle_loop_detection(\n        recent_thoughts: list[str],\n        current_thought: str,\n        messages: list[dict],\n        logger: Any,\n        threshold: int\n) -> bool:\n    \"\"\"\n    Detects and handles reasoning loops by modifying the message history.\n\n    Returns:\n        True if a loop was detected and an intervention message was added.\n    \"\"\"\n    normalized_thought = \" \".join(current_thought.lower().split())\n    recent_thoughts.append(normalized_thought)\n\n    if len(recent_thoughts) > threshold:\n        recent_thoughts.pop(0)\n\n    if len(recent_thoughts) == threshold and len(set(recent_thoughts)) == 1:\n        logger.warning(\"Agent is stuck in a reasoning loop. Intervening.\")\n        messages.append({\n            \"role\": \"user\",\n            \"content\": \"You are repeating the same thought process. You must change your plan. Re-evaluate the problem, try a different tool, or ask for help.\"\n        })\n        recent_thoughts.clear()\n        return True  # Loop detected\n\n    return False  # No loop", "source": {"file": "server/agent/message_handler.py", "section": "server/agent/message_handler.py:def prepare_initial_messages(request_messages: List[OpenAIChatMessage])"}, "tags": ["anton_repo"]}
{"id": "b0000205", "domain": "anton_repo", "section_path": ["server/agent/message_handler.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "# agent/message_handler.py\n\n\"\"\"\nHandles conversation history management and reasoning loop detection.\n\"\"\"\nfrom typing import Any, List, Dict\n\nfrom server.helpers import OpenAIChatMessage\n\n", "source": {"file": "server/agent/message_handler.py", "section": "server/agent/message_handler.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000206", "domain": "anton_repo", "section_path": ["server/agent/concept_graph.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def _dedupe_keep_order(xs: List[str]) -> List[str]:\n    seen = set()\n    out = []\n    for x in xs:\n        if x not in seen:\n            seen.add(x)\n            out.append(x)\n    return out\n\n@lru_cache(maxsize=16)\n", "source": {"file": "server/agent/concept_graph.py", "section": "server/agent/concept_graph.py:def _dedupe_keep_order(xs: List[str])"}, "tags": ["anton_repo"]}
{"id": "b0000207", "domain": "anton_repo", "section_path": ["server/agent/concept_graph.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def load_pack(pack_dir: str) -> Tuple[Dict[str, Dict[str, List[str]]], Dict[str, Dict[str, Any]]]:\n    \"\"\"\n    Returns:\n      adj: {edge_type: {src_id: [dst_id,...]}}\n      nodes: {node_id: node_dict}\n    \"\"\"\n    p = Path(pack_dir)\n    adj_path = p / \"graph_adj.json\"\n    nodes_path = p / \"nodes.jsonl\"\n    if not adj_path.exists():\n        raise FileNotFoundError(f\"Missing {adj_path}\")\n    if not nodes_path.exists():\n        raise FileNotFoundError(f\"Missing {nodes_path}\")\n\n    adj = json.loads(adj_path.read_text(encoding=\"utf-8\"))\n    nodes: Dict[str, Dict[str, Any]] = {}\n    with nodes_path.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            if line.strip():\n                n = json.loads(line)\n                nodes[n[\"id\"]] = n\n    return adj, nodes\n\n", "source": {"file": "server/agent/concept_graph.py", "section": "server/agent/concept_graph.py:def load_pack(pack_dir: str)"}, "tags": ["anton_repo"]}
{"id": "b0000208", "domain": "anton_repo", "section_path": ["server/agent/concept_graph.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def rag_topk_nodes(rag_manager, query: str, pack_name: str, topk: int) -> List[str]:\n    \"\"\"\n    Query FAISS via rag_manager and return a list of node_ids (filtered to this pack).\n    Assumes the 'source' field is a JSON string with {\"pack\":..., \"node_id\":...}\n    \"\"\"\n    hits = rag_manager.retrieve_knowledge(query, top_k=topk * 3)  # overfetch then filter\n    node_ids: List[str] = []\n    for h in hits:\n        src = h.get(\"source\") if isinstance(h, dict) else \"\"\n        try:\n            meta = json.loads(src) if isinstance(src, str) else {}\n        except Exception:\n            meta = {}\n        if meta.get(\"pack\") == pack_name and meta.get(\"node_id\"):\n            node_ids.append(meta[\"node_id\"])\n    return _dedupe_keep_order(node_ids)[:topk]\n\ndef expand_nodes(node_ids: List[str],\n                 adj: Dict[str, Dict[str, List[str]]],\n                 edge_types: Tuple[str, ...] = (\"depends_on\",),\n                 radius: int = 1) -> List[str]:\n    \"\"\"\n    Expand by following specified edge types up to 'radius' hops.\n    \"\"\"\n    frontier = list(node_ids)\n    out = list(node_ids)\n    for _ in range(radius):\n        nxt: List[str] = []\n        for nid in frontier:\n            for et in edge_types:\n                for dst in adj.get(et, {}).get(nid, []):\n                    nxt.append(dst)\n        nxt = _dedupe_keep_order(nxt)\n        # stop if no growth\n        new = [x for x in nxt if x not in out]\n        if not new:\n            break\n        out.extend(new)\n        frontier = new\n    return _dedupe_keep_order(out)\n\ndef format_context(nodes_by_id: Dict[str, Dict[str, Any]],\n                   node_ids: List[str],\n                   max_nodes: int = 8,\n                   max_examples_per_node: int = 1) -> str:\n    \"\"\"\n    Produce a compact, LLM-friendly knowledge bundle:\n    - Name (Type)\n    - Formal rule (when present)\n    - 1–2 sentence summary\n    - 0–1 example I/O\n    \"\"\"\n    chunks: List[str] = []\n    for nid in node_ids[:max_nodes]:\n        n = nodes_by_id.get(nid)\n        if not n:\n            continue\n        header = f\"{n.get('name','').strip()} ({n.get('type','concept')})\"\n        formal = n.get(\"formal\")\n        summary = (n.get(\"summary\") or \"\").strip()\n        part = [f\"### {header}\"]\n        if formal:\n            part.append(f\"Formal: {formal}\")\n        if summary:\n            part.append(summary)\n        exs = [e for e in (n.get(\"examples\") or []) if isinstance(e, dict)]\n        if exs:\n            inp = (exs[0].get(\"input\") or \"\").strip()\n            out = (exs[0].get(\"output\") or \"\").strip()\n            if inp or out:\n                part.append(f\"Example: {inp} -> {out}\".strip())\n        chunks.append(\"\\n\".join(part))\n    return \"\\n\\n\".join(chunks)\n", "source": {"file": "server/agent/concept_graph.py", "section": "server/agent/concept_graph.py:def rag_topk_nodes(rag_manager, query: str, pack_name: str, topk: int)"}, "tags": ["anton_repo"]}
{"id": "b0000209", "domain": "anton_repo", "section_path": ["server/agent/concept_graph.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "# server/agent/concept_graph.py\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any, Optional\nfrom functools import lru_cache\n\n", "source": {"file": "server/agent/concept_graph.py", "section": "server/agent/concept_graph.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000210", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def get_all_resource_usage(logger_instance) -> dict:\n    \"\"\"\n    Captures a snapshot of current CPU, RAM, and usage across ALL GPUs.\n    Returns raw numerical data for calculations.\n    \"\"\"\n    usage = {\n        \"cpu_percent\": psutil.cpu_percent(),\n        \"ram_percent\": psutil.virtual_memory().percent,\n        \"gpus\": []\n    }\n    try:\n        nvmlInit()\n        device_count = nvmlDeviceGetCount()\n        for i in range(device_count):\n            handle = nvmlDeviceGetHandleByIndex(i)\n            gpu_util = nvmlDeviceGetUtilizationRates(handle)\n            mem_info = nvmlDeviceGetMemoryInfo(handle)\n            usage[\"gpus\"].append({\n                \"util_percent\": float(gpu_util.gpu),\n                \"vram_percent\": (mem_info.used / mem_info.total) * 100.0 if mem_info.total > 0 else 0.0\n            })\n    except NameError:\n        pass\n    except NVMLError as e:\n        logger_instance.warning(f\"Could not get GPU stats: {e}\")\n    return usage\n\n\n@asynccontextmanager\nasync ", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def get_all_resource_usage(logger_instance)"}, "tags": ["anton_repo"]}
{"id": "b0000211", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def lifespan(app: FastAPI):\n    \"\"\"Handles application startup and shutdown events.\"\"\"\n    logger.info(\"🚀 Agent Server starting up...\")\n\n    from server.agent.code_indexer import code_indexer\n\n    # Run in a background thread to not block startup\n    import threading\n    ", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def lifespan(app: FastAPI)"}, "tags": ["anton_repo"]}
{"id": "b0000212", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def index_code():\n        logger.info(\"Starting code indexing...\")\n        files_indexed = code_indexer.index_directory()\n        logger.info(f\"✅ Code indexing complete. {files_indexed} files indexed.\")\n        # Save the RAG index to persist embeddings\n        rag_manager.save()\n\n    indexing_thread = threading.Thread(target=index_code)\n    indexing_thread.daemon = True\n    indexing_thread.start()\n\n    # Initialize NVML to check for GPUs\n    try:\n        nvmlInit()\n        logger.info(\"✅ NVML Initialized for GPU monitoring.\")\n    except (NameError, NVMLError):\n        logger.warning(\"NVML not available. GPU stats will not be monitored.\")\n    yield\n    logger.info(\"🌙 Agent Server shutting down.\")\n    logger.info(\"Agent Server shutdown complete.\")\n\n\napp = FastAPI(title=\"Agent Logic Server\", lifespan=lifespan)\n\n\nasync def metrics_collecting_stream_generator(\n        stream: AsyncGenerator[str, None],\n        metrics: MetricsTracker\n) -> AsyncGenerator[str, None]:\n    \"\"\"\n    A wrapper for the agent's streaming response that captures and logs\n    high-level performance metrics for the entire request lifecycle.\n    \"\"\"\n    chunk_count = 0\n    # Use the local get_all_resource_usage function\n    metrics.get_resource_usage = lambda: get_all_resource_usage(logger)\n    metrics.resource_snapshots['agent_request_start'] = metrics.get_resource_usage()\n    try:\n        async for chunk in stream:\n            chunk_count += 1\n            yield chunk\n    finally:\n        metrics.end_time = time.monotonic()\n        metrics.resource_snapshots['agent_request_end'] = metrics.get_resource_usage()\n\n        e2e_latency = metrics.end_time - metrics.start_time\n        throughput = chunk_count / e2e_latency if e2e_latency > 0 else 0\n\n        logger.info(\"--- AGENT SERVER REQUEST METRICS ---\")\n        logger.info(f\"[Latency] Full Request End-to-End: {e2e_latency:.2f} seconds\")\n        logger.info(f\"[Throughput] Chunks per Second: {throughput:.2f}\")\n        logger.info(f\"[Throughput] Total Chunks Streamed: {chunk_count}\")\n\n        start_usage = metrics.resource_snapshots['agent_request_start']\n        end_usage = metrics.resource_snapshots['agent_request_end']\n\n        start_gpu_util_str = \", \".join(\n            [f\"GPU{i}:{gpu['util_percent']:.1f}%\" for i, gpu in enumerate(start_usage['gpus'])]) or \"N/A\"\n        start_vram_str = \", \".join(\n            [f\"GPU{i}:{gpu['vram_percent']:.1f}%\" for i, gpu in enumerate(start_usage['gpus'])]) or \"N/A\"\n        logger.info(\n            f\"[Resources] Start - CPU: {start_usage['cpu_percent']:.1f}%, RAM: {start_usage['ram_percent']:.1f}%, \"\n            f\"Util: {start_gpu_util_str}, VRAM: {start_vram_str}\"\n        )\n\n        end_gpu_util_str = \", \".join(\n            [f\"GPU{i}:{gpu['util_percent']:.1f}%\" for i, gpu in enumerate(end_usage['gpus'])]) or \"N/A\"\n        end_vram_str = \", \".join(\n            [f\"GPU{i}:{gpu['vram_percent']:.1f}%\" for i, gpu in enumerate(end_usage['gpus'])]) or \"N/A\"\n        logger.info(\n            f\"[Resources] End   - CPU: {end_usage['cpu_percent']:.1f}%, RAM: {end_usage['ram_percent']:.1f}%, \"\n            f\"Util: {end_gpu_util_str}, VRAM: {end_vram_str}\"\n        )\n\n        cpu_diff = end_usage['cpu_percent'] - start_usage['cpu_percent']\n        ram_diff = end_usage['ram_percent'] - start_usage['ram_percent']\n\n        if start_usage['gpus'] and end_usage['gpus'] and len(start_usage['gpus']) == len(end_usage['gpus']):\n            gpu_util_diff_str = \", \".join(\n                [f\"GPU{i}:{post['util_percent'] - pre['util_percent']:+.1f}%\" for i, (pre, post) in\n                 enumerate(zip(start_usage['gpus'], end_usage['gpus']))])\n            vram_diff_str = \", \".join(\n                [f\"GPU{i}:{post['vram_percent'] - pre['vram_percent']:+.1f}%\" for i, (pre, post) in\n                 enumerate(zip(start_usage['gpus'], end_usage['gpus']))])\n        else:\n            gpu_util_diff_str = \"N/A\"\n            vram_diff_str = \"N/A\"\n\n        logger.info(\n            f\"[Resources] Difference- CPU: {cpu_diff:+.1f}%, RAM: {ram_diff:+.1f}%, \"\n            f\"Util: {gpu_util_diff_str}, VRAM: {vram_diff_str}\"\n        )\n        logger.info(\"------------------------------------\")\n\n\n@app.post(\"/v1/agent/chat\")\nasync ", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def index_code()"}, "tags": ["anton_repo"]}
{"id": "b0000213", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def agent_chat(request: AgentChatRequest):\n    \"\"\"\n    Handles incoming chat requests using the refactored ReAct agent with KnowledgeStore.\n    Eliminates the complex Planner-Doer-Evaluator loop for simplified control flow.\n    \"\"\"\n    logger.info(\"Agent Server received request. Processing with ReAct agent...\")\n\n    # Reset conversation state for new request\n    knowledge_store = KnowledgeStore()\n    \n    # Create ReAct agent with knowledge store and tool schemas\n    from server.agent.react_agent import ReActAgent\n    available_tools = tool_manager.get_tool_schemas()\n    react_agent = ReActAgent(\n        api_base_url=MODEL_SERVER_URL,\n        tools=available_tools,\n        knowledge_store=knowledge_store,\n        max_iterations=30\n    )\n    \n    # Extract initial messages from request\n    initial_messages = [msg.model_dump() for msg in request.messages]\n    \n    # Process with ReAct agent (replaces the complex organizer loop)\n    metrics = MetricsTracker(logger)\n    \n    async ", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def agent_chat(request: AgentChatRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000214", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def react_with_metrics():\n        async for token in react_agent.process_request(initial_messages, logger):\n            yield token\n    \n    return StreamingResponse(\n        metrics_collecting_stream_generator(react_with_metrics(), metrics),\n        media_type=\"text/plain\"\n    )\n\nfrom server.agent.code_index_refresher import code_refresher\n\n@app.on_event(\"startup\")\n", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def react_with_metrics()"}, "tags": ["anton_repo"]}
{"id": "b0000215", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def start_code_refresher():\n    code_refresher.start()\n\n@app.on_event(\"shutdown\")\n", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def start_code_refresher()"}, "tags": ["anton_repo"]}
{"id": "b0000216", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def stop_code_refresher():\n    code_refresher.stop()\n\n\nif __name__ == \"__main__\":\n    logger.info(f\"Starting Agent Server on {AGENT_SERVER_HOST}:{AGENT_SERVER_PORT}\")\n    uvicorn.run(app, host=AGENT_SERVER_HOST, port=AGENT_SERVER_PORT)\n", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:def stop_code_refresher()"}, "tags": ["anton_repo"]}
{"id": "b0000217", "domain": "anton_repo", "section_path": ["server/agent/agent_server.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "import json\nimport logging\nimport time\nimport psutil\nimport uvicorn\nfrom fastapi import FastAPI\nfrom starlette.responses import StreamingResponse\nfrom contextlib import asynccontextmanager\nfrom typing import AsyncGenerator\n\nfrom vllm.third_party.pynvml import nvmlInit, nvmlDeviceGetCount, nvmlDeviceGetHandleByIndex, \\\n    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo, NVMLError\nfrom server.agent.pack_builder import build_pack_centroids\nbuild_pack_centroids()\nfrom server.agent.config import AGENT_SERVER_HOST, AGENT_SERVER_PORT, MODEL_SERVER_URL\nfrom server.agent.rag_manager import rag_manager\nfrom server.agent.knowledge_store import KnowledgeStore\n\ntry:\n    from pynvml import *\nexcept ImportError:\n    pass\n\nfrom metrics import MetricsTracker\nfrom server.agent.tools.tool_defs import get_all_tools\nfrom server.agent.tools.tool_manager import tool_manager\nfrom server.helpers import AgentChatRequest\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nfrom pathlib import Path\nimport json, numpy as np\nfrom server.agent.rag_manager import rag_manager\n\n\n", "source": {"file": "server/agent/agent_server.py", "section": "server/agent/agent_server.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000218", "domain": "anton_repo", "section_path": ["server/agent/learning_persistance.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def save_learning_data(learning_loop: LearningLoop) -> None:\n    \"\"\"Saves the learning loop data to disk.\"\"\"\n    os.makedirs(os.path.dirname(LEARNING_DATA_PATH), exist_ok=True)\n\n    # Save experiences using pickle (binary format is more efficient for large objects)\n    with open(LEARNING_DATA_PATH, 'wb') as f:\n        pickle.dump(learning_loop.experiences, f)\n\n    # Save metrics as JSON for easier inspection\n    with open(METRICS_DATA_PATH, 'w') as f:\n        json.dump(learning_loop.performance_metrics, f)\n\n\n", "source": {"file": "server/agent/learning_persistance.py", "section": "server/agent/learning_persistance.py:def save_learning_data(learning_loop: LearningLoop)"}, "tags": ["anton_repo"]}
{"id": "b0000219", "domain": "anton_repo", "section_path": ["server/agent/learning_persistance.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def load_learning_data(learning_loop: LearningLoop) -> None:\n    \"\"\"Loads learning data from disk into the learning loop.\"\"\"\n    try:\n        if os.path.exists(LEARNING_DATA_PATH):\n            with open(LEARNING_DATA_PATH, 'rb') as f:\n                learning_loop.experiences = pickle.load(f)\n\n        if os.path.exists(METRICS_DATA_PATH):\n            with open(METRICS_DATA_PATH, 'r') as f:\n                learning_loop.performance_metrics = json.load(f)\n\n    except Exception as e:\n        print(f\"Error loading learning data: {e}\")\n        # Initialize with empty data\n        learning_loop.experiences = []\n        learning_loop.performance_metrics = {\n            \"success_rate\": [],\n            \"task_duration\": [],\n            \"steps_taken\": []\n        }", "source": {"file": "server/agent/learning_persistance.py", "section": "server/agent/learning_persistance.py:def load_learning_data(learning_loop: LearningLoop)"}, "tags": ["anton_repo"]}
{"id": "b0000220", "domain": "anton_repo", "section_path": ["server/agent/learning_persistance.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "\"\"\"\nHandles persisting and loading learning data.\n\"\"\"\nimport json\nimport os\nimport pickle\nfrom typing import Dict, Any\n\nfrom server.agent.learning_loop import LearningLoop\n\nLEARNING_DATA_PATH = \"data/learning/learning_data.pkl\"\nMETRICS_DATA_PATH = \"data/learning/metrics.json\"\n\n\n", "source": {"file": "server/agent/learning_persistance.py", "section": "server/agent/learning_persistance.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000221", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def _strip_prefix(s: str) -> str:\n    s = s.strip()\n    m = re.search(r\"final answer:\\s*(.*)$\", s, flags=re.IGNORECASE | re.DOTALL)\n    return m.group(1).strip() if m else s\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _strip_prefix(s: str)"}, "tags": ["anton_repo"]}
{"id": "b0000222", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _maybe_parse_expr(expr_str: str):\n    s = expr_str.strip()\n    # strip $...$ and \\( ... \\)\n    s = re.sub(r\"^\\s*\\$\\s*|\\s*\\$\\s*$\", \"\", s)\n    s = re.sub(r\"^\\s*\\\\\\(\\s*|\\s*\\\\\\)\\s*$\", \"\", s)\n\n    if HAVE_LATEX:\n        try:\n            return parse_latex(s)\n        except Exception:\n            pass\n\n    # common LaTeX -> SymPy\n    s = (s\n         .replace(\"\\\\arcsin\", \"asin\").replace(\"\\\\arccos\", \"acos\").replace(\"\\\\arctan\", \"atan\")\n         .replace(\"\\\\sin\", \"sin\").replace(\"\\\\cos\", \"cos\").replace(\"\\\\tan\", \"tan\")\n         .replace(\"\\\\ln\", \"log\").replace(\"\\\\log\", \"log\")\n         .replace(\"\\\\pi\", \"pi\")\n         .replace(\"\\\\cdot\", \"*\").replace(\"\\\\times\", \"*\")\n         .replace(\"\\\\sqrt\", \"sqrt\"))\n    s = re.sub(r\"\\\\frac\\s*\\{([^{}]+)\\}\\s*\\{([^{}]+)\\}\", r\"(\\1)/(\\2)\", s)\n    s = re.sub(r\"\\\\left|\\\\right\", \"\", s)\n    s = s.replace(\"{\", \"(\").replace(\"}\", \")\")\n    s = s.replace(\"^\", \"**\")\n    # kill trailing punctuation that sneaks in from problem text\n    s = re.sub(r\"[\\.\\;\\,]\\s*$\", \"\", s)\n\n    # robust fallback with implicit multiplication (handles \"2x+4\")\n    try:\n        return parse_expr(s, transformations=_TRANSFORMS, local_dict={\"x\": x, \"pi\": sympy.pi})\n    except Exception:\n        pass\n\n    try:\n        return sympify(s, {\"x\": x, \"pi\": sympy.pi})\n    except Exception:\n        return None\n\n\n\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _maybe_parse_expr(expr_str: str)"}, "tags": ["anton_repo"]}
{"id": "b0000223", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _num_equal(a, b, tol=1e-6) -> bool:\n    try:\n        return abs(float(a) - float(b)) <= tol\n    except Exception:\n        return False\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _num_equal(a, b, tol=1e-6)"}, "tags": ["anton_repo"]}
{"id": "b0000224", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _extract_fx(problem: str) -> Optional[str]:\n    \"\"\"\n    Extract the RHS of f(x)=... but stop before separators like ' at ', ' for ', comma, or period.\n    \"\"\"\n    m = re.search(\n        r\"f\\s*\\(\\s*x\\s*\\)\\s*=\\s*([^\\n]+?)\\s*(?:,|;|\\.|\\bat\\b|\\bfor\\b|$)\",\n        problem,\n        flags=re.IGNORECASE,\n    )\n    return m.group(1).strip() if m else None\n\n\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _extract_fx(problem: str)"}, "tags": ["anton_repo"]}
{"id": "b0000225", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def _extract_at_point(problem: str) -> Optional[float]:\n    m = re.search(r\"x\\s*=\\s*([+-]?\\d+(?:\\.\\d+)?)\", problem)\n    if m:\n        try:\n            return float(m.group(1))\n        except Exception:\n            return None\n    return None\n\n# ---- verifiers -------------------------------------------------------------\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _extract_at_point(problem: str)"}, "tags": ["anton_repo"]}
{"id": "b0000226", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def _derivative_at_point(req: VerifyRequest) -> Optional[VerifyResult]:\n    if not re.search(r\"(derivative|differentiate|f'\\(x\\)|d/dx)\", req.problem, re.IGNORECASE):\n        return None\n    a = _extract_at_point(req.problem)\n    if a is None:\n        return None  # not a point-evaluation task\n\n    fx_txt = _extract_fx(req.problem)\n    if not fx_txt:\n        return None  # need f(x)=...\n\n    f = _maybe_parse_expr(fx_txt)\n    if f is None:\n        return None\n\n    truth = diff(f, x).subs(x, a)\n    cand_expr_text = _strip_prefix(req.candidate)\n    cand_expr = _maybe_parse_expr(cand_expr_text)\n    if cand_expr is None:\n        # try to parse numeric only\n        cand_num = _maybe_parse_expr(cand_expr_text.replace(\"≈\", \"\").split()[0])\n        if cand_num is None:\n            return None\n        is_ok = _num_equal(truth.evalf(), cand_num.evalf())\n        verdict = Verdict.CORRECT if is_ok else Verdict.INCORRECT\n        return VerifyResult(\n            verdict=verdict,\n            score=1.0 if is_ok else 0.0,\n            expected=str(simplify(truth)),\n            normalized_candidate=str(cand_num),\n            explanation=\"Compared numeric derivative at the evaluation point.\",\n            meta={\"task\": \"derivative_at_point\"},\n        )\n\n    # compare symbolically (or numerically if needed)\n    try:\n        is_ok = simplify(truth - cand_expr) == 0 or _num_equal(truth.evalf(), cand_expr.evalf())\n    except Exception:\n        is_ok = _num_equal(truth.evalf(), cand_expr.evalf())\n\n    return VerifyResult(\n        verdict=Verdict.CORRECT if is_ok else Verdict.INCORRECT,\n        score=1.0 if is_ok else 0.0,\n        expected=str(simplify(truth)),\n        normalized_candidate=str(simplify(cand_expr)),\n        explanation=\"Verified derivative at point via SymPy.\",\n        meta={\"task\": \"derivative_at_point\"},\n    )\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _derivative_at_point(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000227", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def _derivative_expr(req: VerifyRequest) -> Optional[VerifyResult]:\n    if not re.search(r\"(derivative|differentiate|d/dx)\", req.problem, re.IGNORECASE):\n        return None\n    if _extract_at_point(req.problem) is not None:\n        return None  # handled by point case\n\n    fx_txt = _extract_fx(req.problem)\n    if not fx_txt:\n        return None\n\n    f = _maybe_parse_expr(fx_txt)\n    if f is None:\n        return None\n\n    truth = simplify(diff(f, x))\n    cand_expr = _maybe_parse_expr(_strip_prefix(req.candidate))\n    if cand_expr is None:\n        return None\n\n    same = simplify(truth - simplify(cand_expr)) == 0\n    return VerifyResult(\n        verdict=Verdict.CORRECT if same else Verdict.INCORRECT,\n        score=1.0 if same else 0.0,\n        expected=str(truth),\n        normalized_candidate=str(simplify(cand_expr)),\n        explanation=\"Compared symbolic derivatives.\",\n        meta={\"task\": \"derivative_expr\"},\n    )\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _derivative_expr(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000228", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def _limit(req: VerifyRequest) -> Optional[VerifyResult]:\n    if not re.search(r\"(limit|\\\\lim|lim_{)\", req.problem, re.IGNORECASE):\n        return None\n    # very simple extractor: \"... as x -> a\" or \"x→a\"\n    m = re.search(r\"x\\s*(?:->|→)\\s*([+-]?\\d+(?:\\.\\d+)?)\", req.problem)\n    if not m:\n        return None\n    a = float(m.group(1))\n    # try to find expression after 'of' or after 'lim'\n    # e.g. \"Evaluate the limit of (sin(5x))/x as x->0\"\n    ex = None\n    m2 = re.search(r\"of\\s*(.+?)\\s*as\\s*x\", req.problem, re.IGNORECASE)\n    if m2:\n        ex = m2.group(1)\n    if ex is None:\n        # fallback: ')' after lim, very rough\n        m3 = re.search(r\"lim[^\\)]*\\)\\s*([^\\s]+)\", req.problem, re.IGNORECASE)\n        ex = m3.group(1) if m3 else None\n    if not ex:\n        return None\n    f = _maybe_parse_expr(ex)\n    if f is None:\n        return None\n    truth = limit(f, x, a)\n    cand_expr = _maybe_parse_expr(_strip_prefix(req.candidate))\n    if cand_expr is None:\n        # try numeric\n        cand_expr = _maybe_parse_expr(_strip_prefix(req.candidate).replace(\"≈\", \"\").split()[0])\n    if cand_expr is None:\n        return None\n    ok = simplify(truth - cand_expr) == 0 or _num_equal(truth.evalf(), cand_expr.evalf())\n    return VerifyResult(\n        verdict=Verdict.CORRECT if ok else Verdict.INCORRECT,\n        score=1.0 if ok else 0.0,\n        expected=str(simplify(truth)),\n        normalized_candidate=str(simplify(cand_expr)),\n        explanation=\"Verified limit via SymPy.\",\n        meta={\"task\": \"limit\", \"point\": a},\n    )\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _limit(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000229", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def _integral_definite(req: VerifyRequest) -> Optional[VerifyResult]:\n    # \\int_a^b ... dx\n    m = re.search(\n        r\"(?:\\\\int|∫)\\s*[_\\{]\\s*([^}\\s]+)\\s*[\\}^\\s]\\s*[\\^{]\\s*([^}\\s]+)\\s*[\\}]\\s*(.+?)\\s*d\\s*x\",\n        req.problem, re.IGNORECASE\n    )\n    if m:\n        a_txt, b_txt, integ_txt = m.group(1), m.group(2), m.group(3)\n    else:\n        # \"... \\int ... dx from a to b\"\n        m = re.search(\n            r\"(?:\\\\int|∫)\\s*(.+?)\\s*d\\s*x.*?(?:from|between)\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*(?:to|-)\\s*([+-]?\\d+(?:\\.\\d+)?)\",\n            req.problem, re.IGNORECASE\n        )\n        if not m:\n            return None\n        integ_txt, a_txt, b_txt = m.group(1), m.group(2), m.group(3)\n\n    integ_txt = re.sub(r\"[\\.\\;\\,]\\s*$\", \"\", integ_txt)\n    integ = _maybe_parse_expr(integ_txt)\n    a = _maybe_parse_expr(a_txt) or sympify(a_txt)\n    b = _maybe_parse_expr(b_txt) or sympify(b_txt)\n    if integ is None or a is None or b is None:\n        return None\n\n    truth = integrate(integ, (x, a, b))\n    cand = _maybe_parse_expr(_strip_prefix(req.candidate)) or _maybe_parse_expr(_strip_prefix(req.candidate).replace(\"≈\",\"\").split()[0])\n    if cand is None:\n        return None\n    ok = simplify(truth - cand) == 0 or _num_equal(truth.evalf(), cand.evalf())\n    return VerifyResult(\n        verdict=Verdict.CORRECT if ok else Verdict.INCORRECT,\n        score=1.0 if ok else 0.0,\n        expected=str(simplify(truth)),\n        normalized_candidate=str(simplify(cand)),\n        explanation=\"Verified definite integral via SymPy.\",\n        meta={\"task\": \"integral_definite\", \"bounds\": [str(a), str(b)]},\n    )\n\n\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _integral_definite(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000230", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def _integral_indefinite(req: VerifyRequest) -> Optional[VerifyResult]:\n    # accept \\int ... dx OR \"indefinite integral of ...\" / \"antiderivative of ...\"\n    m = re.search(r\"(?:\\\\int|∫)\\s*(.+?)\\s*d\\s*x\", req.problem, re.IGNORECASE)\n    if not m:\n        m = re.search(r\"(?:indefinite integral of|antiderivative of)\\s*(.+)\", req.problem, re.IGNORECASE)\n    if not m:\n        return None\n\n    expr_txt = m.group(1).strip()\n    expr_txt = re.sub(r\"[\\.\\;\\,]\\s*$\", \"\", expr_txt)  # NEW: drop trailing punctuation\n    integ = _maybe_parse_expr(expr_txt)\n    if integ is None:\n        return None\n\n    cand_text = _strip_prefix(req.candidate)\n    cand_text = re.sub(r\"\\+?\\s*C\\b\", \"\", cand_text).strip()  # drop + C for comparison\n    cand = _maybe_parse_expr(cand_text)\n    if cand is None:\n        return None\n\n    same = simplify(diff(cand, x) - integ) == 0\n    return VerifyResult(\n        verdict=Verdict.CORRECT if same else Verdict.INCORRECT,\n        score=1.0 if same else 0.0,\n        expected=str(integrate(integ, x)),\n        normalized_candidate=str(simplify(cand)),\n        explanation=\"Verified indefinite integral by differentiating candidate.\",\n        meta={\"task\": \"integral_indefinite\"},\n    )\n\n\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _integral_indefinite(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000231", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def _evaluate_at_point(req: VerifyRequest):\n    fx_txt = _extract_fx(req.problem)\n    a = _extract_at_point(req.problem)\n    if not fx_txt or a is None:\n        return None\n    f = _maybe_parse_expr(fx_txt)\n    if f is None:\n        return None\n    truth = f.subs(x, a)\n    cand = _maybe_parse_expr(_strip_prefix(req.candidate)) or _maybe_parse_expr(_strip_prefix(req.candidate).replace(\"≈\",\"\").split()[0])\n    if cand is None:\n        return None\n    ok = simplify(truth - cand) == 0 or _num_equal(truth.evalf(), cand.evalf())\n    return VerifyResult(\n        verdict=Verdict.CORRECT if ok else Verdict.INCORRECT,\n        score=1.0 if ok else 0.0,\n        expected=str(simplify(truth)),\n        normalized_candidate=str(simplify(cand)),\n        explanation=\"Verified value of f(x) at a point.\",\n        meta={\"task\": \"evaluate_at_point\", \"point\": a},\n    )\n\n\n@register(\"calculus\")\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def _evaluate_at_point(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000232", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def calculus_router(req: VerifyRequest):\n    fam = (req.context or {}).get(\"task_family\")\n    if fam == \"derivative_at_point\":   return _derivative_at_point(req)\n    if fam == \"derivative_expr\":       return _derivative_expr(req)\n    if fam == \"limit\":                 return _limit(req)\n    if fam == \"integral_definite\":     return _integral_definite(req)\n    if fam == \"integral_indefinite\":   return _integral_indefinite(req)\n    if fam == \"evaluate\":              return _evaluate_at_point(req)\n    # fallback guess\n    for fn in (_derivative_at_point, _derivative_expr, _limit, _integral_definite, _integral_indefinite, _evaluate_at_point):\n        r = fn(req)\n        if r is not None:\n            return r\n    return None\n\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:def calculus_router(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000233", "domain": "anton_repo", "section_path": ["server/agent/verifiers/calc_sympy.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "import re\nimport json\nimport logging\nfrom sympy.parsing.sympy_parser import (\n    parse_expr,\n    standard_transformations,\n    implicit_multiplication_application,\n    convert_xor,\n    function_exponentiation,\n)\n_TRANSFORMS = standard_transformations + (\n    implicit_multiplication_application,\n    convert_xor,\n    function_exponentiation,\n)\n\nfrom typing import Optional, Dict, Any, Tuple\n\nfrom sympy import symbols, diff, simplify, sympify, limit, integrate, Eq\nimport sympy\nfrom sympy.core.relational import Relational\n\ntry:\n    # optional; if not present we fall back to simple parsing\n    from sympy.parsing.latex import parse_latex\n    HAVE_LATEX = True\nexcept Exception:\n    HAVE_LATEX = False\n\nfrom .types import VerifyRequest, VerifyResult, Verdict\nfrom .base import register\n\nlogger = logging.getLogger(__name__)\nx = symbols('x', real=True)\n\n# ---- helpers ---------------------------------------------------------------\n\n", "source": {"file": "server/agent/verifiers/calc_sympy.py", "section": "server/agent/verifiers/calc_sympy.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000234", "domain": "anton_repo", "section_path": ["server/agent/verifiers/__init__.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "from . import calc_sympy as _calc_sympy", "source": {"file": "server/agent/verifiers/__init__.py", "section": "server/agent/verifiers/__init__.py:FULL"}, "tags": ["anton_repo"]}
{"id": "b0000235", "domain": "anton_repo", "section_path": ["server/agent/verifiers/types.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class Verdict(str, Enum):\n    CORRECT = \"correct\"\n    INCORRECT = \"incorrect\"\n    UNKNOWN = \"unknown\"\n\n@dataclass\nclass VerifyRequest:\n    domain: str            # e.g., \"calculus\", \"sql\", \"units\"\n    problem: str           # the original user question (plain text)\n    candidate: str         # model's answer (ideally starts with \"Final Answer:\")\n    context: Optional[Dict[str, Any]] = None  # any extra structured hints\n\n@dataclass\nclass VerifyResult:\n    verdict: Verdict\n    score: float                    # 0..1 confidence\n    expected: Optional[str]         # canonical/correct answer (display string)\n    normalized_candidate: Optional[str]  # parsed/normalized candidate form\n    explanation: str\n    meta: Dict[str, Any]\n\n    ", "source": {"file": "server/agent/verifiers/types.py", "section": "server/agent/verifiers/types.py:class Verdict(str, Enum)"}, "tags": ["anton_repo"]}
{"id": "b0000236", "domain": "anton_repo", "section_path": ["server/agent/verifiers/types.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def to_dict(self) -> Dict[str, Any]:\n        d = asdict(self)\n        d[\"verdict\"] = self.verdict.value\n        return d\n", "source": {"file": "server/agent/verifiers/types.py", "section": "server/agent/verifiers/types.py:def to_dict(self)"}, "tags": ["anton_repo"]}
{"id": "b0000237", "domain": "anton_repo", "section_path": ["server/agent/verifiers/types.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "from dataclasses import dataclass, asdict\nfrom enum import Enum\nfrom typing import Optional, Any, Dict\n\n", "source": {"file": "server/agent/verifiers/types.py", "section": "server/agent/verifiers/types.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000238", "domain": "anton_repo", "section_path": ["server/agent/verifiers/base.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def register(domain: str):\n    \"\"\"\n    Decorator to register a verifier function for a domain.\n    The function should accept VerifyRequest and return VerifyResult or None (if it can't handle the request).\n    \"\"\"\n    ", "source": {"file": "server/agent/verifiers/base.py", "section": "server/agent/verifiers/base.py:def register(domain: str)"}, "tags": ["anton_repo"]}
{"id": "b0000239", "domain": "anton_repo", "section_path": ["server/agent/verifiers/base.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def deco(fn: Callable[[VerifyRequest], Optional[VerifyResult]]):\n        _REGISTRY.setdefault(domain.lower(), []).append(fn)\n        return fn\n    return deco\n\n", "source": {"file": "server/agent/verifiers/base.py", "section": "server/agent/verifiers/base.py:def deco(fn: Callable[[VerifyRequest], Optional[VerifyResult]])"}, "tags": ["anton_repo"]}
{"id": "b0000240", "domain": "anton_repo", "section_path": ["server/agent/verifiers/base.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def verify(req: VerifyRequest) -> VerifyResult:\n    \"\"\"\n    Route to first plugin that can produce a result. If none returns a result, return UNKNOWN.\n    \"\"\"\n    domain = (req.domain or \"\").lower()\n    fns = _REGISTRY.get(domain, []) + _REGISTRY.get(\"*\", [])\n    for fn in fns:\n        try:\n            res = fn(req)\n            if res is not None:\n                return res\n        except Exception as e:\n            logger.exception(\"Verifier '%s' crashed; continuing to next plugin.\", getattr(fn, \"__name__\", \"unknown\"))\n    return VerifyResult(\n        verdict=Verdict.UNKNOWN,\n        score=0.0,\n        expected=None,\n        normalized_candidate=None,\n        explanation=f\"No verifier available for domain '{domain}' or request type.\",\n        meta={\"domain\": domain},\n    )\n", "source": {"file": "server/agent/verifiers/base.py", "section": "server/agent/verifiers/base.py:def verify(req: VerifyRequest)"}, "tags": ["anton_repo"]}
{"id": "b0000241", "domain": "anton_repo", "section_path": ["server/agent/verifiers/base.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "import logging\nfrom typing import Callable, Dict, List, Optional\nfrom .types import VerifyRequest, VerifyResult, Verdict\n\nlogger = logging.getLogger(__name__)\n\n# Simple plugin registry keyed by domain name (lowercase)\n_REGISTRY: Dict[str, List[Callable[[VerifyRequest], Optional[VerifyResult]]]] = {}\n\n", "source": {"file": "server/agent/verifiers/base.py", "section": "server/agent/verifiers/base.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000242", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class LegacyToolWrapper(BaseTool):\n    \"\"\"\n    Wrapper class to make legacy tools compatible with the new BaseTool interface.\n    \"\"\"\n    \n    ", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:class LegacyToolWrapper(BaseTool)"}, "tags": ["anton_repo"]}
{"id": "b0000243", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def __init__(self, legacy_tool_instance: Any, capabilities: list = None):\n        \"\"\"\n        Initialize the wrapper with a legacy tool instance.\n        \n        Args:\n            legacy_tool_instance: The legacy tool instance to wrap\n            capabilities: List of capabilities for this tool\n        \"\"\"\n        self.legacy_tool = legacy_tool_instance\n        self._capabilities = capabilities or []\n        super().__init__()\n    \n    ", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:def __init__(self, legacy_tool_instance: Any, capabilities: list = None)"}, "tags": ["anton_repo"]}
{"id": "b0000244", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def get_metadata(self) -> ToolMetadata:\n        \"\"\"Extract metadata from the legacy tool.\"\"\"\n        function_schema = getattr(self.legacy_tool, 'function', {})\n        function_info = function_schema.get('function', {})\n        \n        name = function_info.get('name', self.legacy_tool.__class__.__name__.lower())\n        description = function_info.get('description', f'Legacy tool: {name}')\n        \n        return ToolMetadata(\n            name=name,\n            version=\"1.0.0\",  # Default version for legacy tools\n            description=description,\n            capabilities=self._capabilities,\n            author=\"Legacy\",\n            tags=[\"legacy\"]\n        )\n    \n    ", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:def get_metadata(self)"}, "tags": ["anton_repo"]}
{"id": "b0000245", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def get_function_schema(self) -> Dict[str, Any]:\n        \"\"\"Return the legacy tool's function schema.\"\"\"\n        return getattr(self.legacy_tool, 'function', {})\n    \n    ", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:def get_function_schema(self)"}, "tags": ["anton_repo"]}
{"id": "b0000246", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: Dict[str, Any]) -> str:\n        \"\"\"Delegate to the legacy tool's run method.\"\"\"\n        return self.legacy_tool.run(arguments)\n\n\n", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:def run(self, arguments: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000247", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def create_legacy_tool_wrappers() -> Dict[str, BaseTool]:\n    \"\"\"\n    Create wrapped versions of all legacy tools.\n    Handles missing dependencies gracefully.\n    \n    Returns:\n        Dictionary mapping tool names to wrapped tool instances\n    \"\"\"\n    wrapped_tools = {}\n    \n    # Try to import and wrap each tool, handling missing dependencies\n    tool_configs = [\n        ('coding', 'ExecutePythonCode', [ToolCapability.CODE_EXECUTION]),\n        ('file_management', 'WriteFileTool', [ToolCapability.FILE_SYSTEM]),\n        ('file_management', 'ReadFileTool', [ToolCapability.FILE_SYSTEM]),\n        ('file_management', 'ListDirectoryTool', [ToolCapability.FILE_SYSTEM]),\n        ('web_search', 'WebSearchTool', [ToolCapability.WEB_SEARCH, ToolCapability.EXTERNAL_API]),\n        ('tool_creation.tool_creator', 'ToolCreator', [ToolCapability.TOOL_CREATION]),\n    ]\n    \n    for module_path, class_name, capabilities in tool_configs:\n        try:\n            module = __import__(f'server.agent.tools.{module_path}', fromlist=[class_name])\n            tool_class = getattr(module, class_name)\n            tool_instance = tool_class()\n            \n            # Extract tool name from function schema\n            tool_name = tool_instance.function.get('function', {}).get('name', class_name.lower())\n            \n            wrapped_tools[tool_name] = LegacyToolWrapper(tool_instance, capabilities)\n            print(f\"🔧 Wrapped legacy tool: {tool_name}\")\n            \n        except ImportError as e:\n            missing_dep = str(e).split(\"'\")[1] if \"'\" in str(e) else \"unknown\"\n            print(f\"ℹ️  Skipping {class_name} due to missing dependency: {missing_dep}\")\n        except Exception as e:\n            print(f\"⚠️  Failed to wrap {class_name}: {e}\")\n    \n    # Try to wrap Git tools\n    try:\n        from server.agent.tools.git import GitManagementSkill\n        git_skill = GitManagementSkill()\n        git_tools = git_skill.get_tools()\n        \n        for git_tool in git_tools:\n            tool_name = git_tool.function.get('function', {}).get('name', 'unknown_git_tool')\n            wrapped_tools[tool_name] = LegacyToolWrapper(\n                git_tool,\n                [ToolCapability.GIT_OPERATIONS, ToolCapability.FILE_SYSTEM]\n            )\n            print(f\"🔧 Wrapped git tool: {tool_name}\")\n    \n    except ImportError as e:\n        print(f\"ℹ️  Skipping Git tools due to missing dependency: {e}\")\n    except Exception as e:\n        print(f\"⚠️  Failed to wrap Git tools: {e}\")\n    \n    return wrapped_tools", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:def create_legacy_tool_wrappers()"}, "tags": ["anton_repo"]}
{"id": "b0000248", "domain": "anton_repo", "section_path": ["server/agent/tools/legacy_wrapper.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "\"\"\"\nCompatibility wrapper for legacy tools to work with the new tool system.\n\"\"\"\n\nfrom typing import Dict, Any\nfrom server.agent.tools.base_tool import BaseTool, ToolMetadata, ToolCapability\n\n\n", "source": {"file": "server/agent/tools/legacy_wrapper.py", "section": "server/agent/tools/legacy_wrapper.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000249", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "class ToolCapability(Enum):\n    \"\"\"Enumeration of tool capabilities for better discovery and categorization.\"\"\"\n    FILE_SYSTEM = \"file_system\"\n    WEB_SEARCH = \"web_search\"\n    CODE_EXECUTION = \"code_execution\"\n    GIT_OPERATIONS = \"git_operations\"\n    TOOL_CREATION = \"tool_creation\"\n    DATA_PROCESSING = \"data_processing\"\n    EXTERNAL_API = \"external_api\"\n\n\n@dataclass\nclass ToolMetadata:\n    \"\"\"Metadata container for tool information.\"\"\"\n    name: str\n    version: str\n    description: str\n    capabilities: List[ToolCapability]\n    author: Optional[str] = None\n    dependencies: Optional[List[str]] = None\n    tags: Optional[List[str]] = None\n\n\n", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:class ToolCapability(Enum)"}, "tags": ["anton_repo"]}
{"id": "b0000250", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "class BaseTool(ABC):\n    \"\"\"\n    Abstract base class for all tools in the system.\n    Provides standardized interface with metadata and versioning support.\n    \"\"\"\n    \n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:class BaseTool(ABC)"}, "tags": ["anton_repo"]}
{"id": "b0000251", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def __init__(self):\n        \"\"\"Initialize the tool with its metadata.\"\"\"\n        self._metadata = self.get_metadata()\n        self._function_schema = self.get_function_schema()\n    \n    @property\n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def __init__(self)"}, "tags": ["anton_repo"]}
{"id": "b0000252", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def metadata(self) -> ToolMetadata:\n        \"\"\"Get tool metadata.\"\"\"\n        return self._metadata\n    \n    @property\n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def metadata(self)"}, "tags": ["anton_repo"]}
{"id": "b0000253", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def function(self) -> Dict[str, Any]:\n        \"\"\"Get the tool's function schema for LLM consumption.\"\"\"\n        return self._function_schema\n    \n    @abstractmethod\n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def function(self)"}, "tags": ["anton_repo"]}
{"id": "b0000254", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def get_metadata(self) -> ToolMetadata:\n        \"\"\"\n        Return metadata about this tool.\n        Must be implemented by each tool.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def get_metadata(self)"}, "tags": ["anton_repo"]}
{"id": "b0000255", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def get_function_schema(self) -> Dict[str, Any]:\n        \"\"\"\n        Return the OpenAI function schema for this tool.\n        Must be implemented by each tool.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def get_function_schema(self)"}, "tags": ["anton_repo"]}
{"id": "b0000256", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: Dict[str, Any]) -> str:\n        \"\"\"\n        Execute the tool with the given arguments.\n        Must be implemented by each tool.\n        \n        Args:\n            arguments: Dictionary of arguments for the tool\n            \n        Returns:\n            String result of the tool execution\n        \"\"\"\n        pass\n    \n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def run(self, arguments: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000257", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def validate_arguments(self, arguments: Dict[str, Any]) -> bool:\n        \"\"\"\n        Validate arguments against the function schema.\n        Override this method for custom validation logic.\n        \n        Args:\n            arguments: Arguments to validate\n            \n        Returns:\n            True if arguments are valid, False otherwise\n        \"\"\"\n        required = self._function_schema.get(\"function\", {}).get(\"parameters\", {}).get(\"required\", [])\n        return all(arg in arguments for arg in required)\n    \n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def validate_arguments(self, arguments: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000258", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def get_full_name(self) -> str:\n        \"\"\"Get the full name including version for conflict resolution.\"\"\"\n        return f\"{self._metadata.name}_v{self._metadata.version.replace('.', '_')}\"\n    \n    ", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def get_full_name(self)"}, "tags": ["anton_repo"]}
{"id": "b0000259", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def is_compatible_version(self, required_version: str) -> bool:\n        \"\"\"\n        Check if this tool version is compatible with the required version.\n        Uses simple semantic versioning rules.\n        \n        Args:\n            required_version: Required version string (e.g., \"1.0.0\")\n            \n        Returns:\n            True if compatible, False otherwise\n        \"\"\"\n        try:\n            current = [int(x) for x in self._metadata.version.split('.')]\n            required = [int(x) for x in required_version.split('.')]\n            \n            # Major version must match exactly\n            if current[0] != required[0]:\n                return False\n            \n            # Minor version must be >= required\n            if len(current) > 1 and len(required) > 1:\n                if current[1] < required[1]:\n                    return False\n            \n            return True\n        except (ValueError, IndexError):\n            return False", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:def is_compatible_version(self, required_version: str)"}, "tags": ["anton_repo"]}
{"id": "b0000260", "domain": "anton_repo", "section_path": ["server/agent/tools/base_tool.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "\"\"\"\nBase tool interface for the dynamic tool management system.\nProvides standardized metadata, versioning, and capability definitions.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n\n", "source": {"file": "server/agent/tools/base_tool.py", "section": "server/agent/tools/base_tool.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000261", "domain": "anton_repo", "section_path": ["server/agent/tools/rebuild_index_tool.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Execute the code index rebuild.\"\"\"\n        from server.agent.code_indexer import code_indexer\n        from server.agent.rag_manager import rag_manager\n\n        confirm = arguments.get('confirm', False)\n\n        if not confirm:\n            return \"⚠️ Rebuild not performed. You must set 'confirm' to true to rebuild the index.\"\n\n        try:\n            # 1. Delete existing index files\n            index_path = rag_manager.index_path\n            doc_store_path = rag_manager.doc_store_path\n\n            files_deleted = 0\n\n            if os.path.exists(index_path):\n                os.remove(index_path)\n                files_deleted += 1\n\n            if os.path.exists(doc_store_path):\n                os.remove(doc_store_path)\n                files_deleted += 1\n\n            # 2. Reset the in-memory structures\n            rag_manager._initialize_empty_stores()\n            code_indexer.indexed_files_meta.clear()\n            code_indexer.source_to_ids.clear()\n\n            # 3. Rebuild the index from scratch\n            start_time = time.time()\n            files_indexed = code_indexer.index_directory()\n            indexing_time = time.time() - start_time\n\n            # 4. Save the new index\n            rag_manager.save()\n\n            return (\n                f\"✅ Successfully rebuilt code index.\\n\"\n                f\"- {files_deleted} old index files deleted\\n\"\n                f\"- {files_indexed} files newly indexed\\n\"\n                f\"- {rag_manager.index.ntotal} total knowledge entries created\\n\"\n                f\"- Completed in {indexing_time:.1f} seconds\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Error during index rebuild: {e}\", exc_info=True)\n            return f\"❌ Error rebuilding index: {str(e)}\"", "source": {"file": "server/agent/tools/rebuild_index_tool.py", "section": "server/agent/tools/rebuild_index_tool.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000262", "domain": "anton_repo", "section_path": ["server/agent/tools/rebuild_index_tool.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "\"\"\"\nTool for completely resetting and rebuilding the code index.\n\"\"\"\nimport os\nimport logging\nimport time\n\nlogger = logging.getLogger(__name__)\n\n\nclass RebuildCodeIndexTool:\n    \"\"\"\n    A tool that completely resets and rebuilds the code index.\n    \"\"\"\n\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rebuild_code_index\",\n            \"description\": \"Completely reset and rebuild the code index. This deletes the existing index first.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"confirm\": {\n                        \"type\": \"boolean\",\n                        \"description\": \"Set to true to confirm the destructive rebuild operation.\"\n                    }\n                },\n                \"required\": [\"confirm\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/rebuild_index_tool.py", "section": "server/agent/tools/rebuild_index_tool.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000263", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def __init__(self, tools_directory: Optional[str] = None):\n        \"\"\"\n        Initialize the tool loader.\n        \n        Args:\n            tools_directory: Path to the tools directory. If None, uses the current directory.\n        \"\"\"\n        if tools_directory is None:\n            self.tools_directory = Path(__file__).parent\n        else:\n            self.tools_directory = Path(tools_directory)\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def __init__(self, tools_directory: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000264", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def list_tool_files(self) -> List[str]:\n        \"\"\"Returns a list of available tool filenames from the tools directory.\"\"\"\n        tool_files = [\n            f.stem for f in self.tools_directory.glob(\"*.py\")\n            if f.name not in ['__init__.py', 'tool_loader.py', 'tool_manager.py', 'tool_defs.py', 'base_tool.py']\n        ]\n        return tool_files\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def list_tool_files(self)"}, "tags": ["anton_repo"]}
{"id": "b0000265", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def discover_tools(self) -> Dict[str, Type[BaseTool]]:\n        \"\"\"\n        Dynamically discover all tools in the tools directory.\n        \n        Returns:\n            Dictionary mapping tool names to their classes\n        \"\"\"\n        discovered_tools = {}\n        tool_files = self.list_tool_files()\n        \n        for tool_file in tool_files:\n            try:\n                tools_in_file = self._load_tools_from_file(tool_file)\n                discovered_tools.update(tools_in_file)\n            except Exception as e:\n                print(f\"⚠️  Warning: Failed to load tools from {tool_file}.py: {e}\")\n                continue\n        \n        return discovered_tools\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def discover_tools(self)"}, "tags": ["anton_repo"]}
{"id": "b0000266", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def _load_tools_from_file(self, module_name: str) -> Dict[str, Type[BaseTool]]:\n        \"\"\"\n        Load all tool classes from a specific module file.\n        \n        Args:\n            module_name: Name of the module to load (without .py extension)\n            \n        Returns:\n            Dictionary mapping tool names to their classes\n        \"\"\"\n        tools = {}\n        \n        try:\n            # Import the module dynamically\n            full_module_name = f\"server.agent.tools.{module_name}\"\n            module = importlib.import_module(full_module_name)\n            \n            # Find all classes that inherit from BaseTool or have the expected interface\n            for name, obj in inspect.getmembers(module, inspect.isclass):\n                if self._is_tool_class(obj) and obj.__module__ == full_module_name:\n                    # Try to instantiate and get the tool name\n                    try:\n                        tool_instance = obj()\n                        tool_name = self._get_tool_name(tool_instance)\n                        tools[tool_name] = obj\n                        print(f\"🔧 Discovered tool: {tool_name} from {module_name}.py\")\n                    except Exception as e:\n                        print(f\"⚠️  Warning: Failed to instantiate {name} from {module_name}.py: {e}\")\n                        continue\n        \n        except ImportError as e:\n            # Don't warn for missing optional dependencies\n            if \"No module named\" in str(e):\n                missing_module = str(e).split(\"'\")[1] if \"'\" in str(e) else \"unknown\"\n                print(f\"ℹ️  Info: Skipping {module_name}.py due to missing dependency: {missing_module}\")\n            else:\n                print(f\"⚠️  Warning: Could not import module {module_name}: {e}\")\n        \n        return tools\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def _load_tools_from_file(self, module_name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000267", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def _is_tool_class(self, cls: Type) -> bool:\n        \"\"\"\n        Check if a class is a valid tool class.\n        \n        Args:\n            cls: Class to check\n            \n        Returns:\n            True if the class is a valid tool, False otherwise\n        \"\"\"\n        # Check if it inherits from BaseTool\n        if issubclass(cls, BaseTool):\n            return True\n        \n        # Check if it has the legacy tool interface (function attribute and run method)\n        if hasattr(cls, 'function') and hasattr(cls, 'run'):\n            return True\n        \n        return False\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def _is_tool_class(self, cls: Type)"}, "tags": ["anton_repo"]}
{"id": "b0000268", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def _get_tool_name(self, tool_instance: Any) -> str:\n        \"\"\"\n        Extract the tool name from a tool instance.\n        \n        Args:\n            tool_instance: Instance of a tool\n            \n        Returns:\n            The tool's name\n        \"\"\"\n        # For BaseTool instances, use metadata\n        if isinstance(tool_instance, BaseTool):\n            return tool_instance.metadata.name\n        \n        # For legacy tools, extract from function schema\n        if hasattr(tool_instance, 'function'):\n            function_schema = tool_instance.function\n            if isinstance(function_schema, dict):\n                return function_schema.get(\"function\", {}).get(\"name\", \"unknown_tool\")\n        \n        # Fallback to class name\n        return tool_instance.__class__.__name__.lower()\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def _get_tool_name(self, tool_instance: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000269", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def create_tool_instances(self) -> Dict[str, Any]:\n        \"\"\"\n        Discover and instantiate all available tools.\n        \n        Returns:\n            Dictionary mapping tool names to their instances\n        \"\"\"\n        tool_classes = self.discover_tools()\n        tool_instances = {}\n        \n        for tool_name, tool_class in tool_classes.items():\n            try:\n                instance = tool_class()\n                tool_instances[tool_name] = instance\n            except Exception as e:\n                print(f\"⚠️  Warning: Failed to instantiate {tool_name}: {e}\")\n                continue\n        \n        return tool_instances\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def create_tool_instances(self)"}, "tags": ["anton_repo"]}
{"id": "b0000270", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def get_tools_by_capability(self, capability: ToolCapability) -> Dict[str, Any]:\n        \"\"\"\n        Get all tools that have a specific capability.\n        \n        Args:\n            capability: The capability to filter by\n            \n        Returns:\n            Dictionary of tools with the specified capability\n        \"\"\"\n        all_tools = self.create_tool_instances()\n        filtered_tools = {}\n        \n        for name, tool in all_tools.items():\n            if isinstance(tool, BaseTool):\n                if capability in tool.metadata.capabilities:\n                    filtered_tools[name] = tool\n            # For legacy tools, we can't filter by capability\n        \n        return filtered_tools\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def get_tools_by_capability(self, capability: ToolCapability)"}, "tags": ["anton_repo"]}
{"id": "b0000271", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def validate_tool_compatibility(self, tool_name: str, required_version: str) -> bool:\n        \"\"\"\n        Check if a tool meets version requirements.\n        \n        Args:\n            tool_name: Name of the tool to check\n            required_version: Required version string\n            \n        Returns:\n            True if the tool meets requirements, False otherwise\n        \"\"\"\n        tools = self.create_tool_instances()\n        tool = tools.get(tool_name)\n        \n        if not tool:\n            return False\n        \n        if isinstance(tool, BaseTool):\n            return tool.is_compatible_version(required_version)\n        \n        # Legacy tools are assumed compatible\n        return True", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:def validate_tool_compatibility(self, tool_name: str, required_version: str)"}, "tags": ["anton_repo"]}
{"id": "b0000272", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_loader.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "import os\nimport importlib\nimport inspect\nfrom typing import List, Dict, Any, Optional, Type\nfrom pathlib import Path\n\nfrom server.agent.tools.base_tool import BaseTool, ToolCapability\n\n\nclass ToolLoader:\n    \"\"\"\n    Enhanced tool loader that dynamically discovers and loads tools from the filesystem.\n    Supports automatic discovery, versioning, and conflict resolution.\n    \"\"\"\n    \n    ", "source": {"file": "server/agent/tools/tool_loader.py", "section": "server/agent/tools/tool_loader.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000273", "domain": "anton_repo", "section_path": ["server/agent/tools/web_search.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        query = arguments.get('query')\n        # Use a default of 3 results if not specified\n        num_results = arguments.get('num_results', 3)\n\n        # Use DuckDuckGo Search API for reliable results\n        search_results = []\n        with DDGS() as ddgs:\n            search_results = list(ddgs.text(\n                keywords=query,\n                region='us-en',\n                safesearch='off',\n                max_results=num_results\n            ))\n\n        if not search_results:\n            return json.dumps([{\"error\": \"No search results found.\", \"query\": query}])\n\n        # Extract data from each link\n        results = []\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n\n        for result in search_results:\n            link = result.get('href')\n            if not link:\n                continue\n\n            try:\n                # Set a timeout to prevent hanging on slow sites\n                response = requests.get(link, headers=headers, timeout=10)\n                response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n\n                soup = BeautifulSoup(response.text, 'html.parser')\n\n                # Extract title and meta description\n                title = soup.title.string.strip() if soup.title else 'No title found'\n\n                meta_desc_tag = soup.find('meta', attrs={'name': 'description'})\n                description = meta_desc_tag[\n                    'content'].strip() if meta_desc_tag and 'content' in meta_desc_tag.attrs else 'No description found'\n\n                results.append({\n                    'title': title,\n                    'url': link,\n                    'description': description\n                })\n            # More specific exception handling\n            except requests.exceptions.RequestException as e:\n                results.append({\n                    'error': f'Failed to fetch URL: {str(e)}',\n                    'url': link\n                })\n            except Exception as e:\n                results.append({\n                    'error': f'An unexpected error occurred while processing URL: {str(e)}',\n                    'url': link\n                })\n\n        # Return a JSON string for easy parsing\n        return json.dumps(results, indent=2)", "source": {"file": "server/agent/tools/web_search.py", "section": "server/agent/tools/web_search.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000274", "domain": "anton_repo", "section_path": ["server/agent/tools/web_search.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "import requests\nfrom bs4 import BeautifulSoup\nfrom duckduckgo_search import DDGS\nimport json  # Import json for a better return format\n\n\nclass WebSearchTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"web_search\",\n            \"description\": \"Searches the web and extracts useful data from the top links.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\"type\": \"string\", \"description\": \"The search query.\"},\n                    \"num_results\": {\"type\": \"integer\", \"description\": \"Number of top results to return.\"}\n                },\n                \"required\": [\"query\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/web_search.py", "section": "server/agent/tools/web_search.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000275", "domain": "anton_repo", "section_path": ["server/agent/tools/__init__.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "", "source": {"file": "server/agent/tools/__init__.py", "section": "server/agent/tools/__init__.py:FULL"}, "tags": ["anton_repo"]}
{"id": "b0000276", "domain": "anton_repo", "section_path": ["server/agent/tools/code_stats.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Execute the codebase statistics functionality.\"\"\"\n        from server.agent.code_indexer import code_indexer\n\n        refresh = arguments.get('refresh', False)\n\n        try:\n            if refresh:\n                updated_files = code_indexer.refresh_index()\n                refresh_msg = f\"Refreshed code index: {updated_files} files updated.\"\n            else:\n                refresh_msg = \"Using existing code index.\"\n\n            stats = code_indexer.get_stats()\n\n            # Format file extension statistics\n            extension_stats = []\n            for ext, count in sorted(stats[\"file_extensions\"].items(), key=lambda x: x[1], reverse=True):\n                extension_stats.append(f\"  - {ext}: {count} files\")\n\n            response = [\n                           f\"📊 Codebase Statistics ({refresh_msg})\",\n                           f\"Total indexed files: {stats['total_files']}\",\n                           f\"Knowledge entries: {stats['knowledge_entries']}\",\n                           \"\\nFile types:\"\n                       ] + extension_stats\n\n            return \"\\n\".join(response)\n\n        except Exception as e:\n            return f\"❌ Error retrieving codebase statistics: {str(e)}\"", "source": {"file": "server/agent/tools/code_stats.py", "section": "server/agent/tools/code_stats.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000277", "domain": "anton_repo", "section_path": ["server/agent/tools/code_stats.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "\"\"\"\nTool for retrieving statistics about the agent's codebase.\n\"\"\"\n\n\nclass CodebaseStatsTool:\n    \"\"\"\n    A tool that provides statistics and information about the indexed codebase.\n    \"\"\"\n\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_codebase_stats\",\n            \"description\": \"Get statistics about the agent's indexed codebase.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"refresh\": {\n                        \"type\": \"boolean\",\n                        \"description\": \"Whether to refresh the code index before returning stats. Defaults to false.\"\n                    }\n                }\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/code_stats.py", "section": "server/agent/tools/code_stats.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000278", "domain": "anton_repo", "section_path": ["server/agent/tools/file_management.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def _resolve_path(user_path: str) -> str:\n    \"\"\"\n    Safely resolves a user-provided path against the project root.\n    Prevents path traversal attacks.\n    \"\"\"\n    # Treat all paths as relative to the project root.\n    # If a user provides an absolute path (e.g., \"/etc/passwd\"),\n    # os.path.join will correctly handle it if the base is absolute.\n    # However, for security, we explicitly join from our trusted root.\n\n    # Create the full path by joining the project root with the user-provided path.\n    # This automatically handles both relative ('data/file.txt') and \"absolute-like\" ('/data/file.txt') inputs safely.\n    combined_path = os.path.join(PROJECT_ROOT, user_path)\n\n    # Normalize the path to resolve '..' etc., and get the real, absolute path.\n    safe_path = os.path.realpath(combined_path)\n\n    # Security Check: Ensure the final, resolved path is still inside the PROJECT_ROOT.\n    if not safe_path.startswith(PROJECT_ROOT):\n        raise ValueError(f\"Path traversal attempt detected. Access denied for path: {user_path}\")\n\n    return safe_path\n\n\nclass WriteFileTool:\n    \"\"\"\n    A tool for writing content to a file within the project directory.\n    \"\"\"\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"write_file\",\n            \"description\": \"Writes content to a file relative to the project root. Creates parent directories and overwrites the file if it exists.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"file_path\": {\n                        \"type\": \"string\",\n                        \"description\": \"The path to the file, relative to the project root.\"\n                    },\n                    \"content\": {\n                        \"type\": \"string\",\n                        \"description\": \"The full content to write to the file.\"\n                    }\n                },\n                \"required\": [\"file_path\", \"content\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/file_management.py", "section": "server/agent/tools/file_management.py:def _resolve_path(user_path: str)"}, "tags": ["anton_repo"]}
{"id": "b0000279", "domain": "anton_repo", "section_path": ["server/agent/tools/file_management.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Executes the tool's logic.\"\"\"\n        file_path_arg = arguments.get('file_path')\n        content = arguments.get('content')\n\n        if not file_path_arg or content is None:\n            return \"❌ Error: Both 'file_path' and 'content' are required.\"\n\n        # Use the helper to get a safe, absolute path\n        safe_file_path = _resolve_path(file_path_arg)\n\n        dir_name = os.path.dirname(safe_file_path)\n        if dir_name:\n            os.makedirs(dir_name, exist_ok=True)\n\n        with open(safe_file_path, 'w', encoding='utf-8') as f:\n            f.write(content)\n\n        # Show the relative path in the success message for clarity\n        return f\"✅ Successfully wrote {len(content)} characters to '{file_path_arg}'.\"\n\n\nclass ReadFileTool:\n    \"\"\"\n    A tool for reading the content of a file from the project directory.\n    \"\"\"\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"read_file\",\n            \"description\": \"Reads the entire content of a specified file relative to the project root.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"file_path\": {\n                        \"type\": \"string\",\n                        \"description\": \"The path to the file to be read, relative to the project root.\"\n                    }\n                },\n                \"required\": [\"file_path\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/file_management.py", "section": "server/agent/tools/file_management.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000280", "domain": "anton_repo", "section_path": ["server/agent/tools/file_management.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Executes the tool's logic.\"\"\"\n        file_path_arg = arguments.get('file_path')\n\n        # Use the helper to get a safe, absolute path\n        safe_file_path = _resolve_path(file_path_arg)\n\n        if not os.path.exists(safe_file_path):\n            return f\"❌ Error: The file '{file_path_arg}' was not found.\"\n\n        with open(safe_file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n        \n        # Sanitize potentially problematic patterns that could be misinterpreted as tool calls\n        # Replace <tool_code> patterns with escaped versions to prevent false tool call detection\n        content = content.replace(\"<tool_code>\", \"&lt;tool_code&gt;\")\n        content = content.replace(\"</tool_code>\", \"&lt;/tool_code&gt;\")\n        content = content.replace(\"<tool_call>\", \"&lt;tool_call&gt;\")\n        content = content.replace(\"</tool_call>\", \"&lt;/tool_call&gt;\")\n        \n        return content\n\n\nclass ListDirectoryTool:\n    \"\"\"\n    A tool for listing the contents of a directory, ignoring files and folders\n    specified in the project's .gitignore file.\n    \"\"\"\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"list_directory\",\n            \"description\": \"Lists files and subdirectories within a given path, ignoring anything in .gitignore.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"path\": {\n                        \"type\": \"string\",\n                        \"description\": \"The path to the directory, relative to the project root. Defaults to '.' (the project root).\"\n                    },\n                    \"recursive\": {\n                        \"type\": \"boolean\",\n                        \"description\": \"Whether to list contents recursively. Defaults to True.\"\n                    }\n                }\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/file_management.py", "section": "server/agent/tools/file_management.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000281", "domain": "anton_repo", "section_path": ["server/agent/tools/file_management.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Executes the tool's logic, filtering results based on .gitignore.\"\"\"\n        path_arg = arguments.get('path', '.')\n        recursive = arguments.get('recursive', True)\n\n        # These are assumed to be defined elsewhere in your project\n        project_root = PROJECT_ROOT\n        safe_path = _resolve_path(path_arg)\n\n        if not os.path.isdir(safe_path):\n            return f\"❌ Error: The path '{path_arg}' is not a valid directory.\"\n\n        # Load .gitignore rules from the project root\n        spec = None\n        gitignore_path = os.path.join(project_root, '.gitignore')\n        if os.path.exists(gitignore_path):\n            with open(gitignore_path, 'r') as f:\n                spec = pathspec.PathSpec.from_lines('gitwildmatch', f)\n\n        display_path = path_arg if path_arg != '.' else 'project root'\n        output_message = f\"✅ Contents of '{display_path}' (respecting .gitignore):\\n\"\n\n        # --- Non-Recursive Listing ---\n        if not recursive:\n            entries = os.listdir(safe_path)\n            if spec:\n                relative_path = os.path.relpath(safe_path, project_root)\n                if relative_path == '.': relative_path = ''\n                entries = [\n                    e for e in entries\n                    if not spec.match_file(os.path.join(relative_path, e))\n                ]\n            return output_message + \"\\n\".join(sorted(entries))\n\n        # --- Recursive Listing ---\n        output_lines = []\n        has_content = False\n        for root, dirs, files in os.walk(safe_path, topdown=True):\n            # Filter directories and files using .gitignore spec\n            if spec:\n                relative_root = os.path.relpath(root, project_root)\n                if relative_root == '.': relative_root = ''\n\n                # Filter dirs IN-PLACE so os.walk doesn't traverse them\n                dirs[:] = [d for d in dirs if not spec.match_file(os.path.join(relative_root, d))]\n                files = [f for f in files if not spec.match_file(os.path.join(relative_root, f))]\n\n            # Don't bother printing empty directories\n            if not files and not dirs:\n                continue\n\n            has_content = True\n            dirs.sort()\n            files.sort()\n\n            level = root.replace(safe_path, '', 1).count(os.sep)\n            indent = ' ' * 4 * level\n\n            dir_name = os.path.basename(root)\n            if root == safe_path:\n                dir_name = display_path\n\n            output_lines.append(f\"{indent}📁 {dir_name}/\")\n\n            sub_indent = ' ' * 4 * (level + 1)\n            for f in files:\n                output_lines.append(f\"{sub_indent}📄 {f}\")\n\n        if not has_content and os.listdir(safe_path):\n            return f\"✅ All contents of '{display_path}' are ignored by .gitignore.\"\n\n        if not has_content:\n            return f\"✅ The directory '{display_path}' is empty.\"\n\n        return output_message + \"\\n\".join(output_lines)", "source": {"file": "server/agent/tools/file_management.py", "section": "server/agent/tools/file_management.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000282", "domain": "anton_repo", "section_path": ["server/agent/tools/file_management.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "import os\nimport json\n\nimport pathspec\n\n# --- START: Added for Project Root ---\n# Get the absolute path of the directory containing this script (server/tools)\nscript_dir = os.path.dirname(os.path.abspath(__file__))\n\n# Define the project root as two directories up from the script's location\nPROJECT_ROOT = os.path.abspath(os.path.join(script_dir, '..', '..', '..'))\n\n\n# --- END: Added for Project Root ---\n\n\n", "source": {"file": "server/agent/tools/file_management.py", "section": "server/agent/tools/file_management.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000283", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def find_git_root():\n    \"\"\"Finds the root directory of the Git repository.\"\"\"\n    try:\n        result = subprocess.run(\n            ['git', 'rev-parse', '--show-toplevel'],\n            capture_output=True, text=True, check=True, encoding='utf-8'\n        )\n        return result.stdout.strip()\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        return os.getcwd()\n\nGIT_ROOT_DIR = find_git_root()\n\n", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def find_git_root()"}, "tags": ["anton_repo"]}
{"id": "b0000284", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _run_command(command: list[str]) -> str:\n    \"\"\"A helper function to run shell commands from the Git root directory.\"\"\"\n    try:\n        result = subprocess.run(\n            command, capture_output=True, text=True, check=True,\n            encoding='utf-8', cwd=GIT_ROOT_DIR\n        )\n        output = result.stdout.strip()\n        return f\"✅ Success:\\n---\\n{output}\\n---\" if output else f\"✅ Command '{' '.join(command)}' executed successfully.\"\n    except FileNotFoundError as e:\n        return f\"❌ Error: Command not found: {e.filename}. Please ensure 'git' or 'gh' is installed and in the system's PATH.\"\n    except subprocess.CalledProcessError as e:\n        error_output = f\"Stderr:\\n---\\n{e.stderr.strip()}\"\n        if e.stdout.strip():\n            error_output += f\"\\nStdout:\\n---\\n{e.stdout.strip()}\"\n        return f\"❌ Error executing command: {' '.join(command)}\\nReturn Code: {e.returncode}\\n{error_output}\"\n    except Exception as e:\n        return f\"❌ An unexpected error occurred: {type(e).__name__}: {e}\"\n\n# --- Individual Tool Classes ---\n\nclass GitStatusTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"git_status\",\n            \"description\": \"Checks the status of the Git repository to see modified or staged files.\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {}} # Corrected for no parameters\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def _run_command(command: list[str])"}, "tags": ["anton_repo"]}
{"id": "b0000285", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        return _run_command([\"git\", \"status\"])\n\nclass GitCommitTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"git_commit\",\n            \"description\": \"Stages all modified files and commits them in a single step.\",\n            \"parameters\": { # Corrected to be a dictionary\n                \"type\": \"object\",\n                \"properties\": {\n                    \"message\": {\n                        \"type\": \"string\",\n                        \"description\": \"The commit message.\"\n                    },\n                    \"add_all\": {\n                        \"type\": \"boolean\",\n                        \"description\": \"If true, stages all changes (`git add .`) before committing. Defaults to true.\"\n                    }\n                },\n                \"required\": [\"message\"]\n            }\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000286", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        message = arguments.get('message')\n        if not message: return \"❌ Error: A commit message is required.\"\n        if arguments.get('add_all', True):\n            add_result = _run_command([\"git\", \"add\", \".\"])\n            if \"❌ Error\" in add_result: return f\"❌ Failed to stage files: {add_result}\"\n        return _run_command([\"git\", \"commit\", \"-m\", message, \"--no-verify\"])\n\nclass GitPushTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"git_push\",\n            \"description\": \"Pushes committed changes to a remote repository.\",\n            \"parameters\": { # Corrected to be a dictionary\n                \"type\": \"object\",\n                \"properties\": {\n                    \"branch\": {\"type\": \"string\", \"description\": \"The local branch to push.\"},\n                    \"remote\": {\"type\": \"string\", \"description\": \"The remote repository. Defaults to 'origin'.\"},\n                    \"set_upstream\": {\"type\": \"boolean\", \"description\": \"If true, sets the upstream branch. Defaults to false.\"}\n                },\n                \"required\": [\"branch\"]\n            }\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000287", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        branch = arguments.get('branch')\n        if not branch: return \"❌ Error: The 'branch' to push is required.\"\n        command = [\"git\", \"push\"]\n        if arguments.get('set_upstream'): command.append(\"--set-upstream\")\n        command.extend([arguments.get('remote', 'origin'), branch])\n        return _run_command(command)\n\nclass CreatePullRequestTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"create_pull_request\",\n            \"description\": \"Creates a pull request on GitHub using the 'gh' CLI.\",\n            \"parameters\": { # Corrected to be a dictionary\n                \"type\": \"object\",\n                \"properties\": {\n                    \"title\": {\"type\": \"string\", \"description\": \"The title of the pull request.\"},\n                    \"body\": {\"type\": \"string\", \"description\": \"The body content of the pull request.\"},\n                    \"head\": {\"type\": \"string\", \"description\": \"The branch to merge from (e.g., 'feature-branch').\"},\n                    \"base\": {\"type\": \"string\", \"description\": \"The branch to merge into. Defaults to 'main'.\"}\n                },\n                \"required\": [\"title\", \"body\", \"head\"]\n            }\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000288", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        title, body, head = arguments.get('title'), arguments.get('body'), arguments.get('head')\n        if not all([title, body, head]): return \"❌ Error: 'title', 'body', and 'head' are required.\"\n        return _run_command([\"gh\", \"pr\", \"create\", \"--title\", title, \"--body\", body, \"--head\", head, \"--base\", arguments.get('base', 'main')])\n\nclass GitCreateBranchTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"git_create_branch\",\n            \"description\": \"Creates a new branch in the Git repository.\",\n            \"parameters\": { # Corrected to be a dictionary\n                \"type\": \"object\",\n                \"properties\": {\n                    \"branch_name\": {\"type\": \"string\", \"description\": \"The name of the branch to create.\"}\n                },\n                \"required\": [\"branch_name\"]\n            }\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000289", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        branch_name = arguments.get('branch_name')\n        if not branch_name: return \"❌ Error: 'branch_name' is required.\"\n        return _run_command([\"git\", \"branch\", branch_name])\n\nclass GitSwitchBranchTool:\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"git_switch_branch\",\n            \"description\": \"Switches to a different, existing branch.\",\n            \"parameters\": { # Corrected to be a dictionary\n                \"type\": \"object\",\n                \"properties\": {\n                    \"branch_name\": {\"type\": \"string\", \"description\": \"The name of the branch to switch to.\"}\n                },\n                \"required\": [\"branch_name\"]\n            }\n        }\n    }\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000290", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        branch_name = arguments.get('branch_name')\n        if not branch_name: return \"❌ Error: 'branch_name' is required.\"\n        return _run_command([\"git\", \"checkout\", branch_name])\n\n# --- Main Skill Class to Access All Tools ---\nclass GitManagementSkill:\n    \"\"\"A skill that provides a suite of tools for Git version control.\"\"\"\n    ", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000291", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def get_tools(self) -> list:\n        \"\"\"Returns a list of all available Git tool instances.\"\"\"\n        return [\n            GitStatusTool(), GitCommitTool(), GitPushTool(),\n            CreatePullRequestTool(), GitCreateBranchTool(), GitSwitchBranchTool()\n        ]", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:def get_tools(self)"}, "tags": ["anton_repo"]}
{"id": "b0000292", "domain": "anton_repo", "section_path": ["server/agent/tools/git.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "import os\nimport subprocess\n\n", "source": {"file": "server/agent/tools/git.py", "section": "server/agent/tools/git.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000293", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_defs.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def get_all_tools() -> List[Any]:\n    \"\"\"\n    Dynamically discover and return all available tools.\n    \n    Returns:\n        List of all tool instances (both new and legacy)\n    \"\"\"\n    all_tools = []\n    \n    # Get legacy tools wrapped for compatibility\n    legacy_tools = create_legacy_tool_wrappers()\n    all_tools.extend(legacy_tools.values())\n    \n    # Discover any new tools that inherit from BaseTool\n    tool_loader = ToolLoader()\n    discovered_tools = tool_loader.create_tool_instances()\n    \n    # Filter out legacy tools we've already wrapped\n    legacy_tool_names = set(legacy_tools.keys())\n    for name, tool in discovered_tools.items():\n        if name not in legacy_tool_names:\n            all_tools.append(tool)\n    \n    return all_tools\n\n\n", "source": {"file": "server/agent/tools/tool_defs.py", "section": "server/agent/tools/tool_defs.py:def get_all_tools()"}, "tags": ["anton_repo"]}
{"id": "b0000294", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_defs.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def get_tools_by_pattern(pattern: str) -> List[Any]:\n    \"\"\"\n    Get tools matching a specific pattern or type.\n    \n    Args:\n        pattern: Pattern to match against tool names or capabilities\n        \n    Returns:\n        List of matching tool instances\n    \"\"\"\n    all_tools = get_all_tools()\n    matching_tools = []\n    \n    for tool in all_tools:\n        tool_name = getattr(tool, 'metadata', {}).get('name', 'unknown')\n        if pattern.lower() in tool_name.lower():\n            matching_tools.append(tool)\n    \n    return matching_tools\n\n\n", "source": {"file": "server/agent/tools/tool_defs.py", "section": "server/agent/tools/tool_defs.py:def get_tools_by_pattern(pattern: str)"}, "tags": ["anton_repo"]}
{"id": "b0000295", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_defs.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def reload_tools() -> List[Any]:\n    \"\"\"\n    Force reload of all tools from the filesystem.\n    \n    Returns:\n        Refreshed list of all tool instances\n    \"\"\"\n    # Clear any cached imports\n    import importlib\n    from server.agent.tools import tool_loader, legacy_wrapper\n    \n    try:\n        importlib.reload(tool_loader)\n        importlib.reload(legacy_wrapper)\n    except:\n        pass  # Ignore reload errors\n    \n    return get_all_tools()\n\n\n# For backward compatibility, provide the STATIC_TOOLS array\n# but now it's dynamically generated\nSTATIC_TOOLS = get_all_tools()\n\n\n# Print discovery information\nif __name__ == \"__main__\":\n    tools = get_all_tools()\n    print(f\"🔍 Discovered {len(tools)} tools:\")\n    for tool in tools:\n        if hasattr(tool, 'metadata'):\n            print(f\"  - {tool.metadata.name} v{tool.metadata.version}\")\n        else:\n            print(f\"  - {tool.__class__.__name__} (legacy)\")\n", "source": {"file": "server/agent/tools/tool_defs.py", "section": "server/agent/tools/tool_defs.py:def reload_tools()"}, "tags": ["anton_repo"]}
{"id": "b0000296", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_defs.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "\"\"\"\nDynamic tool definitions that automatically discover and load tools.\nReplaces the hardcoded STATIC_TOOLS array with intelligent discovery.\n\"\"\"\n\nfrom typing import List, Any\nfrom server.agent.tools.legacy_wrapper import create_legacy_tool_wrappers\nfrom server.agent.tools.tool_loader import ToolLoader\n\n\n", "source": {"file": "server/agent/tools/tool_defs.py", "section": "server/agent/tools/tool_defs.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000297", "domain": "anton_repo", "section_path": ["server/agent/tools/learning_tools.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Returns metrics about the agent's learning and performance.\"\"\"\n        from server.agent.learning_loop import learning_loop\n\n        report = learning_loop.get_performance_report()\n\n        if \"error\" in report:\n            return f\"No learning metrics available yet. The agent needs to complete more tasks to generate performance data.\"\n\n        output = [\n            \"📈 Learning Progress Report:\",\n            f\"Total tasks completed: {report['total_tasks']}\",\n            f\"Recent success rate: {report['recent_success_rate'] * 100:.1f}%\",\n            f\"Knowledge entries: {report['learnings_count']}\"\n        ]\n\n        if report.get('improvement_trends'):\n            output.append(\"\\nImprovement Trends:\")\n            for metric, value in report['improvement_trends'].items():\n                trend = \"improved\" if value > 0 else \"declined\"\n                output.append(f\"- {metric}: {trend} by {abs(value):.2f}\")\n\n        return \"\\n\".join(output)", "source": {"file": "server/agent/tools/learning_tools.py", "section": "server/agent/tools/learning_tools.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000298", "domain": "anton_repo", "section_path": ["server/agent/tools/learning_tools.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "class LearningProgressTool:\n    \"\"\"A tool for checking the agent's learning progress and performance metrics.\"\"\"\n\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"check_learning_progress\",\n            \"description\": \"Returns metrics about the agent's learning progress and performance improvements over time.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {}  # No parameters needed\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/learning_tools.py", "section": "server/agent/tools/learning_tools.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000299", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def resolve_conflicts(tools: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Resolve naming conflicts between tools.\n        \n        Args:\n            tools: Dictionary of tool name to tool instance\n            \n        Returns:\n            Dictionary with resolved tool names\n        \"\"\"\n        # Group tools by base name (without version)\n        grouped_tools = defaultdict(list)\n        for name, tool in tools.items():\n            base_name = ToolConflictResolver._get_base_name(name)\n            grouped_tools[base_name].append((name, tool))\n        \n        resolved_tools = {}\n        \n        for base_name, tool_list in grouped_tools.items():\n            if len(tool_list) == 1:\n                # No conflict, use original name\n                name, tool = tool_list[0]\n                resolved_tools[base_name] = tool\n            else:\n                # Conflict detected, resolve by version\n                resolved = ToolConflictResolver._resolve_version_conflict(tool_list)\n                resolved_tools.update(resolved)\n        \n        return resolved_tools\n    \n    @staticmethod\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def resolve_conflicts(tools: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000300", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "def _get_base_name(tool_name: str) -> str:\n        \"\"\"Extract base name from versioned tool name.\"\"\"\n        # Remove version suffix if present (e.g., \"tool_v1_2_0\" -> \"tool\")\n        return re.sub(r'_v\\d+(_\\d+)*$', '', tool_name)\n    \n    @staticmethod\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def _get_base_name(tool_name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000301", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 3, "block_index": 1, "block_type": "code", "text": "def _resolve_version_conflict(tool_list: List[tuple]) -> Dict[str, Any]:\n        \"\"\"\n        Resolve conflicts between multiple versions of the same tool.\n        Keeps the highest version and adds versioned names for others.\n        \"\"\"\n        resolved = {}\n        \n        # Sort by version (newest first)\n        versioned_tools = []\n        legacy_tools = []\n        \n        for name, tool in tool_list:\n            if isinstance(tool, BaseTool):\n                versioned_tools.append((name, tool))\n            else:\n                legacy_tools.append((name, tool))\n        \n        # Sort versioned tools by version\n        versioned_tools.sort(key=lambda x: x[1].metadata.version, reverse=True)\n        \n        # Add the highest version with base name\n        if versioned_tools:\n            base_name = ToolConflictResolver._get_base_name(versioned_tools[0][0])\n            resolved[base_name] = versioned_tools[0][1]\n            \n            # Add other versions with explicit version names\n            for name, tool in versioned_tools[1:]:\n                resolved[tool.get_full_name()] = tool\n        \n        # Add legacy tools with their original names\n        for name, tool in legacy_tools:\n            resolved[name] = tool\n        \n        return resolved\n\n\nclass ToolManager:\n    \"\"\"\n    Enhanced tool manager with dynamic discovery, versioning, and conflict resolution.\n    \"\"\"\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def _resolve_version_conflict(tool_list: List[tuple])"}, "tags": ["anton_repo"]}
{"id": "b0000302", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 4, "block_index": 1, "block_type": "code", "text": "def __init__(self, auto_discover: bool = True):\n        \"\"\"\n        Initialize the tool manager.\n        \n        Args:\n            auto_discover: Whether to automatically discover tools on initialization\n        \"\"\"\n        self.tools: Dict[str, Any] = {}\n        self.tool_loader = ToolLoader()\n        self._metadata_cache: Dict[str, Dict[str, Any]] = {}\n        \n        print(\"✅ Enhanced ToolManager initialized.\")\n        \n        if auto_discover:\n            self.discover_and_register_tools()\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def __init__(self, auto_discover: bool = True)"}, "tags": ["anton_repo"]}
{"id": "b0000303", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 5, "block_index": 1, "block_type": "code", "text": "def discover_and_register_tools(self):\n        \"\"\"Discover and register all available tools.\"\"\"\n        print(\"🔍 Discovering tools...\")\n        \n        # Get all tool instances\n        discovered_tools = self.tool_loader.create_tool_instances()\n        \n        # Resolve conflicts\n        resolved_tools = ToolConflictResolver.resolve_conflicts(discovered_tools)\n        \n        # Register all resolved tools\n        for name, tool in resolved_tools.items():\n            self._register_tool(name, tool)\n        \n        print(f\"✅ Tool discovery complete. {len(self.tools)} tools registered.\")\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def discover_and_register_tools(self)"}, "tags": ["anton_repo"]}
{"id": "b0000304", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 6, "block_index": 1, "block_type": "code", "text": "def register(self, tool_instance: Any, name: Optional[str] = None):\n        \"\"\"\n        Register a single tool instance.\n        \n        Args:\n            tool_instance: The tool instance to register\n            name: Optional custom name for the tool\n        \"\"\"\n        if name is None:\n            name = self._extract_tool_name(tool_instance)\n        \n        self._register_tool(name, tool_instance)\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def register(self, tool_instance: Any, name: Optional[str] = None)"}, "tags": ["anton_repo"]}
{"id": "b0000305", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 7, "block_index": 1, "block_type": "code", "text": "def _register_tool(self, name: str, tool_instance: Any):\n        \"\"\"Internal method to register a tool with the given name.\"\"\"\n        # Check for conflicts\n        if name in self.tools:\n            existing_tool = self.tools[name]\n            if isinstance(tool_instance, BaseTool) and isinstance(existing_tool, BaseTool):\n                # Compare versions\n                if tool_instance.metadata.version > existing_tool.metadata.version:\n                    print(f\"🔄 Upgrading tool '{name}' from v{existing_tool.metadata.version} to v{tool_instance.metadata.version}\")\n                else:\n                    print(f\"⚠️  Skipping '{name}' v{tool_instance.metadata.version} (current: v{existing_tool.metadata.version})\")\n                    return\n        \n        self.tools[name] = tool_instance\n        self._cache_tool_metadata(name, tool_instance)\n        print(f\"🔧 Tool '{name}' registered.\")\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def _register_tool(self, name: str, tool_instance: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000306", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 8, "block_index": 1, "block_type": "code", "text": "def _extract_tool_name(self, tool_instance: Any) -> str:\n        \"\"\"Extract the name from a tool instance.\"\"\"\n        if isinstance(tool_instance, BaseTool):\n            return tool_instance.metadata.name\n        \n        # Legacy tool extraction\n        if hasattr(tool_instance, 'function'):\n            function_schema = tool_instance.function\n            if isinstance(function_schema, dict):\n                return function_schema.get(\"function\", {}).get(\"name\", \"unknown_tool\")\n        \n        return tool_instance.__class__.__name__.lower()\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def _extract_tool_name(self, tool_instance: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000307", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 9, "block_index": 1, "block_type": "code", "text": "def _cache_tool_metadata(self, name: str, tool_instance: Any):\n        \"\"\"Cache metadata for faster retrieval.\"\"\"\n        metadata = {}\n        \n        if isinstance(tool_instance, BaseTool):\n            metadata = {\n                \"name\": tool_instance.metadata.name,\n                \"version\": tool_instance.metadata.version,\n                \"description\": tool_instance.metadata.description,\n                \"capabilities\": [cap.value for cap in tool_instance.metadata.capabilities],\n                \"author\": tool_instance.metadata.author,\n                \"dependencies\": tool_instance.metadata.dependencies,\n                \"tags\": tool_instance.metadata.tags\n            }\n        else:\n            # Legacy tool metadata\n            if hasattr(tool_instance, 'function'):\n                function_schema = tool_instance.function\n                if isinstance(function_schema, dict):\n                    metadata = {\n                        \"name\": function_schema.get(\"function\", {}).get(\"name\", name),\n                        \"description\": function_schema.get(\"function\", {}).get(\"description\", \"\"),\n                        \"version\": \"legacy\",\n                        \"capabilities\": [],\n                        \"legacy\": True\n                    }\n        \n        self._metadata_cache[name] = metadata\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def _cache_tool_metadata(self, name: str, tool_instance: Any)"}, "tags": ["anton_repo"]}
{"id": "b0000308", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 10, "block_index": 1, "block_type": "code", "text": "def get_tool_schemas(self) -> List[Dict[str, Any]]:\n        \"\"\"Returns the JSON schemas of all registered tools.\"\"\"\n        return [tool.function for tool in self.tools.values()]\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_tool_schemas(self)"}, "tags": ["anton_repo"]}
{"id": "b0000309", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 11, "block_index": 1, "block_type": "code", "text": "def get_tools_by_capability(self, capability: ToolCapability) -> List[str]:\n        \"\"\"\n        Get tool names that have a specific capability.\n        \n        Args:\n            capability: The capability to filter by\n            \n        Returns:\n            List of tool names with the specified capability\n        \"\"\"\n        matching_tools = []\n        \n        for name, metadata in self._metadata_cache.items():\n            if capability.value in metadata.get(\"capabilities\", []):\n                matching_tools.append(name)\n        \n        return matching_tools\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_tools_by_capability(self, capability: ToolCapability)"}, "tags": ["anton_repo"]}
{"id": "b0000310", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 12, "block_index": 1, "block_type": "code", "text": "def get_tool_metadata(self, tool_name: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get metadata for a specific tool.\n        \n        Args:\n            tool_name: Name of the tool\n            \n        Returns:\n            Tool metadata dictionary or None if not found\n        \"\"\"\n        return self._metadata_cache.get(tool_name)\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_tool_metadata(self, tool_name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000311", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 13, "block_index": 1, "block_type": "code", "text": "def get_all_metadata(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Get metadata for all registered tools.\"\"\"\n        return self._metadata_cache.copy()\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_all_metadata(self)"}, "tags": ["anton_repo"]}
{"id": "b0000312", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 14, "block_index": 1, "block_type": "code", "text": "def run_tool(self, tool_name: str, tool_args: Dict[str, Any]) -> str:\n        \"\"\"\n        Find a tool in the registry and execute it with the given arguments.\n        \n        Args:\n            tool_name: Name of the tool to execute\n            tool_args: Arguments to pass to the tool\n            \n        Returns:\n            String result of the tool execution\n        \"\"\"\n        if tool_name not in self.tools:\n            # Try to find a close match\n            similar_tools = [name for name in self.tools.keys() if tool_name.lower() in name.lower()]\n            if similar_tools:\n                suggestion = f\" Did you mean: {', '.join(similar_tools[:3])}?\"\n            else:\n                suggestion = f\" Available tools: {', '.join(list(self.tools.keys())[:5])}\"\n            return f\"❌ Error: Tool '{tool_name}' not found.{suggestion}\"\n\n        tool_instance = self.tools[tool_name]\n        \n        # Validate arguments if possible\n        if isinstance(tool_instance, BaseTool):\n            if not tool_instance.validate_arguments(tool_args):\n                return f\"❌ Error: Invalid arguments for tool '{tool_name}'\"\n        \n        try:\n            return tool_instance.run(tool_args)\n        except Exception as e:\n            return f\"❌ Error executing tool '{tool_name}': {str(e)}\"\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def run_tool(self, tool_name: str, tool_args: Dict[str, Any])"}, "tags": ["anton_repo"]}
{"id": "b0000313", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 15, "block_index": 1, "block_type": "code", "text": "def reload_tools(self):\n        \"\"\"Reload all tools from the filesystem.\"\"\"\n        print(\"🔄 Reloading tools...\")\n        self.tools.clear()\n        self._metadata_cache.clear()\n        self.discover_and_register_tools()\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def reload_tools(self)"}, "tags": ["anton_repo"]}
{"id": "b0000314", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 16, "block_index": 1, "block_type": "code", "text": "def get_tool_count(self) -> int:\n        \"\"\"Get the number of registered tools.\"\"\"\n        return len(self.tools)\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_tool_count(self)"}, "tags": ["anton_repo"]}
{"id": "b0000315", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 17, "block_index": 1, "block_type": "code", "text": "def get_tool_names(self) -> List[str]:\n        \"\"\"Get a list of all registered tool names.\"\"\"\n        return list(self.tools.keys())\n\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def get_tool_names(self)"}, "tags": ["anton_repo"]}
{"id": "b0000316", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 18, "block_index": 1, "block_type": "code", "text": "def has_tool(self, tool_name: str) -> bool:\n        \"\"\"Check if a tool is registered.\"\"\"\n        return tool_name in self.tools\n\n\n# Create a single, global instance that the entire application will share.\ntool_manager = ToolManager()", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:def has_tool(self, tool_name: str)"}, "tags": ["anton_repo"]}
{"id": "b0000317", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_manager.py"], "page": 19, "block_index": 1, "block_type": "code", "text": "# tools/tool_manager.py\n\nfrom typing import Dict, Any, List, Optional\nfrom collections import defaultdict\nimport re\n\nfrom server.agent.tools.base_tool import BaseTool, ToolCapability\nfrom server.agent.tools.tool_loader import ToolLoader\n\n\nclass ToolConflictResolver:\n    \"\"\"Handles conflicts when multiple tools have the same name.\"\"\"\n    \n    @staticmethod\n    ", "source": {"file": "server/agent/tools/tool_manager.py", "section": "server/agent/tools/tool_manager.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000318", "domain": "anton_repo", "section_path": ["server/agent/tools/coding.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"\n        Executes the tool's logic.\n        `arguments` is a dictionary containing the code to run.\n        \"\"\"\n        try:\n            print(f\"Executing tool 'execute_python_code' with arguments: {arguments}\")\n            code = arguments.get('code')\n            if not code:\n                return \"❌ Error: No code provided to execute.\"\n\n            client = docker.from_env()\n            # Use shlex.quote for robust shell escaping\n            escaped_code = shlex.quote(code.strip())\n            command = f'python -c {escaped_code}'\n\n            container_output = client.containers.run(\n                image=\"python:3.11-slim\",\n                command=command,\n                remove=True,\n                stderr=True,\n                stdout=True,\n                detach=False\n            )\n\n            result = container_output.decode('utf-8').strip()\n            return f\"✅ Code executed successfully:\\n---\\n{result}\\n---\" if result else \"✅ Code executed successfully with no output.\"\n\n        except docker.errors.ContainerError as e:\n            error_output = e.stderr.decode('utf-8') if e.stderr else str(e)\n            return f\"❌ An error occurred during code execution:\\n```\\n{error_output.strip()}\\n```\"\n        except docker.errors.APIError as e:\n            # This can happen if the Docker daemon isn't running\n            return f\"❌ An error occurred with the Docker API: {e}. Is the Docker daemon running?\"\n        except Exception as e:\n            return f\"❌ An unexpected error occurred: {type(e).__name__}: {str(e)}\"", "source": {"file": "server/agent/tools/coding.py", "section": "server/agent/tools/coding.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000319", "domain": "anton_repo", "section_path": ["server/agent/tools/coding.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "import docker\nimport shlex\nimport json\n\nclass ExecutePythonCode:\n    \"\"\"\n    A tool for executing Python code in a secure Docker container.\n    \"\"\"\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"execute_python_code\",\n            \"description\": (\n                \"Executes a string of Python code in a secure Docker container and returns the output. \"\n                \"IMPORTANT: This tool cannot save files or interact with the local file system. \"\n                \"It is solely for running code and getting the results back.\"\n            ),\n            # CORRECTED: 'parameters' is now a dictionary\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"code\": {\n                        \"type\": \"string\",\n                        \"description\": \"The raw Python code to be executed.\"\n                    }\n                },\n                \"required\": [\"code\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/coding.py", "section": "server/agent/tools/coding.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000320", "domain": "anton_repo", "section_path": ["server/agent/tools/code_search.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Execute the code search functionality.\"\"\"\n        from server.agent.rag_manager import rag_manager\n\n        query = arguments.get('query')\n        if not query:\n            return \"❌ Error: A search query is required.\"\n\n        max_results = arguments.get('max_results', 3)\n\n        try:\n            # Search the knowledge base for relevant code snippets\n            results = rag_manager.retrieve_knowledge(query=query, top_k=max_results)\n\n            if not results:\n                return \"No relevant code found in the codebase for your query.\"\n\n            # Format the results\n            response = [\"Here are the relevant code snippets:\"]\n\n            for i, result in enumerate(results, 1):\n                source = result.get(\"source\", \"Unknown source\")\n                text = result.get(\"text\", \"\").strip()\n\n                # Limit very long snippets\n                if len(text) > 1500:\n                    text = text[:1500] + \"...\\n[truncated for brevity]\"\n\n                response.append(f\"\\n## Snippet {i}: {source}\")\n                response.append(f\"```python\\n{text}\\n```\")\n\n            return \"\\n\".join(response)\n\n        except Exception as e:\n            return f\"❌ Error searching codebase: {str(e)}\"", "source": {"file": "server/agent/tools/code_search.py", "section": "server/agent/tools/code_search.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000321", "domain": "anton_repo", "section_path": ["server/agent/tools/code_search.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "\"\"\"\nTool for searching and understanding the agent's own code.\n\"\"\"\n\n\nclass CodeSearchTool:\n    \"\"\"\n    A tool that allows the agent to search through its own codebase.\n    \"\"\"\n\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"search_codebase\",\n            \"description\": \"Search through the agent's codebase for relevant files or code snippets.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"The search query related to code structure, functionality, or implementation details.\"\n                    },\n                    \"max_results\": {\n                        \"type\": \"integer\",\n                        \"description\": \"Maximum number of code snippets to return. Defaults to 3.\"\n                    }\n                },\n                \"required\": [\"query\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/code_search.py", "section": "server/agent/tools/code_search.py:IMPORTS"}, "tags": ["anton_repo"]}
{"id": "b0000322", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_creation/tool_creator.py"], "page": 1, "block_index": 1, "block_type": "code", "text": "def run(self, arguments: dict) -> str:\n        \"\"\"Saves code, dynamically loads the new tool, and registers it.\"\"\"\n        tool_name = arguments.get('tool_name')\n        tool_code = arguments.get('tool_code')\n\n        if not tool_name or not tool_code:\n            return \"❌ Error: 'tool_name' and 'tool_code' are required.\"\n\n        try:\n            sanitized_name = re.sub(r'[^a-zA-Z0-9_]', '', tool_name)\n            # We'll create a dedicated directory for custom tools\n            tools_dir = \"tools\"\n            os.makedirs(tools_dir, exist_ok=True)\n\n            # Add an __init__.py to make it a package\n            init_path = os.path.join(tools_dir, \"__init__.py\")\n            if not os.path.exists(init_path):\n                open(init_path, 'a').close()\n\n            file_path = os.path.join(tools_dir, f\"{sanitized_name}.py\")\n\n            with open(file_path, \"w\", encoding='utf-8') as f:\n                f.write(tool_code)\n\n            # Dynamically load the new module\n            module_name = f\"{tools_dir}.{sanitized_name}\"\n            spec = importlib.util.spec_from_file_location(module_name, file_path)\n            module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(module)\n\n            # Find the class inside the loaded module and register it\n            for name, obj in inspect.getmembers(module, inspect.isclass):\n                if obj.__module__ == module_name:\n                    new_tool_instance = obj()\n                    tool_manager.register(new_tool_instance)  # <-- THE FIX\n                    return f\"✅ Success: Tool '{sanitized_name}' created and loaded. It is now available.\"\n\n            return \"❌ Error: Could not find a class to load in the provided tool code.\"\n        except Exception as e:\n            return f\"❌ An unexpected error occurred: {str(e)}\"", "source": {"file": "server/agent/tools/tool_creation/tool_creator.py", "section": "server/agent/tools/tool_creation/tool_creator.py:def run(self, arguments: dict)"}, "tags": ["anton_repo"]}
{"id": "b0000323", "domain": "anton_repo", "section_path": ["server/agent/tools/tool_creation/tool_creator.py"], "page": 2, "block_index": 1, "block_type": "code", "text": "# tools/tool_creation/tool_creator.py\n\nimport os\nimport re\nimport importlib.util\nimport inspect\nfrom server.agent.tools.tool_manager import tool_manager  # <-- IMPORT THE MANAGER\n\n\nclass ToolCreator:\n    \"\"\"\n    A tool for creating new, usable tools. It writes the code to a file\n    and registers the new tool with the central ToolManager.\n    \"\"\"\n    function = {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"create_new_tool\",\n            \"description\": (\n                \"Writes the Python code for a new tool to a file and makes it \"\n                \"immediately available for use in subsequent steps.\"\n            ),\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"tool_name\": {\n                        \"type\": \"string\",\n                        \"description\": \"The snake_case name for the new tool's file (e.g., 'file_writer').\"\n                    },\n                    \"tool_code\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string containing the entire Python code for the new tool's class.\"\n                    }\n                },\n                \"required\": [\"tool_name\", \"tool_code\"]\n            }\n        }\n    }\n\n    ", "source": {"file": "server/agent/tools/tool_creation/tool_creator.py", "section": "server/agent/tools/tool_creation/tool_creator.py:IMPORTS"}, "tags": ["anton_repo"]}
