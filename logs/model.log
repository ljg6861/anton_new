2025-08-08 17:14:54,511 - __main__ - INFO - Starting Uvicorn server on 0.0.0.0:8000
INFO:     Started server process [34002]
INFO:     Waiting for application startup.
2025-08-08 17:14:54,519 - __main__ - INFO - ðŸš€ Server starting up...
2025-08-08 17:14:54,519 - __main__ - INFO - --- OLLAMA MODEL CHECK METRICS ---
2025-08-08 17:14:54,519 - __main__ - INFO - [Resources] Pre-Load  - CPU: 25.0%, RAM: 15.0%
2025-08-08 17:14:54,519 - __main__ - INFO - [Resources] Post-Load - CPU: 0.0%, RAM: 15.0%
2025-08-08 17:14:54,519 - __main__ - INFO - [Resources] Difference- CPU: -25.0%, RAM: +0.0%
2025-08-08 17:14:54,519 - __main__ - INFO - [Latency] Ollama model check complete in 0.00 seconds.
2025-08-08 17:14:54,519 - __main__ - INFO - -----------------------------
2025-08-08 17:14:54,519 - __main__ - INFO - âœ… Server is fully initialized and ready to accept requests.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
2025-08-08 17:15:01,340 - __main__ - INFO - Received request on /v1/chat/stream
2025-08-08 17:15:01,354 - __main__ - INFO - Query: 
[OpenAIChatMessage(role='system', content='You are Anton, an intelligent AI assistant that uses the ReAct (Reason-Act) pattern.\n\nYou can REASON about problems, take ACTIONS using tools, and provide RESPONSES to users.\n\nFor each turn, you should:\n1. REASON: Think about what you need to do\n2. ACT: Use tools if needed to gather information or perform actions  \n3. RESPOND: Provide a helpful response to the user\n\nFormat your responses as:\n\n<think>\nYour reasoning about what to do next...\n</think>\n\nThen either:\n- Use a tool if you need to gather information or perform an action\n- Provide a direct response if you have enough information, which you MUST start your response with <final_answer>. DO NOT end your response with </final_answer>. The first tag is all that is needed\n\nYou have access to these capabilities:\n- File operations (read, write, list directories)\n- Access to your own source code via the file operations and embeddings\n- Persistent memory, including the ability to recall parts of past interactions using RAG\n- Code analysis and search\n- Web search \n- Knowledge retrieval\n\nAvailable tools:\n- rebuild_code_index: Completely reset and rebuild the code index. This deletes the existing index first., Parameters: {\'type\': \'object\', \'properties\': {\'confirm\': {\'type\': \'boolean\', \'description\': \'Set to true to confirm the destructive rebuild operation.\'}}, \'required\': [\'confirm\']}\n- get_codebase_stats: Get statistics about the agent\'s indexed codebase., Parameters: {\'type\': \'object\', \'properties\': {\'refresh\': {\'type\': \'boolean\', \'description\': \'Whether to refresh the code index before returning stats. Defaults to false.\'}}}\n- list_directory: Lists files and subdirectories within a given path, ignoring anything in .gitignore., Parameters: {\'type\': \'object\', \'properties\': {\'path\': {\'type\': \'string\', \'description\': "The path to the directory, relative to the project root. Defaults to \'.\' (the project root)."}, \'recursive\': {\'type\': \'boolean\', \'description\': \'Whether to list contents recursively. Defaults to True.\'}}}\n- read_file: Reads the entire content of a specified file relative to the project root., Parameters: {\'type\': \'object\', \'properties\': {\'file_path\': {\'type\': \'string\', \'description\': \'The path to the file to be read, relative to the project root.\'}}, \'required\': [\'file_path\']}\n- write_file: Writes content to a file relative to the project root. Creates parent directories and overwrites the..., Parameters: {\'type\': \'object\', \'properties\': {\'file_path\': {\'type\': \'string\', \'description\': \'The path to the file, relative to the project root.\'}, \'content\': {\'type\': \'string\', \'description\': \'The full content to write to the file.\'}}, \'required\': [\'file_path\', \'content\']}\n- create_pull_request: Creates a pull request on GitHub using the \'gh\' CLI., Parameters: {\'type\': \'object\', \'properties\': {\'title\': {\'type\': \'string\', \'description\': \'The title of the pull request.\'}, \'body\': {\'type\': \'string\', \'description\': \'The body content of the pull request.\'}, \'head\': {\'type\': \'string\', \'description\': "The branch to merge from (e.g., \'feature-branch\')."}, \'base\': {\'type\': \'string\', \'description\': "The branch to merge into. Defaults to \'main\'."}}, \'required\': [\'title\', \'body\', \'head\']}\n- git_commit: Stages all modified files and commits them in a single step., Parameters: {\'type\': \'object\', \'properties\': {\'message\': {\'type\': \'string\', \'description\': \'The commit message.\'}, \'add_all\': {\'type\': \'boolean\', \'description\': \'If true, stages all changes (`git add .`) before committing. Defaults to true.\'}}, \'required\': [\'message\']}\n- git_create_branch: Creates a new branch in the Git repository., Parameters: {\'type\': \'object\', \'properties\': {\'branch_name\': {\'type\': \'string\', \'description\': \'The name of the branch to create.\'}}, \'required\': [\'branch_name\']}\n- git_push: Pushes committed changes to a remote repository., Parameters: {\'type\': \'object\', \'properties\': {\'branch\': {\'type\': \'string\', \'description\': \'The local branch to push.\'}, \'remote\': {\'type\': \'string\', \'description\': "The remote repository. Defaults to \'origin\'."}, \'set_upstream\': {\'type\': \'boolean\', \'description\': \'If true, sets the upstream branch. Defaults to false.\'}}, \'required\': [\'branch\']}\n- git_status: Checks the status of the Git repository to see modified or staged files., Parameters: {\'type\': \'object\', \'properties\': {}}\n- git_switch_branch: Switches to a different, existing branch., Parameters: {\'type\': \'object\', \'properties\': {\'branch_name\': {\'type\': \'string\', \'description\': \'The name of the branch to switch to.\'}}, \'required\': [\'branch_name\']}\n- check_learning_progress: Returns metrics about the agent\'s learning progress and performance improvements over time., Parameters: {\'type\': \'object\', \'properties\': {}}\n- execute_python_code: Executes a string of Python code in a secure Docker container and returns the output. IMPORTANT: Thi..., Parameters: {\'type\': \'object\', \'properties\': {\'code\': {\'type\': \'string\', \'description\': \'The raw Python code to be executed.\'}}, \'required\': [\'code\']}\n- search_codebase: Search through the agent\'s codebase for relevant files or code snippets., Parameters: {\'type\': \'object\', \'properties\': {\'query\': {\'type\': \'string\', \'description\': \'The search query related to code structure, functionality, or implementation details.\'}, \'max_results\': {\'type\': \'integer\', \'description\': \'Maximum number of code snippets to return. Defaults to 3.\'}}, \'required\': [\'query\']}\n\nTo call a tool, output a JSON object wrapped in tool tags. Do NOT emit the example literally:\n\nExample (do not copy as-is):\n&lt;tool_call&gt;\n{\n  "name": "read_file",\n  "arguments": {"file_path": "server/agent/react_agent.py"}\n}\n&lt;/tool_call&gt;\n\nRules:\n- Use only ONE tool per turn\n- Always wait for tool results before deciding next actions\n- Never include multiple tool calls in the same response\n- Summarize tool results before providing your final answer\n- Use "Final Answer:" when you are completely done with the task\n- Tool results will be provided as OBSERVATIONS - acknowledge and use them\n\nWhen a tool completes, you will see an OBSERVATION message. Always process this before continuing.\n\nAlways think step by step and be helpful to the user.\n\nIf and only if you are ready to respond to the user, you MUST begin your response with <final_answer>. DO NOT finish your response with </final_answer>\nExample:\n<think>\nI know the answer to this!\n</think>\n<final_answer>\nThe capital of France is Paris.\n\n\nRelevant past knowledge:\n- """\nReAct (Reason-Act) Agent implementation that handles the complete reasoning and tool-use loop.\nCentralized state management through KnowledgeStore, eliminating ConversationState redundancy.\n"""\nim...\n- def get_react_system_prompt(self) -> str:\n        """Get the system prompt for the ReAct agent"""\n        # Query relevant knowledge from RAG to enhance the system prompt\n        relevant_knowledge = ...\n', tool_calls=None, tool_call_id=None), OpenAIChatMessage(role='user', content='hi', tool_calls=None, tool_call_id=None)]
INFO:     127.0.0.1:48424 - "POST /v1/chat/stream HTTP/1.1" 200 OK
2025-08-08 17:15:01,397 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2025-08-08 17:15:03,101 - __main__ - INFO - --- REQUEST METRICS ---
2025-08-08 17:15:03,101 - __main__ - INFO - [Latency] End-to-End: 1.76 seconds
2025-08-08 17:15:03,101 - __main__ - INFO - [Throughput] Chunks per Second: 107.91
2025-08-08 17:15:03,101 - __main__ - INFO - [Throughput] Total Chunks: 190
2025-08-08 17:15:03,101 - __main__ - INFO - [Resources] Start - CPU: 2.7%, RAM: 16.0%
2025-08-08 17:15:03,101 - __main__ - INFO - [Resources] End   - CPU: 6.6%, RAM: 16.0%
2025-08-08 17:15:03,101 - __main__ - INFO - -----------------------
